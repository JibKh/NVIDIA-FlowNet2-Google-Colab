{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlowNet2_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JibKh/NVIDIA-FlowNet2-Google-Colab/blob/master/FlowNet2_Colab_Incomp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OGCfYuDTz7n"
      },
      "source": [
        "# Setup and Install FlowNet2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6AYibX0sYcH",
        "outputId": "9a68eccd-e0db-4b04-df27-6fb6451f723a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "Wed Oct 14 12:27:09 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMRndXGRFDJo",
        "outputId": "18967285-716c-4d5e-95ee-e2a757a7d471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install torch==1.0.0 torchvision==0.2.2 -f https://download.pytorch.org/whl/cu100/torch_stable.html\n",
        "!pip install pypng\n",
        "!pip install tensorboardx\n",
        "!pip install setproctitle colorama scipy==1.1.0\n",
        "!pip install flowiz -U"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu100/torch_stable.html\n",
            "Collecting torch==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K     |████████████████████████████████| 591.8MB 31kB/s \n",
            "\u001b[?25hCollecting torchvision==0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/a1/66d72a2fe580a9f0fcbaaa5b976911fbbde9dce9b330ba12791997b856e9/torchvision-0.2.2-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.2) (1.15.0)\n",
            "Collecting tqdm==4.19.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/c4/b67cf1ab472b770e08e94105a0c7ca7032cd070627c435f5998c9cf6e64f/tqdm-4.19.9-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.0MB/s \n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.19.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.19.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch, tqdm, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.0.0 torchvision-0.2.2 tqdm-4.19.9\n",
            "Collecting pypng\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/fb/f719f1ac965e2101aa6ea6f54ef8b40f8fbb033f6ad07c017663467f5147/pypng-0.0.20.tar.gz (649kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 7.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pypng\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypng: filename=pypng-0.0.20-cp36-none-any.whl size=67162 sha256=755aa392ebdc722e35c3156588ad80563fa81684d7f767f88f5bf81e500780fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/6b/ef/0493b536b6d4722c2ae9486691b1d49b922b9877922beeabb3\n",
            "Successfully built pypng\n",
            "Installing collected packages: pypng\n",
            "Successfully installed pypng-0.0.20\n",
            "Collecting tensorboardx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardx) (50.3.0)\n",
            "Installing collected packages: tensorboardx\n",
            "Successfully installed tensorboardx-2.1\n",
            "Collecting setproctitle\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/0d/dc0d2234aacba6cf1a729964383e3452c52096dc695581248b548786f2b3/setproctitle-1.1.10.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 102kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.5)\n",
            "Building wheels for collected packages: setproctitle\n",
            "  Building wheel for setproctitle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for setproctitle: filename=setproctitle-1.1.10-cp36-cp36m-linux_x86_64.whl size=33916 sha256=a46343b1f182f641bf975679408ac87891d7ccf3ec474f6d6a4f83bc59229ae5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/b1/a6/9719530228e258eba904501fef99d5d85c80d52bd8f14438a3\n",
            "Successfully built setproctitle\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement scipy==1.4.1, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: setproctitle, colorama, scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed colorama-0.4.4 scipy-1.1.0 setproctitle-1.1.10\n",
            "Collecting flowiz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/f5/7a0edc26cffd1f8a426a8b0c61bce05296136a6c9057347f995e5e27cf13/flowiz-2.3.1-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 7.4MB/s \n",
            "\u001b[?25hCollecting eel\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/c2/7dc22cc9ea23f0339316d6d249392d3ce67190430f2b05a316f3471ae15d/Eel-0.14.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from flowiz) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from flowiz) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from flowiz) (4.19.9)\n",
            "Collecting bottle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/39/2bf3a1fd963e749cdbe5036a184eda8c37d8af25d1297d94b8b7aeec17c4/bottle-0.12.18-py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.8MB/s \n",
            "\u001b[?25hCollecting bottle-websocket\n",
            "  Downloading https://files.pythonhosted.org/packages/17/8e/a22666b4bb0a6e31de579504077df2b1c2f1438136777c728e6cfabef295/bottle-websocket-0.2.9.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from eel->flowiz) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing in /usr/local/lib/python3.6/dist-packages (from eel->flowiz) (2.4.7)\n",
            "Collecting whichcraft\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/a2/81887a0dae2e4d2adc70d9a3557fdda969f863ced51cd3c47b587d25bce5/whichcraft-0.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flowiz) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flowiz) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flowiz) (1.2.0)\n",
            "Collecting gevent-websocket\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/84/2dc373eb6493e00c884cc11e6c059ec97abae2678d42f06bf780570b0193/gevent_websocket-0.10.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->flowiz) (1.15.0)\n",
            "Collecting gevent\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/92/b80b922f08f222faca53c8d278e2e612192bc74b0e1f0db2f80a6ee46982/gevent-20.9.0-cp36-cp36m-manylinux2010_x86_64.whl (5.3MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3MB 32.2MB/s \n",
            "\u001b[?25hCollecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/89/1eb9dbb9e24f5e2c29ab1a88097b2f1333858aac3cd3cccc6c4c1c8ad867/zope.interface-5.1.2-cp36-cp36m-manylinux2010_x86_64.whl (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 42.8MB/s \n",
            "\u001b[?25hCollecting zope.event\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n",
            "Collecting greenlet>=0.4.17; platform_python_implementation == \"CPython\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d0/532e160c777b42f6f393f9de8c88abb8af6c892037c55e4d3a8a211324dd/greenlet-0.4.17-cp36-cp36m-manylinux1_x86_64.whl (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from gevent->gevent-websocket->bottle-websocket->eel->flowiz) (50.3.0)\n",
            "Building wheels for collected packages: eel, bottle-websocket\n",
            "  Building wheel for eel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eel: filename=Eel-0.14.0-cp36-none-any.whl size=17462 sha256=c2956a542ae925e000d471f6467e7ec3dbdf47cfccd58bc41076ff043203f292\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/a8/f9/0bb7b895584b80f4beabebfb8dcfdb8c7b0db2420b9c2a4821\n",
            "  Building wheel for bottle-websocket (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bottle-websocket: filename=bottle_websocket-0.2.9-cp36-none-any.whl size=2349 sha256=7b75f2166da7895c651cd89456525507be3de4c0f48d8b8d84922facfda23e85\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/fd/80/af47541f053f14f4e5fd5927c91a7615358826429ba036152d\n",
            "Successfully built eel bottle-websocket\n",
            "Installing collected packages: bottle, zope.interface, zope.event, greenlet, gevent, gevent-websocket, bottle-websocket, whichcraft, eel, flowiz\n",
            "Successfully installed bottle-0.12.18 bottle-websocket-0.2.9 eel-0.14.0 flowiz-2.3.1 gevent-20.9.0 gevent-websocket-0.10.1 greenlet-0.4.17 whichcraft-0.6.1 zope.event-4.5.0 zope.interface-5.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWy52WXkEX7M",
        "outputId": "c74f010e-f5ec-421c-f5a8-383a36732418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "# get flownet2-pytorch source\n",
        "!git clone https://github.com/NVIDIA/flownet2-pytorch.git\n",
        "!mv /content/flownet2-pytorch /content/flownet2pytorch\n",
        "os.chdir('./flownet2pytorch')\n",
        "# install custom layers\n",
        "!bash install.sh"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'flownet2-pytorch'...\n",
            "remote: Enumerating objects: 557, done.\u001b[K\n",
            "remote: Total 557 (delta 0), reused 0 (delta 0), pack-reused 557\u001b[K\n",
            "Receiving objects: 100% (557/557), 6.28 MiB | 916.00 KiB/s, done.\n",
            "Resolving deltas: 100% (312/312), done.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating correlation_cuda.egg-info\n",
            "writing correlation_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to correlation_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to correlation_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'correlation_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'correlation_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'correlation_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/lib/include -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c correlation_cuda.cc -o build/temp.linux-x86_64-3.6/correlation_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=correlation_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[Kcorrelation_cuda.cc:1:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/lib/include/torch/csrc/api/include/torch/torch.h:7:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Including torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/lib/include -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c correlation_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/correlation_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=correlation_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/correlation_cuda.o build/temp.linux-x86_64-3.6/correlation_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/correlation_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/correlation_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for correlation_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/correlation_cuda.py to correlation_cuda.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.correlation_cuda.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing correlation_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Extracting correlation_cuda-0.0.0-py3.6-linux-x86_64.egg to /root/.local/lib/python3.6/site-packages\n",
            "Adding correlation-cuda 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for correlation-cuda==0.0.0\n",
            "Finished processing dependencies for correlation-cuda==0.0.0\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating resample2d_cuda.egg-info\n",
            "writing resample2d_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to resample2d_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to resample2d_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'resample2d_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'resample2d_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'resample2d_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/lib/include -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c resample2d_cuda.cc -o build/temp.linux-x86_64-3.6/resample2d_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=resample2d_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[Kresample2d_cuda.cc:2:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/lib/include/torch/csrc/api/include/torch/torch.h:7:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Including torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/lib/include -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c resample2d_kernel.cu -o build/temp.linux-x86_64-3.6/resample2d_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=resample2d_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/resample2d_cuda.o build/temp.linux-x86_64-3.6/resample2d_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/resample2d_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/resample2d_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for resample2d_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resample2d_cuda.py to resample2d_cuda.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.resample2d_cuda.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Extracting resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg to /root/.local/lib/python3.6/site-packages\n",
            "Adding resample2d-cuda 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for resample2d-cuda==0.0.0\n",
            "Finished processing dependencies for resample2d-cuda==0.0.0\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating channelnorm_cuda.egg-info\n",
            "writing channelnorm_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to channelnorm_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to channelnorm_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'channelnorm_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'channelnorm_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'channelnorm_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/lib/include -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c channelnorm_cuda.cc -o build/temp.linux-x86_64-3.6/channelnorm_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=channelnorm_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[Kchannelnorm_cuda.cc:1:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/lib/include/torch/csrc/api/include/torch/torch.h:7:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Including torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/lib/include -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c channelnorm_kernel.cu -o build/temp.linux-x86_64-3.6/channelnorm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=channelnorm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/channelnorm_cuda.o build/temp.linux-x86_64-3.6/channelnorm_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/channelnorm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/channelnorm_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for channelnorm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/channelnorm_cuda.py to channelnorm_cuda.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.channelnorm_cuda.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Extracting channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg to /root/.local/lib/python3.6/site-packages\n",
            "Adding channelnorm-cuda 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for channelnorm-cuda==0.0.0\n",
            "Finished processing dependencies for channelnorm-cuda==0.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVwu6EIMVj2C"
      },
      "source": [
        "import os\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append( '/root/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tekc8kk_Ehft",
        "outputId": "2e849b46-7eca-4ecc-af4c-e14d1fd56d15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python main.py --help"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: main.py [-h] [--start_epoch START_EPOCH] [--total_epochs TOTAL_EPOCHS]\n",
            "               [--batch_size BATCH_SIZE] [--train_n_batches TRAIN_N_BATCHES]\n",
            "               [--crop_size CROP_SIZE [CROP_SIZE ...]]\n",
            "               [--gradient_clip GRADIENT_CLIP]\n",
            "               [--schedule_lr_frequency SCHEDULE_LR_FREQUENCY]\n",
            "               [--schedule_lr_fraction SCHEDULE_LR_FRACTION]\n",
            "               [--rgb_max RGB_MAX] [--number_workers NUMBER_WORKERS]\n",
            "               [--number_gpus NUMBER_GPUS] [--no_cuda] [--seed SEED]\n",
            "               [--name NAME] [--save SAVE]\n",
            "               [--validation_frequency VALIDATION_FREQUENCY]\n",
            "               [--validation_n_batches VALIDATION_N_BATCHES]\n",
            "               [--render_validation] [--inference] [--inference_visualize]\n",
            "               [--inference_size INFERENCE_SIZE [INFERENCE_SIZE ...]]\n",
            "               [--inference_batch_size INFERENCE_BATCH_SIZE]\n",
            "               [--inference_n_batches INFERENCE_N_BATCHES] [--save_flow]\n",
            "               [--resume PATH] [--log_frequency LOG_FREQUENCY]\n",
            "               [--skip_training] [--skip_validation] [--fp16]\n",
            "               [--fp16_scale FP16_SCALE]\n",
            "               [--model {ChannelNorm,FlowNet2,FlowNet2C,FlowNet2CS,FlowNet2CSS,FlowNet2S,FlowNet2SD,Resample2d,tofp16,tofp32}]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --start_epoch START_EPOCH\n",
            "  --total_epochs TOTAL_EPOCHS\n",
            "  --batch_size BATCH_SIZE, -b BATCH_SIZE\n",
            "                        Batch size\n",
            "  --train_n_batches TRAIN_N_BATCHES\n",
            "                        Number of min-batches per epoch. If < 0, it will be\n",
            "                        determined by training_dataloader\n",
            "  --crop_size CROP_SIZE [CROP_SIZE ...]\n",
            "                        Spatial dimension to crop training samples for\n",
            "                        training\n",
            "  --gradient_clip GRADIENT_CLIP\n",
            "  --schedule_lr_frequency SCHEDULE_LR_FREQUENCY\n",
            "                        in number of iterations (0 for no schedule)\n",
            "  --schedule_lr_fraction SCHEDULE_LR_FRACTION\n",
            "  --rgb_max RGB_MAX\n",
            "  --number_workers NUMBER_WORKERS, -nw NUMBER_WORKERS, --num_workers NUMBER_WORKERS\n",
            "  --number_gpus NUMBER_GPUS, -ng NUMBER_GPUS\n",
            "                        number of GPUs to use\n",
            "  --no_cuda\n",
            "  --seed SEED\n",
            "  --name NAME           a name to append to the save directory\n",
            "  --save SAVE, -s SAVE  directory for saving\n",
            "  --validation_frequency VALIDATION_FREQUENCY\n",
            "                        validate every n epochs\n",
            "  --validation_n_batches VALIDATION_N_BATCHES\n",
            "  --render_validation   run inference (save flows to file) and every\n",
            "                        validation_frequency epoch\n",
            "  --inference\n",
            "  --inference_visualize\n",
            "                        visualize the optical flow during inference\n",
            "  --inference_size INFERENCE_SIZE [INFERENCE_SIZE ...]\n",
            "                        spatial size divisible by 64. default (-1,-1) -\n",
            "                        largest possible valid size would be used\n",
            "  --inference_batch_size INFERENCE_BATCH_SIZE\n",
            "  --inference_n_batches INFERENCE_N_BATCHES\n",
            "  --save_flow           save predicted flows to file\n",
            "  --resume PATH         path to latest checkpoint (default: none)\n",
            "  --log_frequency LOG_FREQUENCY, --summ_iter LOG_FREQUENCY\n",
            "                        Log every n batches\n",
            "  --skip_training\n",
            "  --skip_validation\n",
            "  --fp16                Run model in pseudo-fp16 mode (fp16 storage fp32\n",
            "                        math).\n",
            "  --fp16_scale FP16_SCALE\n",
            "                        Loss scaling, positive power of 2 values can improve\n",
            "                        fp16 convergence.\n",
            "\n",
            "Model:\n",
            "  --model {ChannelNorm,FlowNet2,FlowNet2C,FlowNet2CS,FlowNet2CSS,FlowNet2S,FlowNet2SD,Resample2d,tofp16,tofp32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78C23XEP2kQv"
      },
      "source": [
        "# User Input and Restart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9cX_qfLjHsu"
      },
      "source": [
        "# FOR INFERENCE\n",
        "video_frames = None # If you have a video put 1. If you have frames put 2.\n",
        "\n",
        "frames_zip_name = None # If you have the frames, enter its zip file here. For ex: \"3 - Video.zip\"\n",
        "frames_directory = None # Where the frames are located. If its in gdrive: '../gdrive/My Drive/Location of Zip/' Change the Location of Zip to wherever yours is stored.\n",
        "no_frames_skip = None # How many frames you want skipped. This works in modulus manner. If you input 1, all the frames are skipped. 3 means every third frame is skipped etc. Leave at None to not skip frames.\n",
        "flow_video_name = frames_zip_name[0:-4] + '.mp4'\n",
        "\n",
        "video_name = None # If you have a video you want to run inference on. Please include .mp4 or whatever extension the video has.\n",
        "video_local_gdrive = None # If you want to upload a video from your local drive, choose 1. If from your google drive, choose 2. If some other option, go to section \"Upload Video\".\n",
        "video_gdrive = None # File_id for your google drive video. Use this link to see how to get file ID https://docs.meiro.io/books/meiro-integrations/page/where-can-i-find-the-file-id-on-google-drive#:~:text=To%20locate%20the%20File%20ID,%3D%60%20is%20the%20File%20ID."
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PzvfMnQBdNE",
        "outputId": "0d4277c9-a332-4236-82e8-1fc4ff5cf822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# If you are using Google Drive to access frames, mount it here. The first time you run it, it will give you a prompt.\n",
        "if video_frames == 2:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89v-6Ah_Dz_p"
      },
      "source": [
        "# If you are uploading a video from your local machine, please do so here.\n",
        "if video_frames == 1 and video_local_gdrive == 1:\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  if video_name != list(uploaded.keys())[0]:\n",
        "    video_name = list(uploaded.keys())[0]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiX1DcSQ2sye",
        "outputId": "81270cd8-b174-4814-c56b-43c33759a3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# To restart and run again. Change any parameters above and then go click the \"User Input and Restart\" cell. Then Runtime -> Run After.\n",
        "!rm -r ./frames\n",
        "!rm -r ./FlowFrames\n",
        "!rm -r ./output\n",
        "!rm ./$video_name\n",
        "!rm -r ./FlowVideo\n",
        "# !pip install setproctitle colorama scipy==1.1.0"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove './None': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVqbeGLwLGfJ"
      },
      "source": [
        "# Training and Validation - Not tested"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBj_0jWLKci"
      },
      "source": [
        "If you do not want to train your model, you can skip this and move on to inference.\n",
        "\n",
        "The dataset my team used is quite large and we have unlimited storage on OneDrive. So we have mounted OneDrive to read and write data to. <br>\n",
        "To understand how to use it: https://www.youtube.com/watch?v=U6YPgARhRzA&t=255s&ab_channel=BoostUpStation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVqSGUtKLlVA"
      },
      "source": [
        "## OneDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYM_bz-zLbyj"
      },
      "source": [
        "# !wget https://downloads.rclone.org/v1.50.1/rclone-v1.50.1-linux-amd64.deb\n",
        "# !apt install ./rclone-v1.50.1-linux-amd64.deb"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEbqhaQRLiAe"
      },
      "source": [
        "# !rclone config"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DKu50aALjjY"
      },
      "source": [
        "# !sudo mkdir /content/onedrive\n",
        "# !nohup rclone --vfs-cache-mode writes mount onedrive: /content/onedrive &"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phyZO2lSLqla"
      },
      "source": [
        "## Train and Validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y9f7R1gLu3w"
      },
      "source": [
        "# !python main.py --batch_size 8 --model FlowNet2 --loss=L1Loss --optimizer=Adam --optimizer_lr=1e-4 \\\n",
        "# --training_dataset MpiSintelFinal --training_dataset_root /path/to/mpi-sintel/final/dataset  \\\n",
        "# --validation_dataset MpiSintelClean --validation_dataset_root /path/to/mpi-sintel/clean/dataset"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9C7PFQ8U9b6"
      },
      "source": [
        "# Run the inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1VMSks0KQtP"
      },
      "source": [
        "## Setup Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY7ahjMaKAqe"
      },
      "source": [
        "### Upload Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDAo_HFaWbD9"
      },
      "source": [
        "1) Upload your own video from Google Drive. <br>\n",
        "2) Upload a video from your local machine. They will be saved in flownet2pytorch folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkKX6ae-WaVh"
      },
      "source": [
        "# Download from Google drive\n",
        "if video_frames == 1 and video_local_gdrive == 2:\n",
        "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "  gdd.download_file_from_google_drive(file_id=video_gdrive, dest_path=video_name)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fTmINSkJUAZ"
      },
      "source": [
        "# # Or upload from local machine\n",
        "# if video_frames == 1 and video_local_gdrive == 1:\n",
        "#   from google.colab import files\n",
        "#   uploaded = files.upload()\n",
        "#   if video_name != list(uploaded.keys())[0]:\n",
        "#     video_name = list(uploaded.keys())[0]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVWsVga2W1s7"
      },
      "source": [
        "### Converting video to frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d575duExGp8l"
      },
      "source": [
        "if video_frames == 1:\n",
        "  import os\n",
        "  def mkdir_ifnotexists(dir):\n",
        "      if os.path.exists(dir):\n",
        "          return\n",
        "      os.mkdir(dir)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a57t5vdGrrt"
      },
      "source": [
        "if video_frames == 1:\n",
        "  vid_file = video_name\n",
        "  frame_pth = './frames'\n",
        "  mkdir_ifnotexists(frame_pth)\n",
        "  cmd = \"ffmpeg -i %s -start_number 0 -vsync 0 %s/frame_%%06d.png\" % (\n",
        "              vid_file,\n",
        "              frame_pth,\n",
        "          )\n",
        "  os.system(cmd)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L3TRQ5q3Mgi"
      },
      "source": [
        "## Setup Frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSEAcDEAol3I"
      },
      "source": [
        "### Download Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvNve5gFod1r"
      },
      "source": [
        "# if video_frames == 2:\n",
        "#   !mkdir -p ./frames\n",
        "\n",
        "#   from google.colab import drive\n",
        "#   drive.mount('/content/gdrive')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L85hv1iCrFU4",
        "outputId": "abdcf588-a42b-4949-b95d-046d9859fbfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "if video_frames == 2:\n",
        "  !mkdir -p ./frames\n",
        "  unzip_file = frames_directory + frames_zip_name\n",
        "  !unzip '$unzip_file' -d ./frames"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ../gdrive/My Drive/Hajj Videos/Frames/5 - Video.zip\n",
            "warning:  stripped absolute path spec from /\n",
            "mapname:  conversion of  failed\n",
            " extracting: ./frames/20180820173913572_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173913037_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173913038_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173913438_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173913172_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173913171_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173913705_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173912905_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173913305_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173913706_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173912904_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173913304_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173913439_UTC+01.jpg  \n",
            " extracting: ./frames/20180820173913571_UTC+01.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npquPF-UdglG"
      },
      "source": [
        "### Rename Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-ihQN6NDhxB",
        "outputId": "e735f437-44d1-4f6f-91ef-a35499f50f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j36nh6qofUf"
      },
      "source": [
        "if video_frames == 2:\n",
        "  import os\n",
        "\n",
        "  file_dir = \"./frames/\"\n",
        "  for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "    # print(filename)\n",
        "    if filename[-11:] == \"_UTC+01.jpg\":\n",
        "      src = file_dir + filename\n",
        "      dst = file_dir + str(count).zfill(6) + '.png'\n",
        "      os.rename(src, dst)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3veC5bqDiVI",
        "outputId": "ff155a80-9f6b-40e7-fa16-527f0f181ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnbAAdUYYbZ7"
      },
      "source": [
        "### Skip Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgoSnsdWc4eL",
        "outputId": "e47b557a-a147-4854-a261-f624b936d629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZhez6ItYe09"
      },
      "source": [
        "if no_frames_skip != None:\n",
        "  directory = './frames'\n",
        "  # no_frames_skip = 2\n",
        "\n",
        "  for i, file in enumerate(sorted(os.listdir(directory))):\n",
        "    if (file[-4:] == \".png\") and (int(file[0:-4]) % no_frames_skip == 0):\n",
        "      # print(file)\n",
        "      os.remove(directory+'/' + file)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DY2HgOtyK5r"
      },
      "source": [
        "if no_frames_skip != None:\n",
        "  import os\n",
        "\n",
        "  file_dir = \"./frames/\"\n",
        "  for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "    # print(filename)\n",
        "    if filename[-4:] == \".png\":\n",
        "      src = file_dir + filename\n",
        "      dst = file_dir + str(count).zfill(6) + '.png'\n",
        "      os.rename(src, dst)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUPkb7MwDgNi",
        "outputId": "0f4ea4a5-5f03-4fa8-f440-4ca1a13b7ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDUhzIm9KX58"
      },
      "source": [
        "## Run Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmez3yOUKkQx"
      },
      "source": [
        "Download the checkpoint. <br>\n",
        "If you have your own checkpoint after training, skip this step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePuj4IqqGk_k"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da',dest_path='./FlowNet2_checkpoint.pth.tar')"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZn6AR6VKqMb"
      },
      "source": [
        "Run inference. <br>\n",
        "You can learn more about each command from here: https://towardsdatascience.com/generating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOJoEKsHS1n1",
        "outputId": "0764069a-5162-4d99-c919-1188f89e80a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!python main.py --inference --model FlowNet2 --save_flow --save ./output --inference_dataset ImagesFromFolder --inference_dataset_root ./frames/ --resume ./FlowNet2_checkpoint.pth.tar"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing Arguments\n",
            "  [0.018s] \u001b[0mbatch_size: 8\u001b[0m\n",
            "  [0.018s] \u001b[0mcrop_size: [256, 256]\u001b[0m\n",
            "  [0.018s] \u001b[0mfp16: False\u001b[0m\n",
            "  [0.018s] \u001b[0mfp16_scale: 1024.0\u001b[0m\n",
            "  [0.018s] \u001b[0mgradient_clip: None\u001b[0m\n",
            "  [0.018s] \u001b[35minference: True\u001b[0m\n",
            "  [0.018s] \u001b[0minference_batch_size: 1\u001b[0m\n",
            "  [0.018s] \u001b[35minference_dataset: ImagesFromFolder\u001b[0m\n",
            "  [0.018s] \u001b[0minference_dataset_iext: png\u001b[0m\n",
            "  [0.018s] \u001b[0minference_dataset_replicates: 1\u001b[0m\n",
            "  [0.018s] \u001b[35minference_dataset_root: ./frames/\u001b[0m\n",
            "  [0.018s] \u001b[0minference_n_batches: -1\u001b[0m\n",
            "  [0.018s] \u001b[0minference_size: [-1, -1]\u001b[0m\n",
            "  [0.018s] \u001b[0minference_visualize: False\u001b[0m\n",
            "  [0.018s] \u001b[0mlog_frequency: 1\u001b[0m\n",
            "  [0.018s] \u001b[0mloss: L1Loss\u001b[0m\n",
            "  [0.018s] \u001b[0mmodel: FlowNet2\u001b[0m\n",
            "  [0.018s] \u001b[0mmodel_batchNorm: False\u001b[0m\n",
            "  [0.018s] \u001b[0mmodel_div_flow: 20.0\u001b[0m\n",
            "  [0.018s] \u001b[0mname: run\u001b[0m\n",
            "  [0.018s] \u001b[0mno_cuda: False\u001b[0m\n",
            "  [0.018s] \u001b[35mnumber_gpus: 1\u001b[0m\n",
            "  [0.018s] \u001b[0mnumber_workers: 8\u001b[0m\n",
            "  [0.018s] \u001b[0moptimizer: Adam\u001b[0m\n",
            "  [0.018s] \u001b[0moptimizer_amsgrad: False\u001b[0m\n",
            "  [0.018s] \u001b[0moptimizer_betas: (0.9, 0.999)\u001b[0m\n",
            "  [0.019s] \u001b[0moptimizer_eps: 1e-08\u001b[0m\n",
            "  [0.019s] \u001b[0moptimizer_lr: 0.001\u001b[0m\n",
            "  [0.019s] \u001b[0moptimizer_weight_decay: 0\u001b[0m\n",
            "  [0.019s] \u001b[0mrender_validation: False\u001b[0m\n",
            "  [0.019s] \u001b[35mresume: ./FlowNet2_checkpoint.pth.tar\u001b[0m\n",
            "  [0.019s] \u001b[0mrgb_max: 255.0\u001b[0m\n",
            "  [0.019s] \u001b[35msave: ./output\u001b[0m\n",
            "  [0.019s] \u001b[35msave_flow: True\u001b[0m\n",
            "  [0.019s] \u001b[0mschedule_lr_fraction: 10\u001b[0m\n",
            "  [0.019s] \u001b[0mschedule_lr_frequency: 0\u001b[0m\n",
            "  [0.019s] \u001b[0mseed: 1\u001b[0m\n",
            "  [0.019s] \u001b[0mskip_training: False\u001b[0m\n",
            "  [0.019s] \u001b[0mskip_validation: False\u001b[0m\n",
            "  [0.019s] \u001b[0mstart_epoch: 1\u001b[0m\n",
            "  [0.019s] \u001b[0mtotal_epochs: 10000\u001b[0m\n",
            "  [0.019s] \u001b[0mtrain_n_batches: -1\u001b[0m\n",
            "  [0.019s] \u001b[0mtraining_dataset: MpiSintelFinal\u001b[0m\n",
            "  [0.019s] \u001b[0mtraining_dataset_replicates: 1\u001b[0m\n",
            "  [0.019s] \u001b[0mtraining_dataset_root: ./MPI-Sintel/flow/training\u001b[0m\n",
            "  [0.019s] \u001b[0mvalidation_dataset: MpiSintelClean\u001b[0m\n",
            "  [0.019s] \u001b[0mvalidation_dataset_replicates: 1\u001b[0m\n",
            "  [0.019s] \u001b[0mvalidation_dataset_root: ./MPI-Sintel/flow/training\u001b[0m\n",
            "  [0.019s] \u001b[0mvalidation_frequency: 5\u001b[0m\n",
            "  [0.019s] \u001b[0mvalidation_n_batches: -1\u001b[0m\n",
            "  [0.023s] Operation finished\n",
            "\n",
            "Source Code\n",
            "  Current Git Hash: b'2e9e010c98931bc7cef3eb063b195f1e0ab470ba'\n",
            "\n",
            "Initializing Datasets\n",
            "  [0.031s] Inference Dataset: ImagesFromFolder\n",
            "  [0.084s] Inference Input: [3, 2, 704, 1280]\n",
            "  [0.127s] Inference Targets: [3, 2, 704, 1280]\n",
            "  [0.127s] Operation finished\n",
            "\n",
            "Building FlowNet2 model\n",
            "  [4.742s] Effective Batch Size: 8\n",
            "  [4.743s] Number of parameters: 162518834\n",
            "  [4.743s] Initializing CUDA\n",
            "  [8.894s] Parallelizing\n",
            "  [8.895s] Loading checkpoint './FlowNet2_checkpoint.pth.tar'\n",
            "  [9.290s] Loaded checkpoint './FlowNet2_checkpoint.pth.tar' (at epoch 0)\n",
            "  [9.290s] Initializing save directory: ./output\n",
            "  [9.294s] Operation finished\n",
            "\n",
            "Initializing Adam Optimizer\n",
            "  [0.001s] amsgrad = False (<class 'bool'>)\n",
            "  [0.001s] weight_decay = 0 (<class 'int'>)\n",
            "  [0.001s] eps = 1e-08 (<class 'float'>)\n",
            "  [0.001s] betas = (0.9, 0.999) (<class 'tuple'>)\n",
            "  [0.001s] lr = 0.001 (<class 'float'>)\n",
            "  [0.001s] Operation finished\n",
            "\n",
            "Overall Progress:   0%|                                                       | 0/1 [00:00<?, ?it/s]\n",
            "Inferencing :   0%|                                                        | 0/13.0 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "\n",
            "Inference Averages for Epoch 0: L1: 0.667, EPE: 1.155:   0%|               | 0/13.0 [00:01<?, ?it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.667, EPE: 1.155:   8%|▌      | 1/13.0 [00:01<00:19,  1.65s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.667, EPE: 1.155:   8%|▌      | 1/13.0 [00:01<00:19,  1.65s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.662, EPE: 1.147:   8%|▌      | 1/13.0 [00:01<00:19,  1.65s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.662, EPE: 1.147:  15%|█      | 2/13.0 [00:01<00:13,  1.25s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.662, EPE: 1.147:  15%|█      | 2/13.0 [00:01<00:13,  1.25s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.654, EPE: 1.133:  15%|█      | 2/13.0 [00:02<00:13,  1.25s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.654, EPE: 1.133:  23%|█▌     | 3/13.0 [00:02<00:10,  1.04s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.654, EPE: 1.133:  23%|█▌     | 3/13.0 [00:02<00:10,  1.04s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.654, EPE: 1.134:  23%|█▌     | 3/13.0 [00:02<00:10,  1.04s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.654, EPE: 1.134:  31%|██▏    | 4/13.0 [00:02<00:07,  1.22it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.654, EPE: 1.134:  31%|██▏    | 4/13.0 [00:02<00:07,  1.22it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.652, EPE: 1.130:  31%|██▏    | 4/13.0 [00:03<00:07,  1.22it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.652, EPE: 1.130:  38%|██▋    | 5/13.0 [00:03<00:05,  1.48it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.652, EPE: 1.130:  38%|██▋    | 5/13.0 [00:03<00:05,  1.48it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.644, EPE: 1.116:  38%|██▋    | 5/13.0 [00:03<00:05,  1.48it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.644, EPE: 1.116:  46%|███▏   | 6/13.0 [00:03<00:03,  1.76it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.644, EPE: 1.116:  46%|███▏   | 6/13.0 [00:03<00:03,  1.76it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.641, EPE: 1.110:  46%|███▏   | 6/13.0 [00:03<00:03,  1.76it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.641, EPE: 1.110:  54%|███▊   | 7/13.0 [00:03<00:02,  2.04it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.641, EPE: 1.110:  54%|███▊   | 7/13.0 [00:03<00:02,  2.04it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.643, EPE: 1.114:  54%|███▊   | 7/13.0 [00:04<00:02,  2.04it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.643, EPE: 1.114:  62%|████▎  | 8/13.0 [00:04<00:02,  2.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.643, EPE: 1.114:  62%|████▎  | 8/13.0 [00:04<00:02,  2.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.655, EPE: 1.135:  62%|████▎  | 8/13.0 [00:04<00:02,  2.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.655, EPE: 1.135:  69%|████▊  | 9/13.0 [00:04<00:01,  2.51it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.655, EPE: 1.135:  69%|████▊  | 9/13.0 [00:04<00:01,  2.51it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.667, EPE: 1.156:  69%|████▊  | 9/13.0 [00:04<00:01,  2.51it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.667, EPE: 1.156:  77%|████▌ | 10/13.0 [00:04<00:01,  2.68it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.667, EPE: 1.156:  77%|████▌ | 10/13.0 [00:04<00:01,  2.68it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.677, EPE: 1.173:  77%|████▌ | 10/13.0 [00:05<00:01,  2.68it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.677, EPE: 1.173:  85%|█████ | 11/13.0 [00:05<00:00,  2.82it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.677, EPE: 1.173:  85%|█████ | 11/13.0 [00:05<00:00,  2.82it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.686, EPE: 1.188:  85%|█████ | 11/13.0 [00:05<00:00,  2.82it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.686, EPE: 1.188:  92%|█████▌| 12/13.0 [00:05<00:00,  2.93it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.686, EPE: 1.188:  92%|█████▌| 12/13.0 [00:05<00:00,  2.93it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.694, EPE: 1.201:  92%|█████▌| 12/13.0 [00:05<00:00,  2.93it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.694, EPE: 1.201: 100%|██████| 13/13.0 [00:05<00:00,  3.01it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.694, EPE: 1.201: 100%|██████| 13/13.0 [00:05<00:00,  3.01it/s]\u001b[A\n",
            "Overall Progress: 100%|███████████████████████████████████████████████| 1/1 [00:05<00:00,  5.84s/it]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcPNFZh04-YE"
      },
      "source": [
        "# Flowiz technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBogYWu65HQe",
        "outputId": "ef70d711-2494-43f2-8eb7-d64bb2e15fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!python -m flowiz \\\n",
        "output/inference/run.epoch-0-flow-field/*.flo \\\n",
        "-o FlowFrames \\\n",
        "-v FlowVideo \\\n",
        "-r 15\n",
        "\n",
        "!mv ./FlowVideo/000000.flo.mp4 './FlowVideo/$flow_video_name'"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Rendering images [.png] from the flows [.flo]\n",
            "> Created directory: FlowFrames\n",
            "FlowFrames/000012.flo.png: 100% 13/13 [00:04<00:00,  3.00it/s]\n",
            "> Compiling [.mp4] video from the flow images [.png]\n",
            "> Saving video as: FlowVideo/000000.flo.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpdC2-7o-V3p",
        "outputId": "0379e3fa-68e9-45af-9e34-a2b06d11629e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.download('./FlowVideo/'+flow_video_name)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ee1dd4bb-b7bc-4eca-8d54-96652ee21dbe\", \"5 - Video.mp4\", 90562)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBSvCvj5XPMX"
      },
      "source": [
        "# Visualizing flo files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5j8_TkanL0_"
      },
      "source": [
        "### Install scipy as some tensorflow functionality requires updated scipy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb5ZMFHcl_jw"
      },
      "source": [
        "# start_time = time.time()\n",
        "\n",
        "# !pip install scipy==1.4.1"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihUwCSdnXlge"
      },
      "source": [
        "### Define show_flow() for visualization.\n",
        " Original Source https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGwMS0x0XaJC"
      },
      "source": [
        "# # Source:https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# UNKNOWN_FLOW_THRESH = 1e7\n",
        "# def show_flow(filename):\n",
        "#     \"\"\"\n",
        "#     visualize optical flow map using matplotlib\n",
        "#     :param filename: optical flow file\n",
        "#     :return: None\n",
        "#     \"\"\"\n",
        "#     flow = read_flow(filename)\n",
        "#     img = flow_to_image(flow)\n",
        "#     plt.imshow(img)\n",
        "#     plt.show()\n",
        "\n",
        "# def read_flow(filename):\n",
        "#     \"\"\"\n",
        "#     read optical flow from Middlebury .flo file\n",
        "#     :param filename: name of the flow file\n",
        "#     :return: optical flow data in matrix\n",
        "#     \"\"\"\n",
        "#     f = open(filename, 'rb')\n",
        "#     magic = np.fromfile(f, np.float32, count=1)\n",
        "#     data2d = None\n",
        "\n",
        "#     if 202021.25 != magic:\n",
        "#         print ('Magic number incorrect. Invalid .flo file')\n",
        "#     else:\n",
        "#         w = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "#         h = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "#         #print(\"Reading %d x %d flo file\" % (h, w))\n",
        "#         data2d = np.fromfile(f, np.float32, count=2 * w * h)\n",
        "#         # reshape data into 3D array (columns, rows, channels)\n",
        "#         data2d = np.resize(data2d, (h, w, 2))\n",
        "#     f.close()\n",
        "#     return data2d\n",
        "\n",
        "# def flow_to_image(flow):\n",
        "#     \"\"\"\n",
        "#     Convert flow into middlebury color code image\n",
        "#     :param flow: optical flow map\n",
        "#     :return: optical flow image in middlebury color\n",
        "#     \"\"\"\n",
        "#     u = flow[:, :, 0]\n",
        "#     v = flow[:, :, 1]\n",
        "\n",
        "#     maxu = -999.\n",
        "#     maxv = -999.\n",
        "#     minu = 999.\n",
        "#     minv = 999.\n",
        "\n",
        "#     idxUnknow = (abs(u) > UNKNOWN_FLOW_THRESH) | (abs(v) > UNKNOWN_FLOW_THRESH)\n",
        "#     u[idxUnknow] = 0\n",
        "#     v[idxUnknow] = 0\n",
        "\n",
        "#     maxu = max(maxu, np.max(u))\n",
        "#     minu = min(minu, np.min(u))\n",
        "\n",
        "#     maxv = max(maxv, np.max(v))\n",
        "#     minv = min(minv, np.min(v))\n",
        "\n",
        "#     rad = np.sqrt(u ** 2 + v ** 2)\n",
        "#     maxrad = max(-1, np.max(rad))\n",
        "\n",
        "#     #print( \"max flow: %.4f\\nflow range:\\nu = %.3f .. %.3f\\nv = %.3f .. %.3f\" % (maxrad, minu,maxu, minv, maxv))\n",
        "\n",
        "#     u = u/(maxrad + np.finfo(float).eps)\n",
        "#     v = v/(maxrad + np.finfo(float).eps)\n",
        "\n",
        "#     img = compute_color(u, v)\n",
        "\n",
        "#     idx = np.repeat(idxUnknow[:, :, np.newaxis], 3, axis=2)\n",
        "#     img[idx] = 0\n",
        "\n",
        "#     return np.uint8(img)\n",
        "\n",
        "\n",
        "# def compute_color(u, v):\n",
        "#     \"\"\"\n",
        "#     compute optical flow color map\n",
        "#     :param u: optical flow horizontal map\n",
        "#     :param v: optical flow vertical map\n",
        "#     :return: optical flow in color code\n",
        "#     \"\"\"\n",
        "#     [h, w] = u.shape\n",
        "#     img = np.zeros([h, w, 3])\n",
        "#     nanIdx = np.isnan(u) | np.isnan(v)\n",
        "#     u[nanIdx] = 0\n",
        "#     v[nanIdx] = 0\n",
        "\n",
        "#     colorwheel = make_color_wheel()\n",
        "#     ncols = np.size(colorwheel, 0)\n",
        "\n",
        "#     rad = np.sqrt(u**2+v**2)\n",
        "\n",
        "#     a = np.arctan2(-v, -u) / np.pi\n",
        "\n",
        "#     fk = (a+1) / 2 * (ncols - 1) + 1\n",
        "\n",
        "#     k0 = np.floor(fk).astype(int)\n",
        "\n",
        "#     k1 = k0 + 1\n",
        "#     k1[k1 == ncols+1] = 1\n",
        "#     f = fk - k0\n",
        "\n",
        "#     for i in range(0, np.size(colorwheel,1)):\n",
        "#         tmp = colorwheel[:, i]\n",
        "#         col0 = tmp[k0-1] / 255\n",
        "#         col1 = tmp[k1-1] / 255\n",
        "#         col = (1-f) * col0 + f * col1\n",
        "\n",
        "#         idx = rad <= 1\n",
        "#         col[idx] = 1-rad[idx]*(1-col[idx])\n",
        "#         notidx = np.logical_not(idx)\n",
        "\n",
        "#         col[notidx] *= 0.75\n",
        "#         img[:, :, i] = np.uint8(np.floor(255 * col*(1-nanIdx)))\n",
        "\n",
        "#     return img\n",
        "\n",
        "\n",
        "# def make_color_wheel():\n",
        "#     \"\"\"\n",
        "#     Generate color wheel according Middlebury color code\n",
        "#     :return: Color wheel\n",
        "#     \"\"\"\n",
        "#     RY = 15\n",
        "#     YG = 6\n",
        "#     GC = 4\n",
        "#     CB = 11\n",
        "#     BM = 13\n",
        "#     MR = 6\n",
        "\n",
        "#     ncols = RY + YG + GC + CB + BM + MR\n",
        "\n",
        "#     colorwheel = np.zeros([ncols, 3])\n",
        "\n",
        "#     col = 0\n",
        "\n",
        "#     # RY\n",
        "#     colorwheel[0:RY, 0] = 255\n",
        "#     colorwheel[0:RY, 1] = np.transpose(np.floor(255*np.arange(0, RY) / RY))\n",
        "#     col += RY\n",
        "\n",
        "#     # YG\n",
        "#     colorwheel[col:col+YG, 0] = 255 - np.transpose(np.floor(255*np.arange(0, YG) / YG))\n",
        "#     colorwheel[col:col+YG, 1] = 255\n",
        "#     col += YG\n",
        "\n",
        "#     # GC\n",
        "#     colorwheel[col:col+GC, 1] = 255\n",
        "#     colorwheel[col:col+GC, 2] = np.transpose(np.floor(255*np.arange(0, GC) / GC))\n",
        "#     col += GC\n",
        "\n",
        "#     # CB\n",
        "#     colorwheel[col:col+CB, 1] = 255 - np.transpose(np.floor(255*np.arange(0, CB) / CB))\n",
        "#     colorwheel[col:col+CB, 2] = 255\n",
        "#     col += CB\n",
        "\n",
        "#     # BM\n",
        "#     colorwheel[col:col+BM, 2] = 255\n",
        "#     colorwheel[col:col+BM, 0] = np.transpose(np.floor(255*np.arange(0, BM) / BM))\n",
        "#     col += + BM\n",
        "\n",
        "#     # MR\n",
        "#     colorwheel[col:col+MR, 2] = 255 - np.transpose(np.floor(255 * np.arange(0, MR) / MR))\n",
        "#     colorwheel[col:col+MR, 0] = 255\n",
        "\n",
        "#     return colorwheel"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORRfYzZnYET2"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ-Yjc7AnmZz"
      },
      "source": [
        "# show_flow('/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/000001.flo')"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itvl1OTiYMSd"
      },
      "source": [
        "### Save Flo files as images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YopuaMoJPYnT"
      },
      "source": [
        "# import os\n",
        "# import PIL.Image\n",
        "# def mkdir_ifnotexists(dir):\n",
        "#     if os.path.exists(dir):\n",
        "#         return\n",
        "#     os.mkdir(dir)\n",
        "\n",
        "\n",
        "# flo_pth='/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/'\n",
        "# flos=[flo_pth + f for f in os.listdir(flo_pth)]\n",
        "# mkdir_ifnotexists('./FlowFrames')\n",
        "# for i in range(len(flos)):\n",
        "#   PIL.Image.fromarray(flow_to_image(read_flow(flos[i]))).save('./FlowFrames/'+os.path.basename(flos[i])+'.png')\n",
        "#   os.remove(flos[i])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HXMqwKjYT32"
      },
      "source": [
        "### Generate video from Flo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGPockiXSpri"
      },
      "source": [
        "# os.system('ffmpeg -r 15 -i FlowFrames/%6d.flo.png -vcodec libx264 -b 10M -y FlowVideo.mp4')\n",
        "\n",
        "# print(\"My program took\", time.time() - start_time, \"to run\")"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWvhMuDdl1GG"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('FlowVideo.mp4')"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i_mPe1OYoTi"
      },
      "source": [
        "# from IPython.display import HTML\n",
        "# from base64 import b64encode\n",
        "# mp4 = open('FlowVideo.mp4','rb').read()\n",
        "# data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "# HTML(\"\"\"\n",
        "# <video width=400 controls>\n",
        "#       <source src=\"%s\" type=\"video/mp4\">\n",
        "# </video>\n",
        "# \"\"\" % data_url)"
      ],
      "execution_count": 69,
      "outputs": []
    }
  ]
}