{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlowNet2_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JibKh/NVIDIA-FlowNet2-Google-Colab/blob/master/FlowNet2_Colab_SPROJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OGCfYuDTz7n"
      },
      "source": [
        "# Setup and Install FlowNet2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6AYibX0sYcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbf087a-c7dc-4c6a-c11c-3ced527b324e"
      },
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "Sun May  2 17:07:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMRndXGRFDJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42c88ed-3ab5-4b17-c4d7-23a971b8a108"
      },
      "source": [
        "!pip install torch==1.0.0 torchvision==0.2.2 -f https://download.pytorch.org/whl/cu100/torch_stable.html\n",
        "!pip install pypng\n",
        "!pip install tensorboardx\n",
        "!pip install setproctitle colorama scipy==1.1.0\n",
        "!pip install flowiz -U"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu100/torch_stable.html\n",
            "Requirement already satisfied: torch==1.0.0 in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision==0.2.2 in /usr/local/lib/python3.7/dist-packages (0.2.2)\n",
            "Requirement already satisfied: tqdm==4.19.9 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.2) (4.19.9)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.2) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.2) (1.15.0)\n",
            "Requirement already satisfied: pypng in /usr/local/lib/python3.7/dist-packages (0.0.20)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx) (56.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx) (1.15.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n",
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n",
            "Requirement already up-to-date: flowiz in /usr/local/lib/python3.7/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from flowiz) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from flowiz) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from flowiz) (4.19.9)\n",
            "Requirement already satisfied, skipping upgrade: eel in /usr/local/lib/python3.7/dist-packages (from flowiz) (0.14.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flowiz) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flowiz) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flowiz) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flowiz) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: bottle-websocket in /usr/local/lib/python3.7/dist-packages (from eel->flowiz) (0.2.9)\n",
            "Requirement already satisfied, skipping upgrade: whichcraft in /usr/local/lib/python3.7/dist-packages (from eel->flowiz) (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from eel->flowiz) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: bottle in /usr/local/lib/python3.7/dist-packages (from eel->flowiz) (0.12.19)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->flowiz) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: gevent-websocket in /usr/local/lib/python3.7/dist-packages (from bottle-websocket->eel->flowiz) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: gevent in /usr/local/lib/python3.7/dist-packages (from gevent-websocket->bottle-websocket->eel->flowiz) (21.1.2)\n",
            "Requirement already satisfied, skipping upgrade: greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.7/dist-packages (from gevent->gevent-websocket->bottle-websocket->eel->flowiz) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: zope.interface in /usr/local/lib/python3.7/dist-packages (from gevent->gevent-websocket->bottle-websocket->eel->flowiz) (5.4.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent->gevent-websocket->bottle-websocket->eel->flowiz) (56.0.0)\n",
            "Requirement already satisfied, skipping upgrade: zope.event in /usr/local/lib/python3.7/dist-packages (from gevent->gevent-websocket->bottle-websocket->eel->flowiz) (4.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWy52WXkEX7M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "f2dd100a-2406-4b3a-f1f5-b0817005fd51"
      },
      "source": [
        "import os\n",
        "# get flownet2-pytorch source\n",
        "!git clone https://github.com/NVIDIA/flownet2-pytorch.git\n",
        "!mv /content/flownet2-pytorch /content/flownet2pytorch\n",
        "os.chdir('./flownet2pytorch')\n",
        "# install custom layers\n",
        "!bash install.sh"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'flownet2-pytorch'...\n",
            "remote: Enumerating objects: 557, done.\u001b[K\n",
            "remote: Total 557 (delta 0), reused 0 (delta 0), pack-reused 557\u001b[K\n",
            "Receiving objects: 100% (557/557), 6.28 MiB | 15.10 MiB/s, done.\n",
            "Resolving deltas: 100% (312/312), done.\n",
            "mv: cannot stat '/content/flownet2-pytorch': No such file or directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-558a28f58519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'git clone https://github.com/NVIDIA/flownet2-pytorch.git'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mv /content/flownet2-pytorch /content/flownet2pytorch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./flownet2pytorch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# install custom layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash install.sh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './flownet2pytorch'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVwu6EIMVj2C"
      },
      "source": [
        "import os\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append( '/root/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tekc8kk_Ehft"
      },
      "source": [
        "!python main.py --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78C23XEP2kQv"
      },
      "source": [
        "# User Input and Restart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9cX_qfLjHsu"
      },
      "source": [
        "# If you have a video put 1. If you have frames put 2.\n",
        "# Based on your choice, update the below cells accordingly\n",
        "video_frames = 1\n",
        "\n",
        "# If you would like to visualize the flow frames. This WILL DELETE ALL THE FLOWFRAMES GENERATED TO SAVE STORAGE.\n",
        "visualize = False "
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCEEb0v2wYas"
      },
      "source": [
        "# Video Input\n",
        "\n",
        "if video_frames == 1:\n",
        "\n",
        "  video_name = 'test.mp4' # If you have a video you want to run inference on. Please include .mp4 or whatever extension the video has.\n",
        "  video_local_gdrive = 2 # If you want to upload a video from your local drive, choose 1. If from your google drive, choose 2. If some other option, go to section \"Upload Video\".\n",
        "  \n",
        "  # If your video is on gdrive, please add Gdrive ID here.\n",
        "  if video_local_gdrive == 2:\n",
        "    video_gdrive = '1UcL20kKE5LA_Gn0ybxIYGVbya6NxcirF' # File_id for your google drive video. Use this link to see how to get file ID https://docs.meiro.io/books/meiro-integrations/page/where-can-i-find-the-file-id-on-google-drive#:~:text=To%20locate%20the%20File%20ID,%3D%60%20is%20the%20File%20ID.\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lviH4LCUwWmB"
      },
      "source": [
        "# Frames Input\n",
        "\n",
        "if video_frames == 2:\n",
        "\n",
        "  # Mount Gdrive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  frames_zip_name = \"2 - Arabic.zip\" # If you have the frames, enter its zip file here. For ex: \"3 - Video.zip\"\n",
        "  frames_directory = '../gdrive/My Drive/Hajj Videos/Frames/' # Where the frames are located. If its in gdrive: '../gdrive/My Drive/Location of Zip/' Change the Location of Zip to wherever yours is stored.\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjCyiIBPwhsR"
      },
      "source": [
        "# Skip / Average Options\n",
        "\n",
        "no_frames_skip = 1 # How many frames you want skipped. For eg if its 2 then from frames 1,2,3,4,5,6,7 we take frames 1,4,7. Leave at None to not skip frames.\n",
        "\n",
        "# Only one can work at a time\n",
        "no_average_frames = None # How many frames you want to average. Leave at None if you don't want to avg.\n",
        "running_average = False # If you want to visually see running average"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFhOiS9EvPyJ",
        "outputId": "b9652bb0-1fd5-4b0a-ba12-993a6a6b365e"
      },
      "source": [
        "# DO NOT TOUCH\n",
        "\n",
        "flow_video_name = 'flowvid.mp4'\n",
        "\n",
        "# FOR VIDEOS\n",
        "if video_frames == 1:\n",
        "\n",
        "  # This will prompt you to upload the video from your local machine\n",
        "  if video_local_gdrive == 1:\n",
        "\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if video_name != list(uploaded.keys())[0]:\n",
        "      video_name = list(uploaded.keys())[0]\n",
        "\n",
        "  # This downloads the gdrive video\n",
        "  elif video_local_gdrive == 2:\n",
        "\n",
        "    # This will download the video\n",
        "    !gdown --id $video_gdrive\n",
        "\n",
        "# FOR FRAMES\n",
        "if video_frames == 2:\n",
        "  \n",
        "  !mkdir -p ./frames\n",
        "  unzip_file = frames_directory + frames_zip_name\n",
        "  !unzip '$unzip_file' -d ./frames\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UcL20kKE5LA_Gn0ybxIYGVbya6NxcirF\n",
            "To: /content/flownet2pytorch/test.mp4\n",
            "10.2MB [00:00, 38.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiX1DcSQ2sye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95de912-e344-416a-8b49-ef0eb422ba70"
      },
      "source": [
        "# THIS WILL DELETE ALL THE FRAMES, FLOW FRAMES, OUTPUT FILES, FLOW VIDEO.\n",
        "# If you would like to keep something, make sure to comment it out and save it before running this.\n",
        "\n",
        "# To restart and run again. Change any parameters above and then go click the \"User Input and Restart\" cell. Then Runtime -> Run After.\n",
        "\n",
        "!rm -r ./frames\n",
        "!rm -r ./Flo\n",
        "!rm -r ./FlowFrames\n",
        "!rm -r ./output\n",
        "# !rm ./$video_name\n",
        "!rm -r ./Average_Frames\n",
        "!rm -r ./Running_Avg_Frames\n",
        "!rm -r ./FlowVideo\n",
        "!pip install setproctitle colorama scipy==1.1.0"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove './FlowFrames': No such file or directory\n",
            "rm: cannot remove './FlowVideo': No such file or directory\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n",
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVqbeGLwLGfJ"
      },
      "source": [
        "# Training and Validation - Not tested"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBj_0jWLKci"
      },
      "source": [
        "If you do not want to train your model, you can skip this and move on to inference.\n",
        "\n",
        "The dataset my team used is quite large and we have unlimited storage on OneDrive. So we have mounted OneDrive to read and write data to. <br>\n",
        "To understand how to use it: https://www.youtube.com/watch?v=U6YPgARhRzA&t=255s&ab_channel=BoostUpStation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVqSGUtKLlVA"
      },
      "source": [
        "## OneDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYM_bz-zLbyj"
      },
      "source": [
        "# !wget https://downloads.rclone.org/v1.50.1/rclone-v1.50.1-linux-amd64.deb\n",
        "# !apt install ./rclone-v1.50.1-linux-amd64.deb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEbqhaQRLiAe"
      },
      "source": [
        "# !rclone config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DKu50aALjjY"
      },
      "source": [
        "# !sudo mkdir /content/onedrive\n",
        "# !nohup rclone --vfs-cache-mode writes mount onedrive: /content/onedrive &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phyZO2lSLqla"
      },
      "source": [
        "## Train and Validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y9f7R1gLu3w"
      },
      "source": [
        "# !python main.py --batch_size 8 --model FlowNet2 --loss=L1Loss --optimizer=Adam --optimizer_lr=1e-4 \\\n",
        "# --training_dataset MpiSintelFinal --training_dataset_root /path/to/mpi-sintel/final/dataset  \\\n",
        "# --validation_dataset MpiSintelClean --validation_dataset_root /path/to/mpi-sintel/clean/dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9C7PFQ8U9b6"
      },
      "source": [
        "# Run the inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1VMSks0KQtP"
      },
      "source": [
        "## Setup Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVWsVga2W1s7"
      },
      "source": [
        "### Converting video to frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d575duExGp8l"
      },
      "source": [
        "import os\n",
        "\n",
        "if video_frames == 1:\n",
        "  def mkdir_ifnotexists(dir):\n",
        "      if os.path.exists(dir):\n",
        "          return\n",
        "      os.mkdir(dir)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a57t5vdGrrt"
      },
      "source": [
        "if video_frames == 1:\n",
        "  vid_file = video_name\n",
        "  frame_pth = './frames'\n",
        "  mkdir_ifnotexists(frame_pth)\n",
        "  cmd = \"ffmpeg -i %s -start_number 0 -vsync 0 %s/frame_%%06d.png\" % (\n",
        "              vid_file,\n",
        "              frame_pth,\n",
        "          )\n",
        "  os.system(cmd)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7L3TRQ5q3Mgi"
      },
      "source": [
        "## Setup Frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npquPF-UdglG"
      },
      "source": [
        "### Rename Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-ihQN6NDhxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b72c618f-039f-463b-cf85-10d19001a2e1"
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j36nh6qofUf"
      },
      "source": [
        "if video_frames == 2:\n",
        "  import os\n",
        "\n",
        "  file_dir = \"./frames/\"\n",
        "  for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "    # print(filename)\n",
        "    if filename[-11:] == \"_UTC+01.jpg\":\n",
        "      src = file_dir + filename\n",
        "      dst = file_dir + str(count).zfill(6) + '.png'\n",
        "      os.rename(src, dst)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3veC5bqDiVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eeefbdc-3f26-4bb0-8108-98c04f05f34e"
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnbAAdUYYbZ7"
      },
      "source": [
        "### Skip Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgoSnsdWc4eL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0469109-738e-451f-acce-f9435d0550a1"
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZhez6ItYe09"
      },
      "source": [
        "if no_frames_skip != None:\n",
        "  directory = \"./frames\"\n",
        "\n",
        "  temp_skip = no_frames_skip\n",
        "\n",
        "  for i, file in enumerate(sorted(os.listdir(directory))):\n",
        "    if (temp_skip != 0) and (file[-4:] == \".png\"):\n",
        "      os.remove(directory + '/' + file)\n",
        "      temp_skip = temp_skip - 1\n",
        "      continue\n",
        "    temp_skip = no_frames_skip\n",
        "\n",
        "\n",
        "# if no_frames_skip != None:\n",
        "#   directory = './frames'\n",
        "#   # no_frames_skip = 2\n",
        "\n",
        "#   for i, file in enumerate(sorted(os.listdir(directory))):\n",
        "#     if (file[-4:] == \".png\") and (int(file[0:-4]) % no_frames_skip == 0):\n",
        "#       # print(file)\n",
        "#       os.remove(directory+'/' + file)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DY2HgOtyK5r"
      },
      "source": [
        "if no_frames_skip != None:\n",
        "  import os\n",
        "\n",
        "  file_dir = \"./frames/\"\n",
        "  for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "    # print(filename)\n",
        "    if filename[-4:] == \".png\":\n",
        "      src = file_dir + filename\n",
        "      dst = file_dir + str(count).zfill(6) + '.png'\n",
        "      os.rename(src, dst)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUPkb7MwDgNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e09c9d8-c763-4533-9884-38456561802d"
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDUhzIm9KX58"
      },
      "source": [
        "## Run Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmez3yOUKkQx"
      },
      "source": [
        "Download the checkpoint. <br>\n",
        "If you have your own checkpoint after training, skip this step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePuj4IqqGk_k"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da',dest_path='./FlowNet2_checkpoint.pth.tar')"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZn6AR6VKqMb"
      },
      "source": [
        "Run inference. <br>\n",
        "You can learn more about each command from here: https://towardsdatascience.com/generating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOJoEKsHS1n1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688bac57-3db7-4687-c39c-66eab0a6c7e9"
      },
      "source": [
        "!python main.py --inference --model FlowNet2 --save_flow --save ./output --inference_dataset ImagesFromFolder --inference_dataset_root ./frames/ --resume ./FlowNet2_checkpoint.pth.tar"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing Arguments\n",
            "  [0.032s] \u001b[0mbatch_size: 8\u001b[0m\n",
            "  [0.032s] \u001b[0mcrop_size: [256, 256]\u001b[0m\n",
            "  [0.032s] \u001b[0mfp16: False\u001b[0m\n",
            "  [0.032s] \u001b[0mfp16_scale: 1024.0\u001b[0m\n",
            "  [0.032s] \u001b[0mgradient_clip: None\u001b[0m\n",
            "  [0.032s] \u001b[35minference: True\u001b[0m\n",
            "  [0.032s] \u001b[0minference_batch_size: 1\u001b[0m\n",
            "  [0.032s] \u001b[35minference_dataset: ImagesFromFolder\u001b[0m\n",
            "  [0.032s] \u001b[0minference_dataset_iext: png\u001b[0m\n",
            "  [0.032s] \u001b[0minference_dataset_replicates: 1\u001b[0m\n",
            "  [0.032s] \u001b[35minference_dataset_root: ./frames/\u001b[0m\n",
            "  [0.032s] \u001b[0minference_n_batches: -1\u001b[0m\n",
            "  [0.032s] \u001b[0minference_size: [-1, -1]\u001b[0m\n",
            "  [0.032s] \u001b[0minference_visualize: False\u001b[0m\n",
            "  [0.032s] \u001b[0mlog_frequency: 1\u001b[0m\n",
            "  [0.032s] \u001b[0mloss: L1Loss\u001b[0m\n",
            "  [0.032s] \u001b[0mmodel: FlowNet2\u001b[0m\n",
            "  [0.032s] \u001b[0mmodel_batchNorm: False\u001b[0m\n",
            "  [0.032s] \u001b[0mmodel_div_flow: 20.0\u001b[0m\n",
            "  [0.032s] \u001b[0mname: run\u001b[0m\n",
            "  [0.032s] \u001b[0mno_cuda: False\u001b[0m\n",
            "  [0.032s] \u001b[35mnumber_gpus: 1\u001b[0m\n",
            "  [0.032s] \u001b[0mnumber_workers: 8\u001b[0m\n",
            "  [0.032s] \u001b[0moptimizer: Adam\u001b[0m\n",
            "  [0.032s] \u001b[0moptimizer_amsgrad: False\u001b[0m\n",
            "  [0.032s] \u001b[0moptimizer_betas: (0.9, 0.999)\u001b[0m\n",
            "  [0.032s] \u001b[0moptimizer_eps: 1e-08\u001b[0m\n",
            "  [0.032s] \u001b[0moptimizer_lr: 0.001\u001b[0m\n",
            "  [0.032s] \u001b[0moptimizer_weight_decay: 0\u001b[0m\n",
            "  [0.032s] \u001b[0mrender_validation: False\u001b[0m\n",
            "  [0.032s] \u001b[35mresume: ./FlowNet2_checkpoint.pth.tar\u001b[0m\n",
            "  [0.032s] \u001b[0mrgb_max: 255.0\u001b[0m\n",
            "  [0.032s] \u001b[35msave: ./output\u001b[0m\n",
            "  [0.032s] \u001b[35msave_flow: True\u001b[0m\n",
            "  [0.032s] \u001b[0mschedule_lr_fraction: 10\u001b[0m\n",
            "  [0.032s] \u001b[0mschedule_lr_frequency: 0\u001b[0m\n",
            "  [0.032s] \u001b[0mseed: 1\u001b[0m\n",
            "  [0.032s] \u001b[0mskip_training: False\u001b[0m\n",
            "  [0.032s] \u001b[0mskip_validation: False\u001b[0m\n",
            "  [0.032s] \u001b[0mstart_epoch: 1\u001b[0m\n",
            "  [0.032s] \u001b[0mtotal_epochs: 10000\u001b[0m\n",
            "  [0.032s] \u001b[0mtrain_n_batches: -1\u001b[0m\n",
            "  [0.032s] \u001b[0mtraining_dataset: MpiSintelFinal\u001b[0m\n",
            "  [0.032s] \u001b[0mtraining_dataset_replicates: 1\u001b[0m\n",
            "  [0.032s] \u001b[0mtraining_dataset_root: ./MPI-Sintel/flow/training\u001b[0m\n",
            "  [0.032s] \u001b[0mvalidation_dataset: MpiSintelClean\u001b[0m\n",
            "  [0.032s] \u001b[0mvalidation_dataset_replicates: 1\u001b[0m\n",
            "  [0.032s] \u001b[0mvalidation_dataset_root: ./MPI-Sintel/flow/training\u001b[0m\n",
            "  [0.032s] \u001b[0mvalidation_frequency: 5\u001b[0m\n",
            "  [0.032s] \u001b[0mvalidation_n_batches: -1\u001b[0m\n",
            "  [0.036s] Operation finished\n",
            "\n",
            "Source Code\n",
            "  Current Git Hash: b'2e9e010c98931bc7cef3eb063b195f1e0ab470ba'\n",
            "\n",
            "Initializing Datasets\n",
            "  [0.062s] Inference Dataset: ImagesFromFolder\n",
            "  [0.198s] Inference Input: [3, 2, 1024, 1920]\n",
            "  [0.312s] Inference Targets: [3, 2, 1024, 1920]\n",
            "  [0.312s] Operation finished\n",
            "\n",
            "Building FlowNet2 model\n",
            "  [3.671s] Effective Batch Size: 8\n",
            "  [3.672s] Number of parameters: 162518834\n",
            "  [3.672s] Initializing CUDA\n",
            "  [6.383s] Parallelizing\n",
            "  [6.384s] Loading checkpoint './FlowNet2_checkpoint.pth.tar'\n",
            "  [6.755s] Loaded checkpoint './FlowNet2_checkpoint.pth.tar' (at epoch 0)\n",
            "  [6.755s] Initializing save directory: ./output\n",
            "  [6.758s] Operation finished\n",
            "\n",
            "Initializing Adam Optimizer\n",
            "  [0.001s] amsgrad = False (<class 'bool'>)\n",
            "  [0.001s] weight_decay = 0 (<class 'int'>)\n",
            "  [0.001s] eps = 1e-08 (<class 'float'>)\n",
            "  [0.001s] betas = (0.9, 0.999) (<class 'tuple'>)\n",
            "  [0.001s] lr = 0.001 (<class 'float'>)\n",
            "  [0.001s] Operation finished\n",
            "\n",
            "Overall Progress:   0%|                                                       | 0/1 [00:00<?, ?it/s]\n",
            "Inferencing :   0%|                                                        | 0/90.0 [00:00<?, ?it/s]\u001b[ATHCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=405 error=11 : invalid argument\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "\n",
            "Inference Averages for Epoch 0: L1: 0.025, EPE: 0.044:   0%|               | 0/90.0 [00:03<?, ?it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.025, EPE: 0.044:   1%|       | 1/90.0 [00:03<05:21,  3.62s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.025, EPE: 0.044:   1%|       | 1/90.0 [00:03<05:21,  3.62s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.022, EPE: 0.038:   1%|       | 1/90.0 [00:04<05:21,  3.62s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.022, EPE: 0.038:   2%|▏      | 2/90.0 [00:04<04:03,  2.77s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.022, EPE: 0.038:   2%|▏      | 2/90.0 [00:04<04:03,  2.77s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.024, EPE: 0.041:   2%|▏      | 2/90.0 [00:05<04:03,  2.77s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.024, EPE: 0.041:   3%|▏      | 3/90.0 [00:05<03:08,  2.17s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.024, EPE: 0.041:   3%|▏      | 3/90.0 [00:05<03:08,  2.17s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.053, EPE: 0.092:   3%|▏      | 3/90.0 [00:05<03:08,  2.17s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.053, EPE: 0.092:   4%|▎      | 4/90.0 [00:05<02:30,  1.75s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.053, EPE: 0.092:   4%|▎      | 4/90.0 [00:05<02:30,  1.75s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.052, EPE: 0.090:   4%|▎      | 4/90.0 [00:06<02:30,  1.75s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.052, EPE: 0.090:   6%|▍      | 5/90.0 [00:06<02:03,  1.45s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.052, EPE: 0.090:   6%|▍      | 5/90.0 [00:06<02:03,  1.45s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.057, EPE: 0.099:   6%|▍      | 5/90.0 [00:07<02:03,  1.45s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.057, EPE: 0.099:   7%|▍      | 6/90.0 [00:07<01:45,  1.26s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.057, EPE: 0.099:   7%|▍      | 6/90.0 [00:07<01:45,  1.26s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.063, EPE: 0.109:   7%|▍      | 6/90.0 [00:08<01:45,  1.26s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.063, EPE: 0.109:   8%|▌      | 7/90.0 [00:08<01:32,  1.12s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.063, EPE: 0.109:   8%|▌      | 7/90.0 [00:08<01:32,  1.12s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.071, EPE: 0.123:   8%|▌      | 7/90.0 [00:09<01:32,  1.12s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.071, EPE: 0.123:   9%|▌      | 8/90.0 [00:09<01:23,  1.02s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.071, EPE: 0.123:   9%|▌      | 8/90.0 [00:09<01:23,  1.02s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.084, EPE: 0.145:   9%|▌      | 8/90.0 [00:09<01:23,  1.02s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.084, EPE: 0.145:  10%|▋      | 9/90.0 [00:09<01:16,  1.05it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.084, EPE: 0.145:  10%|▋      | 9/90.0 [00:09<01:16,  1.05it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.094, EPE: 0.163:  10%|▋      | 9/90.0 [00:10<01:16,  1.05it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.094, EPE: 0.163:  11%|▋     | 10/90.0 [00:10<01:11,  1.12it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.094, EPE: 0.163:  11%|▋     | 10/90.0 [00:10<01:11,  1.12it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.110, EPE: 0.190:  11%|▋     | 10/90.0 [00:11<01:11,  1.12it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.110, EPE: 0.190:  12%|▋     | 11/90.0 [00:11<01:07,  1.16it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.110, EPE: 0.190:  12%|▋     | 11/90.0 [00:11<01:07,  1.16it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.122, EPE: 0.211:  12%|▋     | 11/90.0 [00:12<01:07,  1.16it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.122, EPE: 0.211:  13%|▊     | 12/90.0 [00:12<01:04,  1.21it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.122, EPE: 0.211:  13%|▊     | 12/90.0 [00:12<01:04,  1.21it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.133, EPE: 0.231:  13%|▊     | 12/90.0 [00:12<01:04,  1.21it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.133, EPE: 0.231:  14%|▊     | 13/90.0 [00:12<01:02,  1.23it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.133, EPE: 0.231:  14%|▊     | 13/90.0 [00:12<01:02,  1.23it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.150, EPE: 0.261:  14%|▊     | 13/90.0 [00:13<01:02,  1.23it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.150, EPE: 0.261:  16%|▉     | 14/90.0 [00:13<01:00,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.150, EPE: 0.261:  16%|▉     | 14/90.0 [00:13<01:00,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.170, EPE: 0.295:  16%|▉     | 14/90.0 [00:14<01:00,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.170, EPE: 0.295:  17%|█     | 15/90.0 [00:14<00:59,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.170, EPE: 0.295:  17%|█     | 15/90.0 [00:14<00:59,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.193, EPE: 0.334:  17%|█     | 15/90.0 [00:15<00:59,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.193, EPE: 0.334:  18%|█     | 16/90.0 [00:15<00:58,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.193, EPE: 0.334:  18%|█     | 16/90.0 [00:15<00:58,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.209, EPE: 0.363:  18%|█     | 16/90.0 [00:16<00:58,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.209, EPE: 0.363:  19%|█▏    | 17/90.0 [00:16<00:57,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.209, EPE: 0.363:  19%|█▏    | 17/90.0 [00:16<00:57,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.227, EPE: 0.393:  19%|█▏    | 17/90.0 [00:16<00:57,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.227, EPE: 0.393:  20%|█▏    | 18/90.0 [00:16<00:55,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.227, EPE: 0.393:  20%|█▏    | 18/90.0 [00:16<00:55,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.246, EPE: 0.426:  20%|█▏    | 18/90.0 [00:17<00:55,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.246, EPE: 0.426:  21%|█▎    | 19/90.0 [00:17<00:55,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.246, EPE: 0.426:  21%|█▎    | 19/90.0 [00:17<00:55,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.262, EPE: 0.454:  21%|█▎    | 19/90.0 [00:18<00:55,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.262, EPE: 0.454:  22%|█▎    | 20/90.0 [00:18<00:54,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.262, EPE: 0.454:  22%|█▎    | 20/90.0 [00:18<00:54,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.277, EPE: 0.480:  22%|█▎    | 20/90.0 [00:19<00:54,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.277, EPE: 0.480:  23%|█▍    | 21/90.0 [00:19<00:53,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.277, EPE: 0.480:  23%|█▍    | 21/90.0 [00:19<00:53,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.294, EPE: 0.509:  23%|█▍    | 21/90.0 [00:19<00:53,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.294, EPE: 0.509:  24%|█▍    | 22/90.0 [00:19<00:52,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.294, EPE: 0.509:  24%|█▍    | 22/90.0 [00:19<00:52,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.313, EPE: 0.542:  24%|█▍    | 22/90.0 [00:20<00:52,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.313, EPE: 0.542:  26%|█▌    | 23/90.0 [00:20<00:52,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.313, EPE: 0.542:  26%|█▌    | 23/90.0 [00:20<00:52,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.335, EPE: 0.580:  26%|█▌    | 23/90.0 [00:21<00:52,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.335, EPE: 0.580:  27%|█▌    | 24/90.0 [00:21<00:51,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.335, EPE: 0.580:  27%|█▌    | 24/90.0 [00:21<00:51,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.357, EPE: 0.619:  27%|█▌    | 24/90.0 [00:22<00:51,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.357, EPE: 0.619:  28%|█▋    | 25/90.0 [00:22<00:50,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.357, EPE: 0.619:  28%|█▋    | 25/90.0 [00:22<00:50,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.374, EPE: 0.647:  28%|█▋    | 25/90.0 [00:22<00:50,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.374, EPE: 0.647:  29%|█▋    | 26/90.0 [00:22<00:48,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.374, EPE: 0.647:  29%|█▋    | 26/90.0 [00:22<00:48,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.384, EPE: 0.664:  29%|█▋    | 26/90.0 [00:23<00:48,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.384, EPE: 0.664:  30%|█▊    | 27/90.0 [00:23<00:48,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.384, EPE: 0.664:  30%|█▊    | 27/90.0 [00:23<00:48,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.390, EPE: 0.676:  30%|█▊    | 27/90.0 [00:24<00:48,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.390, EPE: 0.676:  31%|█▊    | 28/90.0 [00:24<00:46,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.390, EPE: 0.676:  31%|█▊    | 28/90.0 [00:24<00:46,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.389, EPE: 0.675:  31%|█▊    | 28/90.0 [00:25<00:46,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.389, EPE: 0.675:  32%|█▉    | 29/90.0 [00:25<00:46,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.389, EPE: 0.675:  32%|█▉    | 29/90.0 [00:25<00:46,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.390, EPE: 0.676:  32%|█▉    | 29/90.0 [00:25<00:46,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.390, EPE: 0.676:  33%|██    | 30/90.0 [00:25<00:45,  1.33it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.390, EPE: 0.676:  33%|██    | 30/90.0 [00:25<00:45,  1.33it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.393, EPE: 0.681:  33%|██    | 30/90.0 [00:26<00:45,  1.33it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.393, EPE: 0.681:  34%|██    | 31/90.0 [00:26<00:44,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.393, EPE: 0.681:  34%|██    | 31/90.0 [00:26<00:44,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.396, EPE: 0.686:  34%|██    | 31/90.0 [00:27<00:44,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.396, EPE: 0.686:  36%|██▏   | 32/90.0 [00:27<00:43,  1.33it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.396, EPE: 0.686:  36%|██▏   | 32/90.0 [00:27<00:43,  1.33it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.399, EPE: 0.692:  36%|██▏   | 32/90.0 [00:28<00:43,  1.33it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.399, EPE: 0.692:  37%|██▏   | 33/90.0 [00:28<00:43,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.399, EPE: 0.692:  37%|██▏   | 33/90.0 [00:28<00:43,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.403, EPE: 0.699:  37%|██▏   | 33/90.0 [00:28<00:43,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.403, EPE: 0.699:  38%|██▎   | 34/90.0 [00:28<00:42,  1.33it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.403, EPE: 0.699:  38%|██▎   | 34/90.0 [00:28<00:42,  1.33it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.407, EPE: 0.705:  38%|██▎   | 34/90.0 [00:29<00:42,  1.33it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.407, EPE: 0.705:  39%|██▎   | 35/90.0 [00:29<00:41,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.407, EPE: 0.705:  39%|██▎   | 35/90.0 [00:29<00:41,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.413, EPE: 0.715:  39%|██▎   | 35/90.0 [00:30<00:41,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.413, EPE: 0.715:  40%|██▍   | 36/90.0 [00:30<00:40,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.413, EPE: 0.715:  40%|██▍   | 36/90.0 [00:30<00:40,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.420, EPE: 0.727:  40%|██▍   | 36/90.0 [00:31<00:40,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.420, EPE: 0.727:  41%|██▍   | 37/90.0 [00:31<00:40,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.420, EPE: 0.727:  41%|██▍   | 37/90.0 [00:31<00:40,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.423, EPE: 0.733:  41%|██▍   | 37/90.0 [00:32<00:40,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.423, EPE: 0.733:  42%|██▌   | 38/90.0 [00:32<00:39,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.423, EPE: 0.733:  42%|██▌   | 38/90.0 [00:32<00:39,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.426, EPE: 0.738:  42%|██▌   | 38/90.0 [00:32<00:39,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.426, EPE: 0.738:  43%|██▌   | 39/90.0 [00:32<00:38,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.426, EPE: 0.738:  43%|██▌   | 39/90.0 [00:32<00:38,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.430, EPE: 0.744:  43%|██▌   | 39/90.0 [00:33<00:38,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.430, EPE: 0.744:  44%|██▋   | 40/90.0 [00:33<00:37,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.430, EPE: 0.744:  44%|██▋   | 40/90.0 [00:33<00:37,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.432, EPE: 0.748:  44%|██▋   | 40/90.0 [00:34<00:37,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.432, EPE: 0.748:  46%|██▋   | 41/90.0 [00:34<00:37,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.432, EPE: 0.748:  46%|██▋   | 41/90.0 [00:34<00:37,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.435, EPE: 0.753:  46%|██▋   | 41/90.0 [00:35<00:37,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.435, EPE: 0.753:  47%|██▊   | 42/90.0 [00:35<00:36,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.435, EPE: 0.753:  47%|██▊   | 42/90.0 [00:35<00:36,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.437, EPE: 0.758:  47%|██▊   | 42/90.0 [00:35<00:36,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.437, EPE: 0.758:  48%|██▊   | 43/90.0 [00:35<00:35,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.437, EPE: 0.758:  48%|██▊   | 43/90.0 [00:35<00:35,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.440, EPE: 0.761:  48%|██▊   | 43/90.0 [00:36<00:35,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.440, EPE: 0.761:  49%|██▉   | 44/90.0 [00:36<00:34,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.440, EPE: 0.761:  49%|██▉   | 44/90.0 [00:36<00:34,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.766:  49%|██▉   | 44/90.0 [00:37<00:34,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.766:  50%|███   | 45/90.0 [00:37<00:34,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.766:  50%|███   | 45/90.0 [00:37<00:34,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  50%|███   | 45/90.0 [00:38<00:34,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  51%|███   | 46/90.0 [00:38<00:33,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  51%|███   | 46/90.0 [00:38<00:33,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  51%|███   | 46/90.0 [00:38<00:33,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  52%|███▏  | 47/90.0 [00:38<00:32,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  52%|███▏  | 47/90.0 [00:38<00:32,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.452, EPE: 0.783:  52%|███▏  | 47/90.0 [00:39<00:32,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.452, EPE: 0.783:  53%|███▏  | 48/90.0 [00:39<00:31,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.452, EPE: 0.783:  53%|███▏  | 48/90.0 [00:39<00:31,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.456, EPE: 0.790:  53%|███▏  | 48/90.0 [00:40<00:31,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.456, EPE: 0.790:  54%|███▎  | 49/90.0 [00:40<00:31,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.456, EPE: 0.790:  54%|███▎  | 49/90.0 [00:40<00:31,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.459, EPE: 0.795:  54%|███▎  | 49/90.0 [00:41<00:31,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.459, EPE: 0.795:  56%|███▎  | 50/90.0 [00:41<00:30,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.459, EPE: 0.795:  56%|███▎  | 50/90.0 [00:41<00:30,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.466, EPE: 0.808:  56%|███▎  | 50/90.0 [00:41<00:30,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.466, EPE: 0.808:  57%|███▍  | 51/90.0 [00:41<00:29,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.466, EPE: 0.808:  57%|███▍  | 51/90.0 [00:41<00:29,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.467, EPE: 0.809:  57%|███▍  | 51/90.0 [00:42<00:29,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.467, EPE: 0.809:  58%|███▍  | 52/90.0 [00:42<00:29,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.467, EPE: 0.809:  58%|███▍  | 52/90.0 [00:42<00:29,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.470, EPE: 0.813:  58%|███▍  | 52/90.0 [00:43<00:29,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.470, EPE: 0.813:  59%|███▌  | 53/90.0 [00:43<00:28,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.470, EPE: 0.813:  59%|███▌  | 53/90.0 [00:43<00:28,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.470, EPE: 0.814:  59%|███▌  | 53/90.0 [00:44<00:28,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.470, EPE: 0.814:  60%|███▌  | 54/90.0 [00:44<00:27,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.470, EPE: 0.814:  60%|███▌  | 54/90.0 [00:44<00:27,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.817:  60%|███▌  | 54/90.0 [00:44<00:27,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.817:  61%|███▋  | 55/90.0 [00:44<00:26,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.817:  61%|███▋  | 55/90.0 [00:44<00:26,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.474, EPE: 0.821:  61%|███▋  | 55/90.0 [00:45<00:26,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.474, EPE: 0.821:  62%|███▋  | 56/90.0 [00:45<00:25,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.474, EPE: 0.821:  62%|███▋  | 56/90.0 [00:45<00:25,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.818:  62%|███▋  | 56/90.0 [00:46<00:25,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.818:  63%|███▊  | 57/90.0 [00:46<00:25,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.818:  63%|███▊  | 57/90.0 [00:46<00:25,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.473, EPE: 0.819:  63%|███▊  | 57/90.0 [00:47<00:25,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.473, EPE: 0.819:  64%|███▊  | 58/90.0 [00:47<00:24,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.473, EPE: 0.819:  64%|███▊  | 58/90.0 [00:47<00:24,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.471, EPE: 0.816:  64%|███▊  | 58/90.0 [00:48<00:24,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.471, EPE: 0.816:  66%|███▉  | 59/90.0 [00:48<00:23,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.471, EPE: 0.816:  66%|███▉  | 59/90.0 [00:48<00:23,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.817:  66%|███▉  | 59/90.0 [00:48<00:23,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.817:  67%|████  | 60/90.0 [00:48<00:22,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.817:  67%|████  | 60/90.0 [00:48<00:22,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.817:  67%|████  | 60/90.0 [00:49<00:22,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.817:  68%|████  | 61/90.0 [00:49<00:22,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.817:  68%|████  | 61/90.0 [00:49<00:22,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.471, EPE: 0.815:  68%|████  | 61/90.0 [00:50<00:22,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.471, EPE: 0.815:  69%|████▏ | 62/90.0 [00:50<00:21,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.471, EPE: 0.815:  69%|████▏ | 62/90.0 [00:50<00:21,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.469, EPE: 0.813:  69%|████▏ | 62/90.0 [00:51<00:21,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.469, EPE: 0.813:  70%|████▏ | 63/90.0 [00:51<00:20,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.469, EPE: 0.813:  70%|████▏ | 63/90.0 [00:51<00:20,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.469, EPE: 0.812:  70%|████▏ | 63/90.0 [00:51<00:20,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.469, EPE: 0.812:  71%|████▎ | 64/90.0 [00:51<00:19,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.469, EPE: 0.812:  71%|████▎ | 64/90.0 [00:51<00:19,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.817:  71%|████▎ | 64/90.0 [00:52<00:19,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.817:  72%|████▎ | 65/90.0 [00:52<00:19,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.472, EPE: 0.817:  72%|████▎ | 65/90.0 [00:52<00:19,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.470, EPE: 0.814:  72%|████▎ | 65/90.0 [00:53<00:19,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.470, EPE: 0.814:  73%|████▍ | 66/90.0 [00:53<00:18,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.470, EPE: 0.814:  73%|████▍ | 66/90.0 [00:53<00:18,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.469, EPE: 0.812:  73%|████▍ | 66/90.0 [00:54<00:18,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.469, EPE: 0.812:  74%|████▍ | 67/90.0 [00:54<00:17,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.469, EPE: 0.812:  74%|████▍ | 67/90.0 [00:54<00:17,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.468, EPE: 0.811:  74%|████▍ | 67/90.0 [00:54<00:17,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.468, EPE: 0.811:  76%|████▌ | 68/90.0 [00:54<00:16,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.468, EPE: 0.811:  76%|████▌ | 68/90.0 [00:54<00:16,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.466, EPE: 0.807:  76%|████▌ | 68/90.0 [00:55<00:16,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.466, EPE: 0.807:  77%|████▌ | 69/90.0 [00:55<00:16,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.466, EPE: 0.807:  77%|████▌ | 69/90.0 [00:55<00:16,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.464, EPE: 0.804:  77%|████▌ | 69/90.0 [00:56<00:16,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.464, EPE: 0.804:  78%|████▋ | 70/90.0 [00:56<00:15,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.464, EPE: 0.804:  78%|████▋ | 70/90.0 [00:56<00:15,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.467, EPE: 0.808:  78%|████▋ | 70/90.0 [00:57<00:15,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.467, EPE: 0.808:  79%|████▋ | 71/90.0 [00:57<00:14,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.467, EPE: 0.808:  79%|████▋ | 71/90.0 [00:57<00:14,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.466, EPE: 0.808:  79%|████▋ | 71/90.0 [00:58<00:14,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.466, EPE: 0.808:  80%|████▊ | 72/90.0 [00:58<00:13,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.466, EPE: 0.808:  80%|████▊ | 72/90.0 [00:58<00:13,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.469, EPE: 0.812:  80%|████▊ | 72/90.0 [00:58<00:13,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.469, EPE: 0.812:  81%|████▊ | 73/90.0 [00:58<00:13,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.469, EPE: 0.812:  81%|████▊ | 73/90.0 [00:58<00:13,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.468, EPE: 0.810:  81%|████▊ | 73/90.0 [00:59<00:13,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.468, EPE: 0.810:  82%|████▉ | 74/90.0 [00:59<00:12,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.468, EPE: 0.810:  82%|████▉ | 74/90.0 [00:59<00:12,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.467, EPE: 0.809:  82%|████▉ | 74/90.0 [01:00<00:12,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.467, EPE: 0.809:  83%|█████ | 75/90.0 [01:00<00:11,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.467, EPE: 0.809:  83%|█████ | 75/90.0 [01:00<00:11,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.466, EPE: 0.807:  83%|█████ | 75/90.0 [01:01<00:11,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.466, EPE: 0.807:  84%|█████ | 76/90.0 [01:01<00:10,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.466, EPE: 0.807:  84%|█████ | 76/90.0 [01:01<00:10,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.464, EPE: 0.803:  84%|█████ | 76/90.0 [01:01<00:10,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.464, EPE: 0.803:  86%|█████▏| 77/90.0 [01:01<00:09,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.464, EPE: 0.803:  86%|█████▏| 77/90.0 [01:01<00:09,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.462, EPE: 0.800:  86%|█████▏| 77/90.0 [01:02<00:09,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.462, EPE: 0.800:  87%|█████▏| 78/90.0 [01:02<00:09,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.462, EPE: 0.800:  87%|█████▏| 78/90.0 [01:02<00:09,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.459, EPE: 0.795:  87%|█████▏| 78/90.0 [01:03<00:09,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.459, EPE: 0.795:  88%|█████▎| 79/90.0 [01:03<00:08,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.459, EPE: 0.795:  88%|█████▎| 79/90.0 [01:03<00:08,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.457, EPE: 0.791:  88%|█████▎| 79/90.0 [01:04<00:08,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.457, EPE: 0.791:  89%|█████▎| 80/90.0 [01:04<00:07,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.457, EPE: 0.791:  89%|█████▎| 80/90.0 [01:04<00:07,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.454, EPE: 0.786:  89%|█████▎| 80/90.0 [01:04<00:07,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.454, EPE: 0.786:  90%|█████▍| 81/90.0 [01:04<00:06,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.454, EPE: 0.786:  90%|█████▍| 81/90.0 [01:04<00:06,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.452, EPE: 0.783:  90%|█████▍| 81/90.0 [01:05<00:06,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.452, EPE: 0.783:  91%|█████▍| 82/90.0 [01:05<00:06,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.452, EPE: 0.783:  91%|█████▍| 82/90.0 [01:05<00:06,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.778:  91%|█████▍| 82/90.0 [01:06<00:06,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.778:  92%|█████▌| 83/90.0 [01:06<00:05,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.778:  92%|█████▌| 83/90.0 [01:06<00:05,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  92%|█████▌| 83/90.0 [01:07<00:05,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  93%|█████▌| 84/90.0 [01:07<00:04,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  93%|█████▌| 84/90.0 [01:07<00:04,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  93%|█████▌| 84/90.0 [01:07<00:04,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  94%|█████▋| 85/90.0 [01:07<00:03,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  94%|█████▋| 85/90.0 [01:07<00:03,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.765:  94%|█████▋| 85/90.0 [01:08<00:03,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.765:  96%|█████▋| 86/90.0 [01:08<00:03,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.765:  96%|█████▋| 86/90.0 [01:08<00:03,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.440, EPE: 0.762:  96%|█████▋| 86/90.0 [01:09<00:03,  1.32it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.440, EPE: 0.762:  97%|█████▊| 87/90.0 [01:09<00:02,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.440, EPE: 0.762:  97%|█████▊| 87/90.0 [01:09<00:02,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.437, EPE: 0.757:  97%|█████▊| 87/90.0 [01:10<00:02,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.437, EPE: 0.757:  98%|█████▊| 88/90.0 [01:10<00:01,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.437, EPE: 0.757:  98%|█████▊| 88/90.0 [01:10<00:01,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.434, EPE: 0.752:  98%|█████▊| 88/90.0 [01:11<00:01,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.434, EPE: 0.752:  99%|█████▉| 89/90.0 [01:11<00:00,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.434, EPE: 0.752:  99%|█████▉| 89/90.0 [01:11<00:00,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.432, EPE: 0.749:  99%|█████▉| 89/90.0 [01:11<00:00,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.432, EPE: 0.749: 100%|██████| 90/90.0 [01:11<00:00,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.432, EPE: 0.749: 100%|██████| 90/90.0 [01:11<00:00,  1.30it/s]\u001b[A\n",
            "Overall Progress: 100%|███████████████████████████████████████████████| 1/1 [01:11<00:00, 71.92s/it]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex7-_aXHaBUm"
      },
      "source": [
        "# Average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWJvO63kaDbM"
      },
      "source": [
        "if running_average == True or no_average_frames != None:\n",
        "  import numpy as np\n",
        "  from pathlib import Path\n",
        "  import os\n",
        "  from utils.flow_utils import writeFlow\n",
        "\n",
        "  def write_frame_ra(flow, i):\n",
        "    dir = \"./Running_Avg_Frames/\" + str(i).zfill(6) + \".flo\"\n",
        "    writeFlow(dir, flow)\n",
        "\n",
        "  def write_frame_avg(flow, i):\n",
        "    dir = \"./Average_Frames/\" + str(i).zfill(6) + \".flo\"\n",
        "    writeFlow(dir, flow)\n",
        "\n",
        "  def average_list(list1):\n",
        "    length_list = len(list1)\n",
        "    temp_addition = 0\n",
        "    for i in range(0, length_list):\n",
        "        temp_addition += list1[i]\n",
        "    temp_val = temp_addition / length_list\n",
        "    return temp_val\n",
        "    # try:\n",
        "    #   return (list1[0] + list1[1]) / 2\n",
        "    # except:\n",
        "    #   print(\"Error in averaging\")\n",
        "\n",
        "  def make_flow(flo):\n",
        "    tag = np.fromfile(flo, np.float32, count=1)[0]\n",
        "    width = np.fromfile(flo, np.int32, count=1)[0]\n",
        "    height = np.fromfile(flo, np.int32, count=1)[0]\n",
        "    nbands = 2\n",
        "    tmp = np.fromfile(flo, np.float32, count= nbands * width * height)\n",
        "    flow = np.resize(tmp, (int(height), int(width), int(nbands)))\n",
        "    return flow\n",
        "\n",
        "  if no_average_frames != None:\n",
        "    flow_list = [None] * no_average_frames\n",
        "    index_flow = 0\n",
        "    index_name = 0\n",
        "\n",
        "  numerator = 0\n",
        "  denominator = 0\n",
        "  index_name = 0\n",
        "\n",
        "  !mkdir ./Running_Avg_Frames\n",
        "  !mkdir ./Average_Frames\n",
        "  dir = './output/inference/run.epoch-0-flow-field/'\n",
        "\n",
        "  for i, flo_file in enumerate(sorted(os.listdir(dir))):\n",
        "    if flo_file[-3:] != \"flo\":\n",
        "      continue\n",
        "\n",
        "    path = Path(dir + flo_file)\n",
        "    with path.open(mode='r') as flo:\n",
        "      final_flo = make_flow(flo) # From their own code\n",
        "\n",
        "      if running_average == True and no_average_frames == None:\n",
        "        # Method 4\n",
        "        if denominator == 0:\n",
        "          numerator += final_flo\n",
        "          denominator = 1\n",
        "        else:\n",
        "          numerator += final_flo\n",
        "          denominator +=1\n",
        "\n",
        "          average_flow = numerator/denominator\n",
        "\n",
        "          write_frame(average_flow, index_name)\n",
        "          index_name += 1\n",
        "          \n",
        "        # os.remove(dir + flo_file)\n",
        "\n",
        "      # Method 3\n",
        "      if running_average == False and no_average_frames != None:\n",
        "        if (index_flow % no_average_frames == 0) and index_flow != 0:\n",
        "          average_flow = average_list(flow_list)\n",
        "          write_frame_ra(average_flow, index_name)\n",
        "          index_flow = 0\n",
        "          index_name += 1\n",
        "\n",
        "        flow_list[index_flow] = final_flo\n",
        "        index_flow += 1\n",
        "\n",
        "        if i == len(os.listdir(dir)) - 1:\n",
        "          average_flow = average_list(flow_list)\n",
        "          write_frame_avg(average_flow, index_name)\n",
        "\n",
        "        os.remove(dir + flo_file)\n",
        "\n",
        "      # Method 1\n",
        "      # if i == 0:\n",
        "      #   flow_list[0] = flow\n",
        "      # else:\n",
        "      #   flow_list[1] = flow\n",
        "      #   average_flow = average_list(flow_list)\n",
        "      #   write_frame(average_flow, i-1)\n",
        "      #   flow_list[0] = average_flow\n",
        "\n",
        "      # Method 2\n",
        "      # if index_flow == 0:\n",
        "      #   flow_list[index_flow] = flow\n",
        "      #   index_flow += 1\n",
        "      # else:\n",
        "      #   flow_list[index_flow] = flow\n",
        "      #   index_flow = 0\n",
        "      #   average_flow = average_list(flow_list)\n",
        "      #   write_frame(average_flow, index_name)\n",
        "      #   index_name += 1\n",
        "\n",
        "      "
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-EUe_yX5wwC"
      },
      "source": [
        "# Visualizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcPNFZh04-YE"
      },
      "source": [
        "## Flowiz technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBogYWu65HQe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f8a315d1-45a8-40f8-eb39-933b11c5bf01"
      },
      "source": [
        "# if visualize == True:\n",
        "\n",
        "#   !python -m flowiz \\\n",
        "#   ./Flo/*.flo \\\n",
        "#   -o FlowFrames \\\n",
        "#   -v FlowVideo \\\n",
        "#   -r 15\n",
        "\n",
        "#   !mv ./FlowVideo/000000.flo.mp4 './FlowVideo/$flow_video_name'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Rendering images [.png] from the flows [.flo]\n",
            "> Created directory: FlowFrames\n",
            "FlowFrames/000122.flo.png: 100% 123/123 [00:41<00:00,  3.00it/s]\n",
            "> Compiling [.mp4] video from the flow images [.png]\n",
            "> Saving video as: FlowVideo/000000.flo.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpdC2-7o-V3p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "812473a5-3776-4fc4-e01e-7f2786c4c0df"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('./FlowVideo/'+flow_video_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ba1299b7-1bb3-4b3d-8c5f-07440bcb6131\", \"2 - Arabic.mp4\", 649374)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBSvCvj5XPMX"
      },
      "source": [
        "## Scipy Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5j8_TkanL0_"
      },
      "source": [
        "### Install scipy as some tensorflow functionality requires updated scipy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb5ZMFHcl_jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "967272bb-c053-4543-afd4-315778516b34"
      },
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "!pip install scipy==1.4.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/29/162476fd44203116e7980cfbd9352eef9db37c49445d1fec35509022f6aa/scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1MB)\n",
            "\u001b[K     |████████████████████████████████| 26.1MB 113kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy==1.4.1) (1.18.5)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.1.0\n",
            "    Uninstalling scipy-1.1.0:\n",
            "      Successfully uninstalled scipy-1.1.0\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihUwCSdnXlge"
      },
      "source": [
        "### Define show_flow() for visualization.\n",
        " Original Source https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGwMS0x0XaJC"
      },
      "source": [
        "# Source:https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "UNKNOWN_FLOW_THRESH = 1e7\n",
        "def show_flow(filename):\n",
        "    \"\"\"\n",
        "    visualize optical flow map using matplotlib\n",
        "    :param filename: optical flow file\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    flow = read_flow(filename)\n",
        "    img = flow_to_image(flow)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "def read_flow(filename):\n",
        "    \"\"\"\n",
        "    read optical flow from Middlebury .flo file\n",
        "    :param filename: name of the flow file\n",
        "    :return: optical flow data in matrix\n",
        "    \"\"\"\n",
        "    f = open(filename, 'rb')\n",
        "    magic = np.fromfile(f, np.float32, count=1)\n",
        "    data2d = None\n",
        "\n",
        "    if 202021.25 != magic:\n",
        "        print ('Magic number incorrect. Invalid .flo file')\n",
        "    else:\n",
        "        w = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "        h = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "        #print(\"Reading %d x %d flo file\" % (h, w))\n",
        "        data2d = np.fromfile(f, np.float32, count=2 * w * h)\n",
        "        # reshape data into 3D array (columns, rows, channels)\n",
        "        data2d = np.resize(data2d, (h, w, 2))\n",
        "    f.close()\n",
        "    return data2d\n",
        "\n",
        "def flow_to_image(flow):\n",
        "    \"\"\"\n",
        "    Convert flow into middlebury color code image\n",
        "    :param flow: optical flow map\n",
        "    :return: optical flow image in middlebury color\n",
        "    \"\"\"\n",
        "    u = flow[:, :, 0]\n",
        "    v = flow[:, :, 1]\n",
        "\n",
        "    maxu = -999.\n",
        "    maxv = -999.\n",
        "    minu = 999.\n",
        "    minv = 999.\n",
        "\n",
        "    idxUnknow = (abs(u) > UNKNOWN_FLOW_THRESH) | (abs(v) > UNKNOWN_FLOW_THRESH)\n",
        "    u[idxUnknow] = 0\n",
        "    v[idxUnknow] = 0\n",
        "\n",
        "    maxu = max(maxu, np.max(u))\n",
        "    minu = min(minu, np.min(u))\n",
        "\n",
        "    maxv = max(maxv, np.max(v))\n",
        "    minv = min(minv, np.min(v))\n",
        "\n",
        "    rad = np.sqrt(u ** 2 + v ** 2)\n",
        "    maxrad = max(-1, np.max(rad))\n",
        "\n",
        "    #print( \"max flow: %.4f\\nflow range:\\nu = %.3f .. %.3f\\nv = %.3f .. %.3f\" % (maxrad, minu,maxu, minv, maxv))\n",
        "\n",
        "    u = u/(maxrad + np.finfo(float).eps)\n",
        "    v = v/(maxrad + np.finfo(float).eps)\n",
        "\n",
        "    img = compute_color(u, v)\n",
        "\n",
        "    idx = np.repeat(idxUnknow[:, :, np.newaxis], 3, axis=2)\n",
        "    img[idx] = 0\n",
        "\n",
        "    return np.uint8(img)\n",
        "\n",
        "\n",
        "def compute_color(u, v):\n",
        "    \"\"\"\n",
        "    compute optical flow color map\n",
        "    :param u: optical flow horizontal map\n",
        "    :param v: optical flow vertical map\n",
        "    :return: optical flow in color code\n",
        "    \"\"\"\n",
        "    [h, w] = u.shape\n",
        "    img = np.zeros([h, w, 3])\n",
        "    nanIdx = np.isnan(u) | np.isnan(v)\n",
        "    u[nanIdx] = 0\n",
        "    v[nanIdx] = 0\n",
        "\n",
        "    colorwheel = make_color_wheel()\n",
        "    ncols = np.size(colorwheel, 0)\n",
        "\n",
        "    rad = np.sqrt(u**2+v**2)\n",
        "\n",
        "    a = np.arctan2(-v, -u) / np.pi\n",
        "\n",
        "    fk = (a+1) / 2 * (ncols - 1) + 1\n",
        "\n",
        "    k0 = np.floor(fk).astype(int)\n",
        "\n",
        "    k1 = k0 + 1\n",
        "    k1[k1 == ncols+1] = 1\n",
        "    f = fk - k0\n",
        "\n",
        "    for i in range(0, np.size(colorwheel,1)):\n",
        "        tmp = colorwheel[:, i]\n",
        "        col0 = tmp[k0-1] / 255\n",
        "        col1 = tmp[k1-1] / 255\n",
        "        col = (1-f) * col0 + f * col1\n",
        "\n",
        "        idx = rad <= 1\n",
        "        col[idx] = 1-rad[idx]*(1-col[idx])\n",
        "        notidx = np.logical_not(idx)\n",
        "\n",
        "        col[notidx] *= 0.75\n",
        "        img[:, :, i] = np.uint8(np.floor(255 * col*(1-nanIdx)))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def make_color_wheel():\n",
        "    \"\"\"\n",
        "    Generate color wheel according Middlebury color code\n",
        "    :return: Color wheel\n",
        "    \"\"\"\n",
        "    RY = 15\n",
        "    YG = 6\n",
        "    GC = 4\n",
        "    CB = 11\n",
        "    BM = 13\n",
        "    MR = 6\n",
        "\n",
        "    ncols = RY + YG + GC + CB + BM + MR\n",
        "\n",
        "    colorwheel = np.zeros([ncols, 3])\n",
        "\n",
        "    col = 0\n",
        "\n",
        "    # RY\n",
        "    colorwheel[0:RY, 0] = 255\n",
        "    colorwheel[0:RY, 1] = np.transpose(np.floor(255*np.arange(0, RY) / RY))\n",
        "    col += RY\n",
        "\n",
        "    # YG\n",
        "    colorwheel[col:col+YG, 0] = 255 - np.transpose(np.floor(255*np.arange(0, YG) / YG))\n",
        "    colorwheel[col:col+YG, 1] = 255\n",
        "    col += YG\n",
        "\n",
        "    # GC\n",
        "    colorwheel[col:col+GC, 1] = 255\n",
        "    colorwheel[col:col+GC, 2] = np.transpose(np.floor(255*np.arange(0, GC) / GC))\n",
        "    col += GC\n",
        "\n",
        "    # CB\n",
        "    colorwheel[col:col+CB, 1] = 255 - np.transpose(np.floor(255*np.arange(0, CB) / CB))\n",
        "    colorwheel[col:col+CB, 2] = 255\n",
        "    col += CB\n",
        "\n",
        "    # BM\n",
        "    colorwheel[col:col+BM, 2] = 255\n",
        "    colorwheel[col:col+BM, 0] = np.transpose(np.floor(255*np.arange(0, BM) / BM))\n",
        "    col += + BM\n",
        "\n",
        "    # MR\n",
        "    colorwheel[col:col+MR, 2] = 255 - np.transpose(np.floor(255 * np.arange(0, MR) / MR))\n",
        "    colorwheel[col:col+MR, 0] = 255\n",
        "\n",
        "    return colorwheel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itvl1OTiYMSd"
      },
      "source": [
        "### Save Flo files as images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YopuaMoJPYnT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "bf7ea469-0cc3-4470-cc46-2ff7bf45a187"
      },
      "source": [
        "import os\n",
        "import PIL.Image\n",
        "def mkdir_ifnotexists(dir):\n",
        "    if os.path.exists(dir):\n",
        "        return\n",
        "    os.mkdir(dir)\n",
        "\n",
        "if no_average_frames != None:\n",
        "  directory = \"./Average_Frames\"\n",
        "\n",
        "elif running_average == True:\n",
        "  directory = \"./Running_Avg_Frames\"\n",
        "\n",
        "else:\n",
        "  directory = '/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/'\n",
        "\n",
        "# flo_pth='/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/'\n",
        "flo_pth = directory\n",
        "flos=[flo_pth + f for f in os.listdir(flo_pth)]\n",
        "mkdir_ifnotexists('./FlowFrames')\n",
        "length = len(flos)\n",
        "for i in range(length):\n",
        "  if flos[i][-3:] == \"flo\":\n",
        "    print(i+1, \"/\", length)\n",
        "    PIL.Image.fromarray(flow_to_image(read_flow(flos[i]))).save('./FlowFrames/'+os.path.basename(flos[i])+'.png')\n",
        "    os.remove(flos[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 / 123\n",
            "2 / 123\n",
            "3 / 123\n",
            "4 / 123\n",
            "5 / 123\n",
            "6 / 123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-65294d55bec9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mflos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"flo\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./FlowFrames/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"eXIf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m     \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"IEND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXBu8wVowcVG"
      },
      "source": [
        "!ls ./FlowFrames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HXMqwKjYT32"
      },
      "source": [
        "### Generate video from Flo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGPockiXSpri"
      },
      "source": [
        "os.system('ffmpeg -r 25 -i FlowFrames/%6d.flo.png -vcodec libx264 -b 10M -y FlowVideo.mp4')\n",
        "\n",
        "print(\"My program took\", time.time() - start_time, \"to run\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWvhMuDdl1GG"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('FlowVideo.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i_mPe1OYoTi"
      },
      "source": [
        "# from IPython.display import HTML\n",
        "# from base64 import b64encode\n",
        "# mp4 = open('FlowVideo.mp4','rb').read()\n",
        "# data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "# HTML(\"\"\"\n",
        "# <video width=400 controls>\n",
        "#       <source src=\"%s\" type=\"video/mp4\">\n",
        "# </video>\n",
        "# \"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}