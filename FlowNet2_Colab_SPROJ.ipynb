{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlowNet2_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JibKh/NVIDIA-FlowNet2-Google-Colab/blob/master/FlowNet2_Colab_SPROJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogNK5nPyLKrB"
      },
      "source": [
        "# Check GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR9h45BnLMst"
      },
      "source": [
        "The GPU must NOT be Tesla K80. If it is then factory reset runtime and try again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6AYibX0sYcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f5fd3b-79eb-49dd-a60e-72df2df819c7"
      },
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "Sat May  8 15:07:45 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78C23XEP2kQv"
      },
      "source": [
        "# User Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9cX_qfLjHsu"
      },
      "source": [
        "# If you have a video put 1. If you have frames put 2.\n",
        "# Based on your choice, update the below cells accordingly\n",
        "video_frames = 1\n",
        "\n",
        "# If you would like to visualize the flow frames. This WILL DELETE ALL THE FLOWFRAMES GENERATED TO SAVE STORAGE.\n",
        "visualize = False "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCEEb0v2wYas"
      },
      "source": [
        "# Video Input\n",
        "\n",
        "if video_frames == 1:\n",
        "\n",
        "  video_name = 'test.mp4' # If you have a video you want to run inference on. Please include .mp4 or whatever extension the video has.\n",
        "  video_local_gdrive = 2 # If you want to upload a video from your local drive, choose 1. If from your google drive, choose 2. If some other option, go to section \"Upload Video\".\n",
        "  \n",
        "  # If your video is on gdrive, please add Gdrive ID here.\n",
        "  if video_local_gdrive == 2:\n",
        "    video_gdrive = '1UcL20kKE5LA_Gn0ybxIYGVbya6NxcirF' # File_id for your google drive video. Use this link to see how to get file ID https://docs.meiro.io/books/meiro-integrations/page/where-can-i-find-the-file-id-on-google-drive#:~:text=To%20locate%20the%20File%20ID,%3D%60%20is%20the%20File%20ID.\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lviH4LCUwWmB"
      },
      "source": [
        "# Frames Input\n",
        "\n",
        "if video_frames == 2:\n",
        "\n",
        "  # Mount Gdrive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  frames_zip_name = \"2 - Arabic.zip\" # If you have the frames, enter its zip file here. For ex: \"3 - Video.zip\"\n",
        "  frames_directory = '../gdrive/My Drive/Hajj Videos/Frames/' # Where the frames are located. If its in gdrive: '../gdrive/My Drive/Location of Zip/' Change the Location of Zip to wherever yours is stored.\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjCyiIBPwhsR"
      },
      "source": [
        "# Skip / Average Options\n",
        "\n",
        "no_frames_skip = 1 # How many frames you want skipped. For eg if its 2 then from frames 1,2,3,4,5,6,7 we take frames 1,4,7. Leave at None to not skip frames.\n",
        "\n",
        "# Only one can work at a time\n",
        "no_average_frames = None # How many frames you want to average. Leave at None if you don't want to avg.\n",
        "running_average = False # If you want to visually see running average"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFhOiS9EvPyJ",
        "outputId": "6f12a66a-0eee-41e3-ebea-48c798c8ffe9"
      },
      "source": [
        "# DO NOT TOUCH\n",
        "\n",
        "flow_video_name = 'flowvid.mp4'\n",
        "\n",
        "# FOR VIDEOS\n",
        "if video_frames == 1:\n",
        "\n",
        "  # This will prompt you to upload the video from your local machine\n",
        "  if video_local_gdrive == 1:\n",
        "\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if video_name != list(uploaded.keys())[0]:\n",
        "      video_name = list(uploaded.keys())[0]\n",
        "\n",
        "  # This downloads the gdrive video\n",
        "  elif video_local_gdrive == 2:\n",
        "\n",
        "    # This will download the video\n",
        "    !gdown --id $video_gdrive\n",
        "\n",
        "# FOR FRAMES\n",
        "if video_frames == 2:\n",
        "  \n",
        "  !mkdir -p ./frames\n",
        "  unzip_file = frames_directory + frames_zip_name\n",
        "  !unzip '$unzip_file' -d ./frames\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UcL20kKE5LA_Gn0ybxIYGVbya6NxcirF\n",
            "To: /content/test.mp4\n",
            "\r0.00B [00:00, ?B/s]\r6.82MB [00:00, 67.1MB/s]\r10.2MB [00:00, 62.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiX1DcSQ2sye"
      },
      "source": [
        "# # THIS WILL DELETE ALL THE FRAMES, FLOW FRAMES, OUTPUT FILES, FLOW VIDEO.\n",
        "# # If you would like to keep something, make sure to comment it out and save it before running this.\n",
        "\n",
        "# # To restart and run again. Change any parameters above and then go click the \"User Input and Restart\" cell. Then Runtime -> Run After.\n",
        "\n",
        "# !rm -r ./frames\n",
        "# !rm -r ./Flo\n",
        "# !rm -r ./FlowFrames\n",
        "# !rm -r ./output\n",
        "# # !rm ./$video_name\n",
        "# !rm -r ./Average_Frames\n",
        "# !rm -r ./Running_Avg_Frames\n",
        "# !rm -r ./FlowVideo\n",
        "# !pip install setproctitle colorama scipy==1.1.0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gE_PzuiNKF4"
      },
      "source": [
        "# Setup Video / Frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ODrjmF5NOC5"
      },
      "source": [
        "## Setup Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFfa5R6tNOC5"
      },
      "source": [
        "Converting video to frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vuJWgkTNOC5"
      },
      "source": [
        "import os\n",
        "\n",
        "if video_frames == 1:\n",
        "  def mkdir_ifnotexists(dir):\n",
        "      if os.path.exists(dir):\n",
        "          return\n",
        "      os.mkdir(dir)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmnYMaDJNODA"
      },
      "source": [
        "if video_frames == 1:\n",
        "  vid_file = video_name\n",
        "  frame_pth = './frames'\n",
        "  mkdir_ifnotexists(frame_pth)\n",
        "  cmd = \"ffmpeg -i %s -start_number 0 -vsync 0 %s/frame_%%06d.png\" % (\n",
        "              vid_file,\n",
        "              frame_pth,\n",
        "          )\n",
        "  os.system(cmd)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr47ObqgrBTE"
      },
      "source": [
        "!rm test.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t60sUMuNRLZ"
      },
      "source": [
        "## Setup Frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZzEI0oeNRLZ"
      },
      "source": [
        "Rename Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTa3YYfiNRLa",
        "outputId": "b4c48c6f-6fab-4604-ba82-42b0d92f81b6"
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6MZlFeuNRLa"
      },
      "source": [
        "if video_frames == 2:\n",
        "  import os\n",
        "\n",
        "  file_dir = \"./frames/\"\n",
        "  for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "    # print(filename)\n",
        "    if filename[-11:] == \"_UTC+01.jpg\":\n",
        "      src = file_dir + filename\n",
        "      dst = file_dir + str(count).zfill(6) + '.png'\n",
        "      os.rename(src, dst)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44Yctdz7NRLb",
        "outputId": "832b0de5-c11b-4a5b-ca89-643aaf05eb47"
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pyBrSUVNRLb"
      },
      "source": [
        "Skip Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enywSfQ6NRLb",
        "outputId": "2a227db3-ae49-45a2-efd1-45653e462465"
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knL6MOOQNRLb"
      },
      "source": [
        "if no_frames_skip != None:\n",
        "  directory = \"./frames\"\n",
        "\n",
        "  temp_skip = no_frames_skip\n",
        "\n",
        "  for i, file in enumerate(sorted(os.listdir(directory))):\n",
        "    if (temp_skip != 0) and (file[-4:] == \".png\"):\n",
        "      os.remove(directory + '/' + file)\n",
        "      temp_skip = temp_skip - 1\n",
        "      continue\n",
        "    temp_skip = no_frames_skip\n",
        "\n",
        "\n",
        "# if no_frames_skip != None:\n",
        "#   directory = './frames'\n",
        "#   # no_frames_skip = 2\n",
        "\n",
        "#   for i, file in enumerate(sorted(os.listdir(directory))):\n",
        "#     if (file[-4:] == \".png\") and (int(file[0:-4]) % no_frames_skip == 0):\n",
        "#       # print(file)\n",
        "#       os.remove(directory+'/' + file)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxY5ICzwNRLb"
      },
      "source": [
        "if no_frames_skip != None:\n",
        "  import os\n",
        "\n",
        "  file_dir = \"./frames/\"\n",
        "  for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "    # print(filename)\n",
        "    if filename[-4:] == \".png\":\n",
        "      src = file_dir + filename\n",
        "      dst = file_dir + str(count).zfill(6) + '.png'\n",
        "      os.rename(src, dst)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQpbfMeRNRLc",
        "outputId": "f1328cad-a09d-4806-b709-4814a065e318"
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUf1OTRXElWr"
      },
      "source": [
        "# NWPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3M14FnKfsHI"
      },
      "source": [
        "## Resized Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcTSrn5hNxCA",
        "outputId": "039927d7-aa04-4842-be05-47ad9f3c5c8a"
      },
      "source": [
        "# FlowNet outputs frames in multiples of 64. So we ensure it matches that for NWPU also.\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "img = Image.open(\"./frames/000000.png\")\n",
        "\n",
        "# New Sizes\n",
        "x = (img.size[0] // 64) * 64\n",
        "y = (img.size[1] // 64) * 64\n",
        "\n",
        "x, y"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1920, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SlK-azbgHVy"
      },
      "source": [
        "dir = \"./frames\"\n",
        "\n",
        "for frame in sorted(os.listdir(dir)):\n",
        "  if frame[-3:] == 'png':\n",
        "\n",
        "    # Open image and resize\n",
        "    image = Image.open(dir + \"/\" + frame)\n",
        "    new_image = image.resize((x, y))\n",
        "\n",
        "    # Remove image and write new one\n",
        "    os.remove(dir + \"/\" + frame)\n",
        "    new_image.save(dir + \"/\" + frame)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8LDp_Ryq8Cm"
      },
      "source": [
        "## Setup text file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svT7wMpoq9tb"
      },
      "source": [
        "f = open(\"./frames/test1.txt\", \"w\")\n",
        "\n",
        "i = 0\n",
        "for frame in sorted(os.listdir(\"./frames\")):\n",
        "\n",
        "  if frame[-3:] == 'png':\n",
        "\n",
        "    if i != 0:\n",
        "      f.write(\"\\n\")\n",
        "      \n",
        "    f.write(frame[:-4])\n",
        "    i += 1\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctFBGklsjl3c"
      },
      "source": [
        "## Import NWPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsKZi0pThUQL",
        "outputId": "ceac26df-b697-40f9-c681-b6f1d06a67c0"
      },
      "source": [
        "!gdown --id '1-QsJ4EHwMBwDRQl7bMeCkI0gvUtM2eGZ'"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-QsJ4EHwMBwDRQl7bMeCkI0gvUtM2eGZ\n",
            "To: /content/NWPU.zip\n",
            "306MB [00:02, 110MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXIG2U6qp7N7",
        "outputId": "c51fc3e5-9bd8-4abb-f8f4-17b7dbbeaed7"
      },
      "source": [
        "!unzip NWPU.zip\n",
        "!rm NWPU.zip"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  NWPU.zip\n",
            "   creating: NWPU-Crowd-Sample-Code/\n",
            "  inflating: NWPU-Crowd-Sample-Code/val.txt  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.gitignore  \n",
            " extracting: NWPU-Crowd-Sample-Code/__init__.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/requirements.txt  \n",
            "  inflating: NWPU-Crowd-Sample-Code/trainer.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/README.md  \n",
            "  inflating: NWPU-Crowd-Sample-Code/LICENSE  \n",
            "  inflating: NWPU-Crowd-Sample-Code/validation.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/CANNet-all_ep_243_mae_93.6_mse_489.9_nae_0.382.pth  \n",
            "  inflating: NWPU-Crowd-Sample-Code/train.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/config.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/MCNN-all_ep_907_mae_218.5_mse_700.6_nae_2.005.pth  \n",
            "  inflating: NWPU-Crowd-Sample-Code/SFCN+-all_ep_321_mae_90.7_mse_487.2_nae_0.375.pth  \n",
            "  inflating: NWPU-Crowd-Sample-Code/model_out.pth  \n",
            "  inflating: NWPU-Crowd-Sample-Code/Video_Maker.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/before_dividing_by_mask.csv  \n",
            "   creating: NWPU-Crowd-Sample-Code/.git/\n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/description  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/packed-refs  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/config  \n",
            " extracting: NWPU-Crowd-Sample-Code/.git/HEAD  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/index  \n",
            "   creating: NWPU-Crowd-Sample-Code/.git/info/\n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/info/exclude  \n",
            "   creating: NWPU-Crowd-Sample-Code/.git/hooks/\n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/hooks/pre-rebase.sample  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/hooks/pre-receive.sample  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/hooks/post-update.sample  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/hooks/pre-push.sample  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/hooks/pre-commit.sample  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/hooks/commit-msg.sample  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/hooks/update.sample  \n",
            "   creating: NWPU-Crowd-Sample-Code/.git/refs/\n",
            "   creating: NWPU-Crowd-Sample-Code/.git/refs/heads/\n",
            " extracting: NWPU-Crowd-Sample-Code/.git/refs/heads/master  \n",
            "   creating: NWPU-Crowd-Sample-Code/.git/refs/remotes/\n",
            "   creating: NWPU-Crowd-Sample-Code/.git/refs/remotes/origin/\n",
            " extracting: NWPU-Crowd-Sample-Code/.git/refs/remotes/origin/HEAD  \n",
            "   creating: NWPU-Crowd-Sample-Code/.git/objects/\n",
            "   creating: NWPU-Crowd-Sample-Code/.git/objects/pack/\n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/objects/pack/pack-e45621db7d2e21e1f9ad7c880f5e76405bebb044.pack  \n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/objects/pack/pack-e45621db7d2e21e1f9ad7c880f5e76405bebb044.idx  \n",
            "   creating: NWPU-Crowd-Sample-Code/.git/logs/\n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/logs/HEAD  \n",
            "   creating: NWPU-Crowd-Sample-Code/.git/logs/refs/\n",
            "   creating: NWPU-Crowd-Sample-Code/.git/logs/refs/heads/\n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/logs/refs/heads/master  \n",
            "   creating: NWPU-Crowd-Sample-Code/.git/logs/refs/remotes/\n",
            "   creating: NWPU-Crowd-Sample-Code/.git/logs/refs/remotes/origin/\n",
            "  inflating: NWPU-Crowd-Sample-Code/.git/logs/refs/remotes/origin/HEAD  \n",
            "   creating: NWPU-Crowd-Sample-Code/models/\n",
            " extracting: NWPU-Crowd-Sample-Code/models/__init__.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/CC.py  \n",
            "   creating: NWPU-Crowd-Sample-Code/models/counters/\n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/CSRNet.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/VGG.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/CANNet.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/MCNN.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__init__.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/Res101_SFCN.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/SCAR.py  \n",
            "   creating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/\n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/MCNN.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/VGG.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/SCAR.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/CSRNet.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/Res101_SFCN.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/MCNN.cpython-37.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/VGG.cpython-37.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/Res101_SFCN.cpython-37.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/CSRNet.cpython-37.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/counters/__pycache__/SCAR.cpython-37.pyc  \n",
            "   creating: NWPU-Crowd-Sample-Code/models/__pycache__/\n",
            "  inflating: NWPU-Crowd-Sample-Code/models/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/__pycache__/CC.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/models/__pycache__/CC.cpython-37.pyc  \n",
            "   creating: NWPU-Crowd-Sample-Code/misc/\n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/layer.py  \n",
            " extracting: NWPU-Crowd-Sample-Code/misc/__init__.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/dot_ops.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/cal_mean.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/utils.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/transforms.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/evaluation_code.py  \n",
            "   creating: NWPU-Crowd-Sample-Code/misc/__pycache__/\n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/__pycache__/transforms.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/__pycache__/dot_ops.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/__pycache__/layer.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/__pycache__/utils.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/__pycache__/transforms.cpython-37.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/__pycache__/layer.cpython-37.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/__pycache__/dot_ops.cpython-37.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/misc/__pycache__/utils.cpython-37.pyc  \n",
            "   creating: NWPU-Crowd-Sample-Code/datasets/\n",
            "  inflating: NWPU-Crowd-Sample-Code/datasets/common.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/datasets/__init__.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/datasets/get_density_map_gaussian.m  \n",
            "  inflating: NWPU-Crowd-Sample-Code/datasets/basedataset.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/datasets/get_dot_map.m  \n",
            "  inflating: NWPU-Crowd-Sample-Code/datasets/preapre_NWPU.m  \n",
            "   creating: NWPU-Crowd-Sample-Code/datasets/setting/\n",
            " extracting: NWPU-Crowd-Sample-Code/datasets/setting/__init__.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/datasets/setting/NWPU.py  \n",
            "   creating: NWPU-Crowd-Sample-Code/datasets/setting/__pycache__/\n",
            "  inflating: NWPU-Crowd-Sample-Code/datasets/setting/__pycache__/NWPU.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/datasets/setting/__pycache__/__init__.cpython-36.pyc  \n",
            "   creating: NWPU-Crowd-Sample-Code/datasets/__pycache__/\n",
            "  inflating: NWPU-Crowd-Sample-Code/datasets/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/datasets/__pycache__/basedataset.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/datasets/__pycache__/common.cpython-36.pyc  \n",
            "   creating: NWPU-Crowd-Sample-Code/.ipynb_checkpoints/\n",
            "   creating: NWPU-Crowd-Sample-Code/saved_exp_para/\n",
            "   creating: NWPU-Crowd-Sample-Code/saved_exp_para/CANNet/\n",
            "  inflating: NWPU-Crowd-Sample-Code/saved_exp_para/CANNet/config.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/saved_exp_para/CANNet/NWPU.py  \n",
            "   creating: NWPU-Crowd-Sample-Code/saved_exp_para/CSRNet/\n",
            "  inflating: NWPU-Crowd-Sample-Code/saved_exp_para/CSRNet/config.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/saved_exp_para/CSRNet/NWPU.py  \n",
            "   creating: NWPU-Crowd-Sample-Code/saved_exp_para/MCNN/\n",
            "  inflating: NWPU-Crowd-Sample-Code/saved_exp_para/MCNN/NWPU.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/saved_exp_para/MCNN/config.py  \n",
            "   creating: NWPU-Crowd-Sample-Code/saved_exp_para/VGG/\n",
            "  inflating: NWPU-Crowd-Sample-Code/saved_exp_para/VGG/NWPU.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/saved_exp_para/VGG/config.py  \n",
            "   creating: NWPU-Crowd-Sample-Code/saved_exp_para/Res_SFCN/\n",
            "  inflating: NWPU-Crowd-Sample-Code/saved_exp_para/Res_SFCN/config.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/saved_exp_para/Res_SFCN/NWPU.py  \n",
            "   creating: NWPU-Crowd-Sample-Code/saved_exp_para/SCAR/\n",
            "  inflating: NWPU-Crowd-Sample-Code/saved_exp_para/SCAR/config.py  \n",
            "  inflating: NWPU-Crowd-Sample-Code/saved_exp_para/SCAR/NWPU.py  \n",
            "   creating: NWPU-Crowd-Sample-Code/sample/\n",
            "  inflating: NWPU-Crowd-Sample-Code/sample/0.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/sample/2.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/sample/1.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/sample/4.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/sample/3.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/sample/5.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/sample/6.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/sample/7.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/sample/8.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/sample/9.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/sample/result.png  \n",
            "   creating: NWPU-Crowd-Sample-Code/test/\n",
            "  inflating: NWPU-Crowd-Sample-Code/test/result.jpg  \n",
            " extracting: NWPU-Crowd-Sample-Code/test/test.txt  \n",
            "   creating: NWPU-Crowd-Sample-Code/test/.ipynb_checkpoints/\n",
            "   creating: NWPU-Crowd-Sample-Code/__pycache__/\n",
            "  inflating: NWPU-Crowd-Sample-Code/__pycache__/trainer.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/__pycache__/config.cpython-36.pyc  \n",
            "  inflating: NWPU-Crowd-Sample-Code/__pycache__/config.cpython-37.pyc  \n",
            "   creating: NWPU-Crowd-Sample-Code/test_data_sample/\n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/0.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/44.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/68.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/194.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/178.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/327.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/312.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/424.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/672.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/694.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/903.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/889.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/871.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/40.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/74.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/182.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/157.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/58_B.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/51_B.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/40_B.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/23_B.jpg  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test_data_sample/test.txt  \n",
            "   creating: NWPU-Crowd-Sample-Code/testing/\n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_55_A.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_54_B.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_43_B.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_39_A.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_12_B.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_8_B.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_174_A.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_141_A.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_108_B.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_128_B.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_88_A.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_87_A.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_69_B.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/testing/IMG_72_B.png  \n",
            "  inflating: NWPU-Crowd-Sample-Code/image_blending.py  \n",
            " extracting: NWPU-Crowd-Sample-Code/data.csv  \n",
            " extracting: NWPU-Crowd-Sample-Code/before_last_for_loop_crop_preds.csv  \n",
            "  inflating: NWPU-Crowd-Sample-Code/test.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtdQClnhu1Cr"
      },
      "source": [
        "## Do NWPU Stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdCjDvbZRDwN",
        "outputId": "cb68469e-17ca-4589-96d5-42aa76a6fbd6"
      },
      "source": [
        "%cd NWPU-Crowd-Sample-Code/\n",
        "!mkdir Final_Results"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/NWPU-Crowd-Sample-Code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ngURUZu22Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102a67b8-dc1f-4724-9523-6fb3e2c7691a"
      },
      "source": [
        "# Edit dataRoot, result_path, model_path, txtpath variables in test.py\n",
        "!python test.py"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n",
            "100% 170M/170M [00:02<00:00, 74.1MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/tensor.py:474: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "predicted count:  32.42654541015625\n",
            "000000 32.4265\n",
            "predicted count:  34.2504931640625\n",
            "000001 34.2505\n",
            "predicted count:  32.3001904296875\n",
            "000002 32.3002\n",
            "predicted count:  21.45480224609375\n",
            "000003 21.4548\n",
            "predicted count:  12.25815185546875\n",
            "000004 12.2582\n",
            "predicted count:  11.36124267578125\n",
            "000005 11.3612\n",
            "predicted count:  10.981556396484375\n",
            "000006 10.9816\n",
            "predicted count:  14.591448974609374\n",
            "000007 14.5914\n",
            "predicted count:  14.314183349609374\n",
            "000008 14.3142\n",
            "predicted count:  13.420162353515625\n",
            "000009 13.4202\n",
            "predicted count:  13.115670166015626\n",
            "000010 13.1157\n",
            "predicted count:  14.35672119140625\n",
            "000011 14.3567\n",
            "predicted count:  12.993096923828125\n",
            "000012 12.9931\n",
            "predicted count:  12.83175537109375\n",
            "000013 12.8318\n",
            "predicted count:  13.64953369140625\n",
            "000014 13.6495\n",
            "predicted count:  21.5364453125\n",
            "000015 21.5364\n",
            "predicted count:  15.841488037109375\n",
            "000016 15.8415\n",
            "predicted count:  15.049046630859374\n",
            "000017 15.0490\n",
            "predicted count:  17.536104736328124\n",
            "000018 17.5361\n",
            "predicted count:  17.300479736328125\n",
            "000019 17.3005\n",
            "predicted count:  19.5941796875\n",
            "000020 19.5942\n",
            "predicted count:  14.068145751953125\n",
            "000021 14.0681\n",
            "predicted count:  18.618671875\n",
            "000022 18.6187\n",
            "predicted count:  24.53746826171875\n",
            "000023 24.5375\n",
            "predicted count:  18.388800048828124\n",
            "000024 18.3888\n",
            "predicted count:  15.06931640625\n",
            "000025 15.0693\n",
            "predicted count:  15.2144677734375\n",
            "000026 15.2145\n",
            "predicted count:  13.786739501953125\n",
            "000027 13.7867\n",
            "predicted count:  13.65735107421875\n",
            "000028 13.6574\n",
            "predicted count:  10.1715673828125\n",
            "000029 10.1716\n",
            "predicted count:  7.934884033203125\n",
            "000030 7.9349\n",
            "predicted count:  6.918006591796875\n",
            "000031 6.9180\n",
            "predicted count:  8.544544067382812\n",
            "000032 8.5445\n",
            "predicted count:  11.50254150390625\n",
            "000033 11.5025\n",
            "predicted count:  6.002862548828125\n",
            "000034 6.0029\n",
            "predicted count:  11.658072509765624\n",
            "000035 11.6581\n",
            "predicted count:  4.831511535644531\n",
            "000036 4.8315\n",
            "predicted count:  9.830668334960938\n",
            "000037 9.8307\n",
            "predicted count:  13.443145751953125\n",
            "000038 13.4431\n",
            "predicted count:  13.206343994140624\n",
            "000039 13.2063\n",
            "predicted count:  16.89891357421875\n",
            "000040 16.8989\n",
            "predicted count:  19.398677978515625\n",
            "000041 19.3987\n",
            "predicted count:  12.424444580078125\n",
            "000042 12.4244\n",
            "predicted count:  7.775975341796875\n",
            "000043 7.7760\n",
            "predicted count:  6.995691528320313\n",
            "000044 6.9957\n",
            "predicted count:  11.702537841796875\n",
            "000045 11.7025\n",
            "predicted count:  14.24474365234375\n",
            "000046 14.2447\n",
            "predicted count:  19.9164111328125\n",
            "000047 19.9164\n",
            "predicted count:  17.709581298828127\n",
            "000048 17.7096\n",
            "predicted count:  17.80156005859375\n",
            "000049 17.8016\n",
            "predicted count:  12.9737744140625\n",
            "000050 12.9738\n",
            "predicted count:  21.408828125\n",
            "000051 21.4088\n",
            "predicted count:  28.2108544921875\n",
            "000052 28.2109\n",
            "predicted count:  35.56116943359375\n",
            "000053 35.5612\n",
            "predicted count:  22.58721435546875\n",
            "000054 22.5872\n",
            "predicted count:  21.2433935546875\n",
            "000055 21.2434\n",
            "predicted count:  29.03725830078125\n",
            "000056 29.0373\n",
            "predicted count:  12.701942138671875\n",
            "000057 12.7019\n",
            "predicted count:  12.66877197265625\n",
            "000058 12.6688\n",
            "predicted count:  16.25608642578125\n",
            "000059 16.2561\n",
            "predicted count:  16.819337158203126\n",
            "000060 16.8193\n",
            "predicted count:  24.8863720703125\n",
            "000061 24.8864\n",
            "predicted count:  26.43263671875\n",
            "000062 26.4326\n",
            "predicted count:  16.28693603515625\n",
            "000063 16.2869\n",
            "predicted count:  17.283013916015626\n",
            "000064 17.2830\n",
            "predicted count:  21.75337646484375\n",
            "000065 21.7534\n",
            "predicted count:  19.57982666015625\n",
            "000066 19.5798\n",
            "predicted count:  13.629669189453125\n",
            "000067 13.6297\n",
            "predicted count:  15.588818359375\n",
            "000068 15.5888\n",
            "predicted count:  9.539742431640626\n",
            "000069 9.5397\n",
            "predicted count:  14.931552734375\n",
            "000070 14.9316\n",
            "predicted count:  20.9392236328125\n",
            "000071 20.9392\n",
            "predicted count:  19.390672607421877\n",
            "000072 19.3907\n",
            "predicted count:  10.303160400390626\n",
            "000073 10.3032\n",
            "predicted count:  11.68951904296875\n",
            "000074 11.6895\n",
            "predicted count:  14.475478515625\n",
            "000075 14.4755\n",
            "predicted count:  19.2993896484375\n",
            "000076 19.2994\n",
            "predicted count:  21.5837158203125\n",
            "000077 21.5837\n",
            "predicted count:  18.21823974609375\n",
            "000078 18.2182\n",
            "predicted count:  23.89376708984375\n",
            "000079 23.8938\n",
            "predicted count:  23.39243408203125\n",
            "000080 23.3924\n",
            "predicted count:  16.606866455078126\n",
            "000081 16.6069\n",
            "predicted count:  15.670706787109374\n",
            "000082 15.6707\n",
            "predicted count:  9.966585693359375\n",
            "000083 9.9666\n",
            "predicted count:  13.59177978515625\n",
            "000084 13.5918\n",
            "predicted count:  23.66936279296875\n",
            "000085 23.6694\n",
            "predicted count:  18.298214111328125\n",
            "000086 18.2982\n",
            "predicted count:  17.3417041015625\n",
            "000087 17.3417\n",
            "predicted count:  21.30126953125\n",
            "000088 21.3013\n",
            "predicted count:  22.461171875\n",
            "000089 22.4612\n",
            "predicted count:  22.62234375\n",
            "000090 22.6223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7rlOWslUMU_",
        "outputId": "acb0bbc9-403f-4654-f128-a1891b3ce912"
      },
      "source": [
        "!mv Final_Results /content/\n",
        "%cd ../\n",
        "!mv Final_Results NWPU_Results\n",
        "!rm -r NWPU-Crowd-Sample-Code\n",
        "!rm /content/frames/test1.txt"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-kuk7gHvBwP"
      },
      "source": [
        "## To Zip NWPU files and then have to get shareable link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUN-ObA5QGcv"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq0SVyVfvDvB"
      },
      "source": [
        "# %cd /content/drive/MyDrive/\n",
        "# !zip -r NWPU.zip './NWPU-Crowd-Sample-Code'\n",
        "# %cd ../../"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh_ui4kmLvBw"
      },
      "source": [
        "# FlowNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OGCfYuDTz7n"
      },
      "source": [
        "## Setup and Install FlowNet2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMRndXGRFDJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12ef0ad-afe3-4d6d-e2dc-7b06cffe7509"
      },
      "source": [
        "!pip install torch==1.0.0 torchvision==0.2.2 -f https://download.pytorch.org/whl/cu100/torch_stable.html\n",
        "!pip install pypng\n",
        "!pip install tensorboardx\n",
        "!pip install setproctitle colorama scipy==1.1.0\n",
        "!pip install flowiz -U"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu100/torch_stable.html\n",
            "Collecting torch==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/3b/0b8de6e654c2983898564226792c6f09d9bcaba97b7b29c40e4ed4ae43ed/torch-1.0.0-cp37-cp37m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K     |████████████████████████████████| 591.8MB 31kB/s \n",
            "\u001b[?25hCollecting torchvision==0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/a1/66d72a2fe580a9f0fcbaaa5b976911fbbde9dce9b330ba12791997b856e9/torchvision-0.2.2-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.2) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.2) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.2.2) (1.19.5)\n",
            "Collecting tqdm==4.19.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/c4/b67cf1ab472b770e08e94105a0c7ca7032cd070627c435f5998c9cf6e64f/tqdm-4.19.9-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.3MB/s \n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.19.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.19.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch, tqdm, torchvision\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.0.0 torchvision-0.2.2 tqdm-4.19.9\n",
            "Collecting pypng\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/fb/f719f1ac965e2101aa6ea6f54ef8b40f8fbb033f6ad07c017663467f5147/pypng-0.0.20.tar.gz (649kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 7.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pypng\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypng: filename=pypng-0.0.20-cp37-none-any.whl size=67163 sha256=565ac5f95302cd78a70af2fde4ac187c1d52d67f5f3d2f636abaf7c1674d466c\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/6b/ef/0493b536b6d4722c2ae9486691b1d49b922b9877922beeabb3\n",
            "Successfully built pypng\n",
            "Installing collected packages: pypng\n",
            "Successfully installed pypng-0.0.20\n",
            "Collecting tensorboardx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardx) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx) (56.1.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx) (1.15.0)\n",
            "Installing collected packages: tensorboardx\n",
            "Successfully installed tensorboardx-2.2\n",
            "Collecting setproctitle\n",
            "  Downloading https://files.pythonhosted.org/packages/97/5c/16a6e69febfbee3f1a1a8c4318d1f054ff4d3ef2a61b233937c316cba06d/setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/de/0c22c6754370ba6b1fa8e53bd6e514d4a41a181125d405a501c215cbdbd6/scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 102kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: setproctitle, colorama, scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed colorama-0.4.4 scipy-1.1.0 setproctitle-1.2.2\n",
            "Collecting flowiz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/f5/7a0edc26cffd1f8a426a8b0c61bce05296136a6c9057347f995e5e27cf13/flowiz-2.3.1-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from flowiz) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from flowiz) (4.19.9)\n",
            "Collecting eel\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/c2/7dc22cc9ea23f0339316d6d249392d3ce67190430f2b05a316f3471ae15d/Eel-0.14.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from flowiz) (3.2.2)\n",
            "Collecting bottle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/44/aeafdd6ca05a8e1c3f91eeeb272a202d5cb1b3b23730a5ca686a81c48d24/bottle-0.12.19-py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.8MB/s \n",
            "\u001b[?25hCollecting bottle-websocket\n",
            "  Downloading https://files.pythonhosted.org/packages/17/8e/a22666b4bb0a6e31de579504077df2b1c2f1438136777c728e6cfabef295/bottle-websocket-0.2.9.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from eel->flowiz) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing in /usr/local/lib/python3.7/dist-packages (from eel->flowiz) (2.4.7)\n",
            "Collecting whichcraft\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/a2/81887a0dae2e4d2adc70d9a3557fdda969f863ced51cd3c47b587d25bce5/whichcraft-0.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flowiz) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flowiz) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flowiz) (1.3.1)\n",
            "Collecting gevent-websocket\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/84/2dc373eb6493e00c884cc11e6c059ec97abae2678d42f06bf780570b0193/gevent_websocket-0.10.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->flowiz) (1.15.0)\n",
            "Collecting gevent\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/85/df3d1fd2b60a87455475f93012861b76a411d27ba4a0859939adbe2c9dc3/gevent-21.1.2-cp37-cp37m-manylinux2010_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: greenlet<2.0,>=0.4.17; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.7/dist-packages (from gevent->gevent-websocket->bottle-websocket->eel->flowiz) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent->gevent-websocket->bottle-websocket->eel->flowiz) (56.1.0)\n",
            "Collecting zope.event\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/85/b45408c64f3b888976f1d5b37eed8d746b8d5729a66a49ec846fda27d371/zope.event-4.5.0-py2.py3-none-any.whl\n",
            "Collecting zope.interface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/a7/94e1a92c71436f934cdd2102826fa041c83dcb7d21dd0f1fb1a57f6e0620/zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 51.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: eel, bottle-websocket\n",
            "  Building wheel for eel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eel: filename=Eel-0.14.0-cp37-none-any.whl size=17462 sha256=fa8e44b7659d77288436edf53524f1763a323c564c2869418a9290b70a3e54c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/a8/f9/0bb7b895584b80f4beabebfb8dcfdb8c7b0db2420b9c2a4821\n",
            "  Building wheel for bottle-websocket (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bottle-websocket: filename=bottle_websocket-0.2.9-cp37-none-any.whl size=2347 sha256=bc8b5d901fc39236f6a6b9841bfdbb8c86ab57c001484aaf8380577ad3730a24\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/fd/80/af47541f053f14f4e5fd5927c91a7615358826429ba036152d\n",
            "Successfully built eel bottle-websocket\n",
            "Installing collected packages: bottle, zope.event, zope.interface, gevent, gevent-websocket, bottle-websocket, whichcraft, eel, flowiz\n",
            "Successfully installed bottle-0.12.19 bottle-websocket-0.2.9 eel-0.14.0 flowiz-2.3.1 gevent-21.1.2 gevent-websocket-0.10.1 whichcraft-0.6.1 zope.event-4.5.0 zope.interface-5.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWy52WXkEX7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21374ba1-f0da-499c-e3eb-c06ca84d8559"
      },
      "source": [
        "import os\n",
        "# get flownet2-pytorch source\n",
        "!git clone https://github.com/NVIDIA/flownet2-pytorch.git\n",
        "!mv /content/flownet2-pytorch /content/flownet2pytorch\n",
        "os.chdir('./flownet2pytorch')\n",
        "# install custom layers\n",
        "!bash install.sh"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'flownet2-pytorch'...\n",
            "remote: Enumerating objects: 557, done.\u001b[K\n",
            "remote: Total 557 (delta 0), reused 0 (delta 0), pack-reused 557\u001b[K\n",
            "Receiving objects: 100% (557/557), 6.28 MiB | 31.99 MiB/s, done.\n",
            "Resolving deltas: 100% (312/312), done.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating correlation_cuda.egg-info\n",
            "writing correlation_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to correlation_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to correlation_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'correlation_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'correlation_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'correlation_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/lib/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c correlation_cuda.cc -o build/temp.linux-x86_64-3.7/correlation_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=correlation_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[Kcorrelation_cuda.cc:1:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include/torch/torch.h:7:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Including torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/lib/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c correlation_cuda_kernel.cu -o build/temp.linux-x86_64-3.7/correlation_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=correlation_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/correlation_cuda.o build/temp.linux-x86_64-3.7/correlation_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/correlation_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/correlation_cuda.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for correlation_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/correlation_cuda.py to correlation_cuda.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying correlation_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.correlation_cuda.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/correlation_cuda-0.0.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing correlation_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.7/site-packages/correlation_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "Extracting correlation_cuda-0.0.0-py3.7-linux-x86_64.egg to /root/.local/lib/python3.7/site-packages\n",
            "Adding correlation-cuda 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/correlation_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for correlation-cuda==0.0.0\n",
            "Finished processing dependencies for correlation-cuda==0.0.0\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating resample2d_cuda.egg-info\n",
            "writing resample2d_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to resample2d_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to resample2d_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'resample2d_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'resample2d_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'resample2d_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/lib/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c resample2d_cuda.cc -o build/temp.linux-x86_64-3.7/resample2d_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=resample2d_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[Kresample2d_cuda.cc:2:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include/torch/torch.h:7:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Including torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/lib/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c resample2d_kernel.cu -o build/temp.linux-x86_64-3.7/resample2d_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=resample2d_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/resample2d_cuda.o build/temp.linux-x86_64-3.7/resample2d_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/resample2d_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/resample2d_cuda.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for resample2d_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resample2d_cuda.py to resample2d_cuda.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.resample2d_cuda.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/resample2d_cuda-0.0.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing resample2d_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.7/site-packages/resample2d_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "Extracting resample2d_cuda-0.0.0-py3.7-linux-x86_64.egg to /root/.local/lib/python3.7/site-packages\n",
            "Adding resample2d-cuda 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/resample2d_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for resample2d-cuda==0.0.0\n",
            "Finished processing dependencies for resample2d-cuda==0.0.0\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating channelnorm_cuda.egg-info\n",
            "writing channelnorm_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to channelnorm_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to channelnorm_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'channelnorm_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'channelnorm_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'channelnorm_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/lib/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c channelnorm_cuda.cc -o build/temp.linux-x86_64-3.7/channelnorm_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=channelnorm_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[Kchannelnorm_cuda.cc:1:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include/torch/torch.h:7:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Including torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/lib/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c channelnorm_kernel.cu -o build/temp.linux-x86_64-3.7/channelnorm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=channelnorm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/channelnorm_cuda.o build/temp.linux-x86_64-3.7/channelnorm_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.7/channelnorm_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/channelnorm_cuda.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for channelnorm_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/channelnorm_cuda.py to channelnorm_cuda.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying channelnorm_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.channelnorm_cuda.cpython-37: module references __file__\n",
            "creating dist\n",
            "creating 'dist/channelnorm_cuda-0.0.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing channelnorm_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.7/site-packages/channelnorm_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "Extracting channelnorm_cuda-0.0.0-py3.7-linux-x86_64.egg to /root/.local/lib/python3.7/site-packages\n",
            "Adding channelnorm-cuda 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.7/site-packages/channelnorm_cuda-0.0.0-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for channelnorm-cuda==0.0.0\n",
            "Finished processing dependencies for channelnorm-cuda==0.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVwu6EIMVj2C"
      },
      "source": [
        "import os\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append( '/root/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tekc8kk_Ehft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61e27256-3206-425c-a223-b9506d13ee86"
      },
      "source": [
        "!python main.py --help"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: main.py [-h] [--start_epoch START_EPOCH] [--total_epochs TOTAL_EPOCHS]\n",
            "               [--batch_size BATCH_SIZE] [--train_n_batches TRAIN_N_BATCHES]\n",
            "               [--crop_size CROP_SIZE [CROP_SIZE ...]]\n",
            "               [--gradient_clip GRADIENT_CLIP]\n",
            "               [--schedule_lr_frequency SCHEDULE_LR_FREQUENCY]\n",
            "               [--schedule_lr_fraction SCHEDULE_LR_FRACTION]\n",
            "               [--rgb_max RGB_MAX] [--number_workers NUMBER_WORKERS]\n",
            "               [--number_gpus NUMBER_GPUS] [--no_cuda] [--seed SEED]\n",
            "               [--name NAME] [--save SAVE]\n",
            "               [--validation_frequency VALIDATION_FREQUENCY]\n",
            "               [--validation_n_batches VALIDATION_N_BATCHES]\n",
            "               [--render_validation] [--inference] [--inference_visualize]\n",
            "               [--inference_size INFERENCE_SIZE [INFERENCE_SIZE ...]]\n",
            "               [--inference_batch_size INFERENCE_BATCH_SIZE]\n",
            "               [--inference_n_batches INFERENCE_N_BATCHES] [--save_flow]\n",
            "               [--resume PATH] [--log_frequency LOG_FREQUENCY]\n",
            "               [--skip_training] [--skip_validation] [--fp16]\n",
            "               [--fp16_scale FP16_SCALE]\n",
            "               [--model {ChannelNorm,FlowNet2,FlowNet2C,FlowNet2CS,FlowNet2CSS,FlowNet2S,FlowNet2SD,Resample2d,tofp16,tofp32}]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --start_epoch START_EPOCH\n",
            "  --total_epochs TOTAL_EPOCHS\n",
            "  --batch_size BATCH_SIZE, -b BATCH_SIZE\n",
            "                        Batch size\n",
            "  --train_n_batches TRAIN_N_BATCHES\n",
            "                        Number of min-batches per epoch. If < 0, it will be\n",
            "                        determined by training_dataloader\n",
            "  --crop_size CROP_SIZE [CROP_SIZE ...]\n",
            "                        Spatial dimension to crop training samples for\n",
            "                        training\n",
            "  --gradient_clip GRADIENT_CLIP\n",
            "  --schedule_lr_frequency SCHEDULE_LR_FREQUENCY\n",
            "                        in number of iterations (0 for no schedule)\n",
            "  --schedule_lr_fraction SCHEDULE_LR_FRACTION\n",
            "  --rgb_max RGB_MAX\n",
            "  --number_workers NUMBER_WORKERS, -nw NUMBER_WORKERS, --num_workers NUMBER_WORKERS\n",
            "  --number_gpus NUMBER_GPUS, -ng NUMBER_GPUS\n",
            "                        number of GPUs to use\n",
            "  --no_cuda\n",
            "  --seed SEED\n",
            "  --name NAME           a name to append to the save directory\n",
            "  --save SAVE, -s SAVE  directory for saving\n",
            "  --validation_frequency VALIDATION_FREQUENCY\n",
            "                        validate every n epochs\n",
            "  --validation_n_batches VALIDATION_N_BATCHES\n",
            "  --render_validation   run inference (save flows to file) and every\n",
            "                        validation_frequency epoch\n",
            "  --inference\n",
            "  --inference_visualize\n",
            "                        visualize the optical flow during inference\n",
            "  --inference_size INFERENCE_SIZE [INFERENCE_SIZE ...]\n",
            "                        spatial size divisible by 64. default (-1,-1) -\n",
            "                        largest possible valid size would be used\n",
            "  --inference_batch_size INFERENCE_BATCH_SIZE\n",
            "  --inference_n_batches INFERENCE_N_BATCHES\n",
            "  --save_flow           save predicted flows to file\n",
            "  --resume PATH         path to latest checkpoint (default: none)\n",
            "  --log_frequency LOG_FREQUENCY, --summ_iter LOG_FREQUENCY\n",
            "                        Log every n batches\n",
            "  --skip_training\n",
            "  --skip_validation\n",
            "  --fp16                Run model in pseudo-fp16 mode (fp16 storage fp32\n",
            "                        math).\n",
            "  --fp16_scale FP16_SCALE\n",
            "                        Loss scaling, positive power of 2 values can improve\n",
            "                        fp16 convergence.\n",
            "\n",
            "Model:\n",
            "  --model {ChannelNorm,FlowNet2,FlowNet2C,FlowNet2CS,FlowNet2CSS,FlowNet2S,FlowNet2SD,Resample2d,tofp16,tofp32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVqbeGLwLGfJ"
      },
      "source": [
        "## Training and Validation - Not tested"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBj_0jWLKci"
      },
      "source": [
        "If you do not want to train your model, you can skip this and move on to inference.\n",
        "\n",
        "The dataset my team used is quite large and we have unlimited storage on OneDrive. So we have mounted OneDrive to read and write data to. <br>\n",
        "To understand how to use it: https://www.youtube.com/watch?v=U6YPgARhRzA&t=255s&ab_channel=BoostUpStation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVqSGUtKLlVA"
      },
      "source": [
        "### OneDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYM_bz-zLbyj"
      },
      "source": [
        "# !wget https://downloads.rclone.org/v1.50.1/rclone-v1.50.1-linux-amd64.deb\n",
        "# !apt install ./rclone-v1.50.1-linux-amd64.deb"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEbqhaQRLiAe"
      },
      "source": [
        "# !rclone config"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DKu50aALjjY"
      },
      "source": [
        "# !sudo mkdir /content/onedrive\n",
        "# !nohup rclone --vfs-cache-mode writes mount onedrive: /content/onedrive &"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phyZO2lSLqla"
      },
      "source": [
        "### Train and Validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y9f7R1gLu3w"
      },
      "source": [
        "# !python main.py --batch_size 8 --model FlowNet2 --loss=L1Loss --optimizer=Adam --optimizer_lr=1e-4 \\\n",
        "# --training_dataset MpiSintelFinal --training_dataset_root /path/to/mpi-sintel/final/dataset  \\\n",
        "# --validation_dataset MpiSintelClean --validation_dataset_root /path/to/mpi-sintel/clean/dataset"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9C7PFQ8U9b6"
      },
      "source": [
        "## Run inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmez3yOUKkQx"
      },
      "source": [
        "Download the checkpoint. <br>\n",
        "If you have your own checkpoint after training, skip this step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePuj4IqqGk_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd93380-8992-4902-9062-d9d768a17c8e"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da',dest_path='./FlowNet2_checkpoint.pth.tar')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da into ./FlowNet2_checkpoint.pth.tar... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZn6AR6VKqMb"
      },
      "source": [
        "Run inference. <br>\n",
        "You can learn more about each command from here: https://towardsdatascience.com/generating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOJoEKsHS1n1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb8c532-b95a-4337-8a34-3a9ca4eb3944"
      },
      "source": [
        "!python main.py --inference --model FlowNet2 --save_flow --save ./output --inference_dataset ImagesFromFolder --inference_dataset_root ../frames/ --resume ./FlowNet2_checkpoint.pth.tar"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing Arguments\n",
            "  [0.028s] \u001b[0mbatch_size: 8\u001b[0m\n",
            "  [0.029s] \u001b[0mcrop_size: [256, 256]\u001b[0m\n",
            "  [0.029s] \u001b[0mfp16: False\u001b[0m\n",
            "  [0.029s] \u001b[0mfp16_scale: 1024.0\u001b[0m\n",
            "  [0.029s] \u001b[0mgradient_clip: None\u001b[0m\n",
            "  [0.029s] \u001b[35minference: True\u001b[0m\n",
            "  [0.029s] \u001b[0minference_batch_size: 1\u001b[0m\n",
            "  [0.029s] \u001b[35minference_dataset: ImagesFromFolder\u001b[0m\n",
            "  [0.029s] \u001b[0minference_dataset_iext: png\u001b[0m\n",
            "  [0.029s] \u001b[0minference_dataset_replicates: 1\u001b[0m\n",
            "  [0.029s] \u001b[35minference_dataset_root: ../frames/\u001b[0m\n",
            "  [0.029s] \u001b[0minference_n_batches: -1\u001b[0m\n",
            "  [0.029s] \u001b[0minference_size: [-1, -1]\u001b[0m\n",
            "  [0.029s] \u001b[0minference_visualize: False\u001b[0m\n",
            "  [0.029s] \u001b[0mlog_frequency: 1\u001b[0m\n",
            "  [0.029s] \u001b[0mloss: L1Loss\u001b[0m\n",
            "  [0.029s] \u001b[0mmodel: FlowNet2\u001b[0m\n",
            "  [0.029s] \u001b[0mmodel_batchNorm: False\u001b[0m\n",
            "  [0.029s] \u001b[0mmodel_div_flow: 20.0\u001b[0m\n",
            "  [0.029s] \u001b[0mname: run\u001b[0m\n",
            "  [0.029s] \u001b[0mno_cuda: False\u001b[0m\n",
            "  [0.029s] \u001b[35mnumber_gpus: 1\u001b[0m\n",
            "  [0.029s] \u001b[0mnumber_workers: 8\u001b[0m\n",
            "  [0.029s] \u001b[0moptimizer: Adam\u001b[0m\n",
            "  [0.029s] \u001b[0moptimizer_amsgrad: False\u001b[0m\n",
            "  [0.029s] \u001b[0moptimizer_betas: (0.9, 0.999)\u001b[0m\n",
            "  [0.029s] \u001b[0moptimizer_eps: 1e-08\u001b[0m\n",
            "  [0.029s] \u001b[0moptimizer_lr: 0.001\u001b[0m\n",
            "  [0.029s] \u001b[0moptimizer_weight_decay: 0\u001b[0m\n",
            "  [0.029s] \u001b[0mrender_validation: False\u001b[0m\n",
            "  [0.029s] \u001b[35mresume: ./FlowNet2_checkpoint.pth.tar\u001b[0m\n",
            "  [0.029s] \u001b[0mrgb_max: 255.0\u001b[0m\n",
            "  [0.029s] \u001b[35msave: ./output\u001b[0m\n",
            "  [0.029s] \u001b[35msave_flow: True\u001b[0m\n",
            "  [0.029s] \u001b[0mschedule_lr_fraction: 10\u001b[0m\n",
            "  [0.029s] \u001b[0mschedule_lr_frequency: 0\u001b[0m\n",
            "  [0.029s] \u001b[0mseed: 1\u001b[0m\n",
            "  [0.029s] \u001b[0mskip_training: False\u001b[0m\n",
            "  [0.029s] \u001b[0mskip_validation: False\u001b[0m\n",
            "  [0.029s] \u001b[0mstart_epoch: 1\u001b[0m\n",
            "  [0.029s] \u001b[0mtotal_epochs: 10000\u001b[0m\n",
            "  [0.029s] \u001b[0mtrain_n_batches: -1\u001b[0m\n",
            "  [0.029s] \u001b[0mtraining_dataset: MpiSintelFinal\u001b[0m\n",
            "  [0.029s] \u001b[0mtraining_dataset_replicates: 1\u001b[0m\n",
            "  [0.029s] \u001b[0mtraining_dataset_root: ./MPI-Sintel/flow/training\u001b[0m\n",
            "  [0.029s] \u001b[0mvalidation_dataset: MpiSintelClean\u001b[0m\n",
            "  [0.029s] \u001b[0mvalidation_dataset_replicates: 1\u001b[0m\n",
            "  [0.029s] \u001b[0mvalidation_dataset_root: ./MPI-Sintel/flow/training\u001b[0m\n",
            "  [0.029s] \u001b[0mvalidation_frequency: 5\u001b[0m\n",
            "  [0.029s] \u001b[0mvalidation_n_batches: -1\u001b[0m\n",
            "  [0.032s] Operation finished\n",
            "\n",
            "Source Code\n",
            "  Current Git Hash: b'2e9e010c98931bc7cef3eb063b195f1e0ab470ba'\n",
            "\n",
            "Initializing Datasets\n",
            "  [0.082s] Inference Dataset: ImagesFromFolder\n",
            "  [0.260s] Inference Input: [3, 2, 1024, 1920]\n",
            "  [0.410s] Inference Targets: [3, 2, 1024, 1920]\n",
            "  [0.411s] Operation finished\n",
            "\n",
            "Building FlowNet2 model\n",
            "  [3.763s] Effective Batch Size: 8\n",
            "  [3.763s] Number of parameters: 162518834\n",
            "  [3.764s] Initializing CUDA\n",
            "  [6.497s] Parallelizing\n",
            "  [6.498s] Loading checkpoint './FlowNet2_checkpoint.pth.tar'\n",
            "  [6.881s] Loaded checkpoint './FlowNet2_checkpoint.pth.tar' (at epoch 0)\n",
            "  [6.881s] Initializing save directory: ./output\n",
            "  [6.884s] Operation finished\n",
            "\n",
            "Initializing Adam Optimizer\n",
            "  [0.001s] amsgrad = False (<class 'bool'>)\n",
            "  [0.001s] weight_decay = 0 (<class 'int'>)\n",
            "  [0.001s] eps = 1e-08 (<class 'float'>)\n",
            "  [0.001s] betas = (0.9, 0.999) (<class 'tuple'>)\n",
            "  [0.001s] lr = 0.001 (<class 'float'>)\n",
            "  [0.001s] Operation finished\n",
            "\n",
            "Overall Progress:   0%|                                                       | 0/1 [00:00<?, ?it/s]\n",
            "Inferencing :   0%|                                                        | 0/90.0 [00:00<?, ?it/s]\u001b[ATHCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=405 error=11 : invalid argument\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "\n",
            "Inference Averages for Epoch 0: L1: 0.024, EPE: 0.042:   0%|               | 0/90.0 [00:05<?, ?it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.024, EPE: 0.042:   1%|       | 1/90.0 [00:05<08:13,  5.55s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.024, EPE: 0.042:   1%|       | 1/90.0 [00:05<08:13,  5.55s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.021, EPE: 0.036:   1%|       | 1/90.0 [00:06<08:13,  5.55s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.021, EPE: 0.036:   2%|▏      | 2/90.0 [00:06<06:01,  4.11s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.021, EPE: 0.036:   2%|▏      | 2/90.0 [00:06<06:01,  4.11s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.023, EPE: 0.039:   2%|▏      | 2/90.0 [00:07<06:01,  4.11s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.023, EPE: 0.039:   3%|▏      | 3/90.0 [00:07<04:31,  3.12s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.023, EPE: 0.039:   3%|▏      | 3/90.0 [00:07<04:31,  3.12s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.050, EPE: 0.086:   3%|▏      | 3/90.0 [00:07<04:31,  3.12s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.050, EPE: 0.086:   4%|▎      | 4/90.0 [00:07<03:27,  2.42s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.050, EPE: 0.086:   4%|▎      | 4/90.0 [00:07<03:27,  2.42s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.048, EPE: 0.084:   4%|▎      | 4/90.0 [00:08<03:27,  2.42s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.048, EPE: 0.084:   6%|▍      | 5/90.0 [00:08<02:43,  1.93s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.048, EPE: 0.084:   6%|▍      | 5/90.0 [00:08<02:43,  1.93s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.053, EPE: 0.092:   6%|▍      | 5/90.0 [00:09<02:43,  1.93s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.053, EPE: 0.092:   7%|▍      | 6/90.0 [00:09<02:13,  1.59s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.053, EPE: 0.092:   7%|▍      | 6/90.0 [00:09<02:13,  1.59s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.059, EPE: 0.102:   7%|▍      | 6/90.0 [00:10<02:13,  1.59s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.059, EPE: 0.102:   8%|▌      | 7/90.0 [00:10<01:52,  1.36s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.059, EPE: 0.102:   8%|▌      | 7/90.0 [00:10<01:52,  1.36s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.067, EPE: 0.116:   8%|▌      | 7/90.0 [00:11<01:52,  1.36s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.067, EPE: 0.116:   9%|▌      | 8/90.0 [00:11<01:36,  1.18s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.067, EPE: 0.116:   9%|▌      | 8/90.0 [00:11<01:36,  1.18s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.079, EPE: 0.137:   9%|▌      | 8/90.0 [00:11<01:36,  1.18s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.079, EPE: 0.137:  10%|▋      | 9/90.0 [00:11<01:26,  1.07s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.079, EPE: 0.137:  10%|▋      | 9/90.0 [00:11<01:26,  1.07s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.088, EPE: 0.153:  10%|▋      | 9/90.0 [00:12<01:26,  1.07s/it]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.088, EPE: 0.153:  11%|▋     | 10/90.0 [00:12<01:18,  1.02it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.088, EPE: 0.153:  11%|▋     | 10/90.0 [00:12<01:18,  1.02it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.104, EPE: 0.179:  11%|▋     | 10/90.0 [00:13<01:18,  1.02it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.104, EPE: 0.179:  12%|▋     | 11/90.0 [00:13<01:13,  1.07it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.104, EPE: 0.179:  12%|▋     | 11/90.0 [00:13<01:13,  1.07it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.115, EPE: 0.199:  12%|▋     | 11/90.0 [00:14<01:13,  1.07it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.115, EPE: 0.199:  13%|▊     | 12/90.0 [00:14<01:08,  1.14it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.115, EPE: 0.199:  13%|▊     | 12/90.0 [00:14<01:08,  1.14it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.127, EPE: 0.220:  13%|▊     | 12/90.0 [00:15<01:08,  1.14it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.127, EPE: 0.220:  14%|▊     | 13/90.0 [00:15<01:06,  1.16it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.127, EPE: 0.220:  14%|▊     | 13/90.0 [00:15<01:06,  1.16it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.145, EPE: 0.252:  14%|▊     | 13/90.0 [00:15<01:06,  1.16it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.145, EPE: 0.252:  16%|▉     | 14/90.0 [00:15<01:03,  1.20it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.145, EPE: 0.252:  16%|▉     | 14/90.0 [00:15<01:03,  1.20it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.166, EPE: 0.287:  16%|▉     | 14/90.0 [00:16<01:03,  1.20it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.166, EPE: 0.287:  17%|█     | 15/90.0 [00:16<01:01,  1.23it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.166, EPE: 0.287:  17%|█     | 15/90.0 [00:16<01:01,  1.23it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.186, EPE: 0.322:  17%|█     | 15/90.0 [00:17<01:01,  1.23it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.186, EPE: 0.322:  18%|█     | 16/90.0 [00:17<00:58,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.186, EPE: 0.322:  18%|█     | 16/90.0 [00:17<00:58,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.202, EPE: 0.349:  18%|█     | 16/90.0 [00:18<00:58,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.202, EPE: 0.349:  19%|█▏    | 17/90.0 [00:18<00:57,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.202, EPE: 0.349:  19%|█▏    | 17/90.0 [00:18<00:57,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.218, EPE: 0.378:  19%|█▏    | 17/90.0 [00:18<00:57,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.218, EPE: 0.378:  20%|█▏    | 18/90.0 [00:18<00:55,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.218, EPE: 0.378:  20%|█▏    | 18/90.0 [00:18<00:55,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.236, EPE: 0.408:  20%|█▏    | 18/90.0 [00:19<00:55,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.236, EPE: 0.408:  21%|█▎    | 19/90.0 [00:19<00:54,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.236, EPE: 0.408:  21%|█▎    | 19/90.0 [00:19<00:54,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.251, EPE: 0.434:  21%|█▎    | 19/90.0 [00:20<00:54,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.251, EPE: 0.434:  22%|█▎    | 20/90.0 [00:20<00:54,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.251, EPE: 0.434:  22%|█▎    | 20/90.0 [00:20<00:54,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.265, EPE: 0.458:  22%|█▎    | 20/90.0 [00:21<00:54,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.265, EPE: 0.458:  23%|█▍    | 21/90.0 [00:21<00:53,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.265, EPE: 0.458:  23%|█▍    | 21/90.0 [00:21<00:53,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.280, EPE: 0.485:  23%|█▍    | 21/90.0 [00:21<00:53,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.280, EPE: 0.485:  24%|█▍    | 22/90.0 [00:21<00:52,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.280, EPE: 0.485:  24%|█▍    | 22/90.0 [00:21<00:52,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.299, EPE: 0.517:  24%|█▍    | 22/90.0 [00:22<00:52,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.299, EPE: 0.517:  26%|█▌    | 23/90.0 [00:22<00:51,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.299, EPE: 0.517:  26%|█▌    | 23/90.0 [00:22<00:51,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.320, EPE: 0.554:  26%|█▌    | 23/90.0 [00:23<00:51,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.320, EPE: 0.554:  27%|█▌    | 24/90.0 [00:23<00:50,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.320, EPE: 0.554:  27%|█▌    | 24/90.0 [00:23<00:50,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.340, EPE: 0.590:  27%|█▌    | 24/90.0 [00:24<00:50,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.340, EPE: 0.590:  28%|█▋    | 25/90.0 [00:24<00:49,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.340, EPE: 0.590:  28%|█▋    | 25/90.0 [00:24<00:49,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.356, EPE: 0.616:  28%|█▋    | 25/90.0 [00:24<00:49,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.356, EPE: 0.616:  29%|█▋    | 26/90.0 [00:24<00:49,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.356, EPE: 0.616:  29%|█▋    | 26/90.0 [00:24<00:49,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.365, EPE: 0.633:  29%|█▋    | 26/90.0 [00:25<00:49,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.365, EPE: 0.633:  30%|█▊    | 27/90.0 [00:25<00:48,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.365, EPE: 0.633:  30%|█▊    | 27/90.0 [00:25<00:48,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.371, EPE: 0.643:  30%|█▊    | 27/90.0 [00:26<00:48,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.371, EPE: 0.643:  31%|█▊    | 28/90.0 [00:26<00:47,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.371, EPE: 0.643:  31%|█▊    | 28/90.0 [00:26<00:47,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.371, EPE: 0.642:  31%|█▊    | 28/90.0 [00:27<00:47,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.371, EPE: 0.642:  32%|█▉    | 29/90.0 [00:27<00:46,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.371, EPE: 0.642:  32%|█▉    | 29/90.0 [00:27<00:46,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.371, EPE: 0.643:  32%|█▉    | 29/90.0 [00:28<00:46,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.371, EPE: 0.643:  33%|██    | 30/90.0 [00:28<00:46,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.371, EPE: 0.643:  33%|██    | 30/90.0 [00:28<00:46,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.374, EPE: 0.648:  33%|██    | 30/90.0 [00:28<00:46,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.374, EPE: 0.648:  34%|██    | 31/90.0 [00:28<00:45,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.374, EPE: 0.648:  34%|██    | 31/90.0 [00:28<00:45,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.376, EPE: 0.652:  34%|██    | 31/90.0 [00:29<00:45,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.376, EPE: 0.652:  36%|██▏   | 32/90.0 [00:29<00:44,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.376, EPE: 0.652:  36%|██▏   | 32/90.0 [00:29<00:44,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.379, EPE: 0.657:  36%|██▏   | 32/90.0 [00:30<00:44,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.379, EPE: 0.657:  37%|██▏   | 33/90.0 [00:30<00:44,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.379, EPE: 0.657:  37%|██▏   | 33/90.0 [00:30<00:44,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.383, EPE: 0.664:  37%|██▏   | 33/90.0 [00:31<00:44,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.383, EPE: 0.664:  38%|██▎   | 34/90.0 [00:31<00:42,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.383, EPE: 0.664:  38%|██▎   | 34/90.0 [00:31<00:42,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.387, EPE: 0.670:  38%|██▎   | 34/90.0 [00:31<00:42,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.387, EPE: 0.670:  39%|██▎   | 35/90.0 [00:31<00:42,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.387, EPE: 0.670:  39%|██▎   | 35/90.0 [00:31<00:42,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.392, EPE: 0.679:  39%|██▎   | 35/90.0 [00:32<00:42,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.392, EPE: 0.679:  40%|██▍   | 36/90.0 [00:32<00:41,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.392, EPE: 0.679:  40%|██▍   | 36/90.0 [00:32<00:41,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.399, EPE: 0.691:  40%|██▍   | 36/90.0 [00:33<00:41,  1.31it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.399, EPE: 0.691:  41%|██▍   | 37/90.0 [00:33<00:41,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.399, EPE: 0.691:  41%|██▍   | 37/90.0 [00:33<00:41,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.402, EPE: 0.696:  41%|██▍   | 37/90.0 [00:34<00:41,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.402, EPE: 0.696:  42%|██▌   | 38/90.0 [00:34<00:40,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.402, EPE: 0.696:  42%|██▌   | 38/90.0 [00:34<00:40,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.404, EPE: 0.700:  42%|██▌   | 38/90.0 [00:35<00:40,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.404, EPE: 0.700:  43%|██▌   | 39/90.0 [00:35<00:39,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.404, EPE: 0.700:  43%|██▌   | 39/90.0 [00:35<00:39,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.408, EPE: 0.707:  43%|██▌   | 39/90.0 [00:35<00:39,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.408, EPE: 0.707:  44%|██▋   | 40/90.0 [00:35<00:38,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.408, EPE: 0.707:  44%|██▋   | 40/90.0 [00:35<00:38,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.410, EPE: 0.711:  44%|██▋   | 40/90.0 [00:36<00:38,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.410, EPE: 0.711:  46%|██▋   | 41/90.0 [00:36<00:38,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.410, EPE: 0.711:  46%|██▋   | 41/90.0 [00:36<00:38,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.413, EPE: 0.715:  46%|██▋   | 41/90.0 [00:37<00:38,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.413, EPE: 0.715:  47%|██▊   | 42/90.0 [00:37<00:37,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.413, EPE: 0.715:  47%|██▊   | 42/90.0 [00:37<00:37,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.415, EPE: 0.718:  47%|██▊   | 42/90.0 [00:38<00:37,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.415, EPE: 0.718:  48%|██▊   | 43/90.0 [00:38<00:37,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.415, EPE: 0.718:  48%|██▊   | 43/90.0 [00:38<00:37,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.416, EPE: 0.721:  48%|██▊   | 43/90.0 [00:38<00:37,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.416, EPE: 0.721:  49%|██▉   | 44/90.0 [00:38<00:36,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.416, EPE: 0.721:  49%|██▉   | 44/90.0 [00:38<00:36,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.419, EPE: 0.725:  49%|██▉   | 44/90.0 [00:39<00:36,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.419, EPE: 0.725:  50%|███   | 45/90.0 [00:39<00:35,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.419, EPE: 0.725:  50%|███   | 45/90.0 [00:39<00:35,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.420, EPE: 0.728:  50%|███   | 45/90.0 [00:40<00:35,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.420, EPE: 0.728:  51%|███   | 46/90.0 [00:40<00:34,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.420, EPE: 0.728:  51%|███   | 46/90.0 [00:40<00:34,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.423, EPE: 0.734:  51%|███   | 46/90.0 [00:41<00:34,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.423, EPE: 0.734:  52%|███▏  | 47/90.0 [00:41<00:33,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.423, EPE: 0.734:  52%|███▏  | 47/90.0 [00:41<00:33,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.428, EPE: 0.742:  52%|███▏  | 47/90.0 [00:42<00:33,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.428, EPE: 0.742:  53%|███▏  | 48/90.0 [00:42<00:32,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.428, EPE: 0.742:  53%|███▏  | 48/90.0 [00:42<00:32,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.433, EPE: 0.749:  53%|███▏  | 48/90.0 [00:42<00:32,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.433, EPE: 0.749:  54%|███▎  | 49/90.0 [00:42<00:32,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.433, EPE: 0.749:  54%|███▎  | 49/90.0 [00:42<00:32,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.436, EPE: 0.754:  54%|███▎  | 49/90.0 [00:43<00:32,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.436, EPE: 0.754:  56%|███▎  | 50/90.0 [00:43<00:31,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.436, EPE: 0.754:  56%|███▎  | 50/90.0 [00:43<00:31,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.440, EPE: 0.762:  56%|███▎  | 50/90.0 [00:44<00:31,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.440, EPE: 0.762:  57%|███▍  | 51/90.0 [00:44<00:30,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.440, EPE: 0.762:  57%|███▍  | 51/90.0 [00:44<00:30,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.766:  57%|███▍  | 51/90.0 [00:45<00:30,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.766:  58%|███▍  | 52/90.0 [00:45<00:29,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.766:  58%|███▍  | 52/90.0 [00:45<00:29,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.770:  58%|███▍  | 52/90.0 [00:45<00:29,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.770:  59%|███▌  | 53/90.0 [00:45<00:28,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.770:  59%|███▌  | 53/90.0 [00:45<00:28,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.445, EPE: 0.770:  59%|███▌  | 53/90.0 [00:46<00:28,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.445, EPE: 0.770:  60%|███▌  | 54/90.0 [00:46<00:28,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.445, EPE: 0.770:  60%|███▌  | 54/90.0 [00:46<00:28,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.775:  60%|███▌  | 54/90.0 [00:47<00:28,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.775:  61%|███▋  | 55/90.0 [00:47<00:27,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.775:  61%|███▋  | 55/90.0 [00:47<00:27,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.450, EPE: 0.779:  61%|███▋  | 55/90.0 [00:48<00:27,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.450, EPE: 0.779:  62%|███▋  | 56/90.0 [00:48<00:26,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.450, EPE: 0.779:  62%|███▋  | 56/90.0 [00:48<00:26,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.777:  62%|███▋  | 56/90.0 [00:49<00:26,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.777:  63%|███▊  | 57/90.0 [00:49<00:25,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.777:  63%|███▊  | 57/90.0 [00:49<00:25,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.778:  63%|███▊  | 57/90.0 [00:49<00:25,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.778:  64%|███▊  | 58/90.0 [00:49<00:24,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.778:  64%|███▊  | 58/90.0 [00:49<00:24,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.448, EPE: 0.776:  64%|███▊  | 58/90.0 [00:50<00:24,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.448, EPE: 0.776:  66%|███▉  | 59/90.0 [00:50<00:24,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.448, EPE: 0.776:  66%|███▉  | 59/90.0 [00:50<00:24,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.448, EPE: 0.777:  66%|███▉  | 59/90.0 [00:51<00:24,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.448, EPE: 0.777:  67%|████  | 60/90.0 [00:51<00:23,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.448, EPE: 0.777:  67%|████  | 60/90.0 [00:51<00:23,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.777:  67%|████  | 60/90.0 [00:52<00:23,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.777:  68%|████  | 61/90.0 [00:52<00:23,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.777:  68%|████  | 61/90.0 [00:52<00:23,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.775:  68%|████  | 61/90.0 [00:53<00:23,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.775:  69%|████▏ | 62/90.0 [00:53<00:22,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.775:  69%|████▏ | 62/90.0 [00:53<00:22,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  69%|████▏ | 62/90.0 [00:53<00:22,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  70%|████▏ | 63/90.0 [00:53<00:21,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  70%|████▏ | 63/90.0 [00:53<00:21,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.446, EPE: 0.773:  70%|████▏ | 63/90.0 [00:54<00:21,  1.26it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.446, EPE: 0.773:  71%|████▎ | 64/90.0 [00:54<00:20,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.446, EPE: 0.773:  71%|████▎ | 64/90.0 [00:54<00:20,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.779:  71%|████▎ | 64/90.0 [00:55<00:20,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.779:  72%|████▎ | 65/90.0 [00:55<00:19,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.449, EPE: 0.779:  72%|████▎ | 65/90.0 [00:55<00:19,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.775:  72%|████▎ | 65/90.0 [00:56<00:19,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.775:  73%|████▍ | 66/90.0 [00:56<00:18,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.775:  73%|████▍ | 66/90.0 [00:56<00:18,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  73%|████▍ | 66/90.0 [00:56<00:18,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  74%|████▍ | 67/90.0 [00:56<00:18,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  74%|████▍ | 67/90.0 [00:56<00:18,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.446, EPE: 0.772:  74%|████▍ | 67/90.0 [00:57<00:18,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.446, EPE: 0.772:  76%|████▌ | 68/90.0 [00:57<00:17,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.446, EPE: 0.772:  76%|████▌ | 68/90.0 [00:57<00:17,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  76%|████▌ | 68/90.0 [00:58<00:17,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  77%|████▌ | 69/90.0 [00:58<00:16,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  77%|████▌ | 69/90.0 [00:58<00:16,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.766:  77%|████▌ | 69/90.0 [00:59<00:16,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.766:  78%|████▋ | 70/90.0 [00:59<00:15,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.766:  78%|████▋ | 70/90.0 [00:59<00:15,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.770:  78%|████▋ | 70/90.0 [01:00<00:15,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.770:  79%|████▋ | 71/90.0 [01:00<00:14,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.770:  79%|████▋ | 71/90.0 [01:00<00:14,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  79%|████▋ | 71/90.0 [01:00<00:14,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  80%|████▊ | 72/90.0 [01:00<00:14,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  80%|████▊ | 72/90.0 [01:00<00:14,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  80%|████▊ | 72/90.0 [01:01<00:14,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  81%|████▊ | 73/90.0 [01:01<00:13,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.447, EPE: 0.774:  81%|████▊ | 73/90.0 [01:01<00:13,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.446, EPE: 0.773:  81%|████▊ | 73/90.0 [01:02<00:13,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.446, EPE: 0.773:  82%|████▉ | 74/90.0 [01:02<00:12,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.446, EPE: 0.773:  82%|████▉ | 74/90.0 [01:02<00:12,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.445, EPE: 0.771:  82%|████▉ | 74/90.0 [01:03<00:12,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.445, EPE: 0.771:  83%|█████ | 75/90.0 [01:03<00:11,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.445, EPE: 0.771:  83%|█████ | 75/90.0 [01:03<00:11,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  83%|█████ | 75/90.0 [01:03<00:11,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  84%|█████ | 76/90.0 [01:03<00:10,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.444, EPE: 0.769:  84%|█████ | 76/90.0 [01:03<00:10,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.766:  84%|█████ | 76/90.0 [01:04<00:10,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.766:  86%|█████▏| 77/90.0 [01:04<00:10,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.442, EPE: 0.766:  86%|█████▏| 77/90.0 [01:04<00:10,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.440, EPE: 0.763:  86%|█████▏| 77/90.0 [01:05<00:10,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.440, EPE: 0.763:  87%|█████▏| 78/90.0 [01:05<00:09,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.440, EPE: 0.763:  87%|█████▏| 78/90.0 [01:05<00:09,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.438, EPE: 0.759:  87%|█████▏| 78/90.0 [01:06<00:09,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.438, EPE: 0.759:  88%|█████▎| 79/90.0 [01:06<00:08,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.438, EPE: 0.759:  88%|█████▎| 79/90.0 [01:06<00:08,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.436, EPE: 0.754:  88%|█████▎| 79/90.0 [01:07<00:08,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.436, EPE: 0.754:  89%|█████▎| 80/90.0 [01:07<00:07,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.436, EPE: 0.754:  89%|█████▎| 80/90.0 [01:07<00:07,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.433, EPE: 0.750:  89%|█████▎| 80/90.0 [01:07<00:07,  1.30it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.433, EPE: 0.750:  90%|█████▍| 81/90.0 [01:07<00:07,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.433, EPE: 0.750:  90%|█████▍| 81/90.0 [01:07<00:07,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.431, EPE: 0.746:  90%|█████▍| 81/90.0 [01:08<00:07,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.431, EPE: 0.746:  91%|█████▍| 82/90.0 [01:08<00:06,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.431, EPE: 0.746:  91%|█████▍| 82/90.0 [01:08<00:06,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.428, EPE: 0.741:  91%|█████▍| 82/90.0 [01:09<00:06,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.428, EPE: 0.741:  92%|█████▌| 83/90.0 [01:09<00:05,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.428, EPE: 0.741:  92%|█████▌| 83/90.0 [01:09<00:05,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.426, EPE: 0.738:  92%|█████▌| 83/90.0 [01:10<00:05,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.426, EPE: 0.738:  93%|█████▌| 84/90.0 [01:10<00:04,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.426, EPE: 0.738:  93%|█████▌| 84/90.0 [01:10<00:04,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.423, EPE: 0.733:  93%|█████▌| 84/90.0 [01:10<00:04,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.423, EPE: 0.733:  94%|█████▋| 85/90.0 [01:10<00:03,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.423, EPE: 0.733:  94%|█████▋| 85/90.0 [01:10<00:03,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.421, EPE: 0.729:  94%|█████▋| 85/90.0 [01:11<00:03,  1.27it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.421, EPE: 0.729:  96%|█████▋| 86/90.0 [01:11<00:03,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.421, EPE: 0.729:  96%|█████▋| 86/90.0 [01:11<00:03,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.419, EPE: 0.725:  96%|█████▋| 86/90.0 [01:12<00:03,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.419, EPE: 0.725:  97%|█████▊| 87/90.0 [01:12<00:02,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.419, EPE: 0.725:  97%|█████▊| 87/90.0 [01:12<00:02,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.416, EPE: 0.721:  97%|█████▊| 87/90.0 [01:13<00:02,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.416, EPE: 0.721:  98%|█████▊| 88/90.0 [01:13<00:01,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.416, EPE: 0.721:  98%|█████▊| 88/90.0 [01:13<00:01,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.414, EPE: 0.717:  98%|█████▊| 88/90.0 [01:14<00:01,  1.29it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.414, EPE: 0.717:  99%|█████▉| 89/90.0 [01:14<00:00,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.414, EPE: 0.717:  99%|█████▉| 89/90.0 [01:14<00:00,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.412, EPE: 0.713:  99%|█████▉| 89/90.0 [01:14<00:00,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.412, EPE: 0.713: 100%|██████| 90/90.0 [01:14<00:00,  1.28it/s]\u001b[A\n",
            "Inference Averages for Epoch 0: L1: 0.412, EPE: 0.713: 100%|██████| 90/90.0 [01:14<00:00,  1.28it/s]\u001b[A\n",
            "Overall Progress: 100%|███████████████████████████████████████████████| 1/1 [01:15<00:00, 75.04s/it]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex7-_aXHaBUm"
      },
      "source": [
        "## Average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWJvO63kaDbM"
      },
      "source": [
        "if running_average == True or no_average_frames != None:\n",
        "  import numpy as np\n",
        "  from pathlib import Path\n",
        "  import os\n",
        "  from utils.flow_utils import writeFlow\n",
        "\n",
        "  def write_frame_ra(flow, i):\n",
        "    dir = \"./Running_Avg_Frames/\" + str(i).zfill(6) + \".flo\"\n",
        "    writeFlow(dir, flow)\n",
        "\n",
        "  def write_frame_avg(flow, i):\n",
        "    dir = \"./Average_Frames/\" + str(i).zfill(6) + \".flo\"\n",
        "    writeFlow(dir, flow)\n",
        "\n",
        "  def average_list(list1):\n",
        "    length_list = len(list1)\n",
        "    temp_addition = 0\n",
        "    for i in range(0, length_list):\n",
        "        temp_addition += list1[i]\n",
        "    temp_val = temp_addition / length_list\n",
        "    return temp_val\n",
        "    # try:\n",
        "    #   return (list1[0] + list1[1]) / 2\n",
        "    # except:\n",
        "    #   print(\"Error in averaging\")\n",
        "\n",
        "  def make_flow(flo):\n",
        "    tag = np.fromfile(flo, np.float32, count=1)[0]\n",
        "    width = np.fromfile(flo, np.int32, count=1)[0]\n",
        "    height = np.fromfile(flo, np.int32, count=1)[0]\n",
        "    nbands = 2\n",
        "    tmp = np.fromfile(flo, np.float32, count= nbands * width * height)\n",
        "    flow = np.resize(tmp, (int(height), int(width), int(nbands)))\n",
        "    return flow\n",
        "\n",
        "  if no_average_frames != None:\n",
        "    flow_list = [None] * no_average_frames\n",
        "    index_flow = 0\n",
        "    index_name = 0\n",
        "\n",
        "  numerator = 0\n",
        "  denominator = 0\n",
        "  index_name = 0\n",
        "\n",
        "  !mkdir ./Running_Avg_Frames\n",
        "  !mkdir ./Average_Frames\n",
        "  dir = './output/inference/run.epoch-0-flow-field/'\n",
        "\n",
        "  for i, flo_file in enumerate(sorted(os.listdir(dir))):\n",
        "    if flo_file[-3:] != \"flo\":\n",
        "      continue\n",
        "\n",
        "    path = Path(dir + flo_file)\n",
        "    with path.open(mode='r') as flo:\n",
        "      final_flo = make_flow(flo) # From their own code\n",
        "\n",
        "      if running_average == True and no_average_frames == None:\n",
        "        # Method 4\n",
        "        if denominator == 0:\n",
        "          numerator += final_flo\n",
        "          denominator = 1\n",
        "        else:\n",
        "          numerator += final_flo\n",
        "          denominator +=1\n",
        "\n",
        "          average_flow = numerator/denominator\n",
        "\n",
        "          write_frame(average_flow, index_name)\n",
        "          index_name += 1\n",
        "          \n",
        "        # os.remove(dir + flo_file)\n",
        "\n",
        "      # Method 3\n",
        "      if running_average == False and no_average_frames != None:\n",
        "        if (index_flow % no_average_frames == 0) and index_flow != 0:\n",
        "          average_flow = average_list(flow_list)\n",
        "          write_frame_ra(average_flow, index_name)\n",
        "          index_flow = 0\n",
        "          index_name += 1\n",
        "\n",
        "        flow_list[index_flow] = final_flo\n",
        "        index_flow += 1\n",
        "\n",
        "        if i == len(os.listdir(dir)) - 1:\n",
        "          average_flow = average_list(flow_list)\n",
        "          write_frame_avg(average_flow, index_name)\n",
        "\n",
        "        os.remove(dir + flo_file)\n",
        "\n",
        "      # Method 1\n",
        "      # if i == 0:\n",
        "      #   flow_list[0] = flow\n",
        "      # else:\n",
        "      #   flow_list[1] = flow\n",
        "      #   average_flow = average_list(flow_list)\n",
        "      #   write_frame(average_flow, i-1)\n",
        "      #   flow_list[0] = average_flow\n",
        "\n",
        "      # Method 2\n",
        "      # if index_flow == 0:\n",
        "      #   flow_list[index_flow] = flow\n",
        "      #   index_flow += 1\n",
        "      # else:\n",
        "      #   flow_list[index_flow] = flow\n",
        "      #   index_flow = 0\n",
        "      #   average_flow = average_list(flow_list)\n",
        "      #   write_frame(average_flow, index_name)\n",
        "      #   index_name += 1\n",
        "\n",
        "      "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-EUe_yX5wwC"
      },
      "source": [
        "## Visualizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcPNFZh04-YE"
      },
      "source": [
        "### Flowiz technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBogYWu65HQe"
      },
      "source": [
        "# if visualize == True:\n",
        "\n",
        "#   !python -m flowiz \\\n",
        "#   ./Flo/*.flo \\\n",
        "#   -o FlowFrames \\\n",
        "#   -v FlowVideo \\\n",
        "#   -r 15\n",
        "\n",
        "#   !mv ./FlowVideo/000000.flo.mp4 './FlowVideo/$flow_video_name'"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpdC2-7o-V3p"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('./FlowVideo/'+flow_video_name)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBSvCvj5XPMX"
      },
      "source": [
        "### Scipy Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5j8_TkanL0_"
      },
      "source": [
        "Install scipy as some tensorflow functionality requires updated scipy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb5ZMFHcl_jw"
      },
      "source": [
        "if visualize == True:\n",
        "  import time\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  !pip install scipy==1.4.1"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihUwCSdnXlge"
      },
      "source": [
        "Define show_flow() for visualization.\n",
        " Original Source https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGwMS0x0XaJC"
      },
      "source": [
        "# Source:https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "UNKNOWN_FLOW_THRESH = 1e7\n",
        "def show_flow(filename):\n",
        "    \"\"\"\n",
        "    visualize optical flow map using matplotlib\n",
        "    :param filename: optical flow file\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    flow = read_flow(filename)\n",
        "    img = flow_to_image(flow)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "def read_flow(filename):\n",
        "    \"\"\"\n",
        "    read optical flow from Middlebury .flo file\n",
        "    :param filename: name of the flow file\n",
        "    :return: optical flow data in matrix\n",
        "    \"\"\"\n",
        "    f = open(filename, 'rb')\n",
        "    magic = np.fromfile(f, np.float32, count=1)\n",
        "    data2d = None\n",
        "\n",
        "    if 202021.25 != magic:\n",
        "        print ('Magic number incorrect. Invalid .flo file')\n",
        "    else:\n",
        "        w = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "        h = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "        #print(\"Reading %d x %d flo file\" % (h, w))\n",
        "        data2d = np.fromfile(f, np.float32, count=2 * w * h)\n",
        "        # reshape data into 3D array (columns, rows, channels)\n",
        "        data2d = np.resize(data2d, (h, w, 2))\n",
        "    f.close()\n",
        "    return data2d\n",
        "\n",
        "def flow_to_image(flow):\n",
        "    \"\"\"\n",
        "    Convert flow into middlebury color code image\n",
        "    :param flow: optical flow map\n",
        "    :return: optical flow image in middlebury color\n",
        "    \"\"\"\n",
        "    u = flow[:, :, 0]\n",
        "    v = flow[:, :, 1]\n",
        "\n",
        "    maxu = -999.\n",
        "    maxv = -999.\n",
        "    minu = 999.\n",
        "    minv = 999.\n",
        "\n",
        "    idxUnknow = (abs(u) > UNKNOWN_FLOW_THRESH) | (abs(v) > UNKNOWN_FLOW_THRESH)\n",
        "    u[idxUnknow] = 0\n",
        "    v[idxUnknow] = 0\n",
        "\n",
        "    maxu = max(maxu, np.max(u))\n",
        "    minu = min(minu, np.min(u))\n",
        "\n",
        "    maxv = max(maxv, np.max(v))\n",
        "    minv = min(minv, np.min(v))\n",
        "\n",
        "    rad = np.sqrt(u ** 2 + v ** 2)\n",
        "    maxrad = max(-1, np.max(rad))\n",
        "\n",
        "    #print( \"max flow: %.4f\\nflow range:\\nu = %.3f .. %.3f\\nv = %.3f .. %.3f\" % (maxrad, minu,maxu, minv, maxv))\n",
        "\n",
        "    u = u/(maxrad + np.finfo(float).eps)\n",
        "    v = v/(maxrad + np.finfo(float).eps)\n",
        "\n",
        "    img = compute_color(u, v)\n",
        "\n",
        "    idx = np.repeat(idxUnknow[:, :, np.newaxis], 3, axis=2)\n",
        "    img[idx] = 0\n",
        "\n",
        "    return np.uint8(img)\n",
        "\n",
        "\n",
        "def compute_color(u, v):\n",
        "    \"\"\"\n",
        "    compute optical flow color map\n",
        "    :param u: optical flow horizontal map\n",
        "    :param v: optical flow vertical map\n",
        "    :return: optical flow in color code\n",
        "    \"\"\"\n",
        "    [h, w] = u.shape\n",
        "    img = np.zeros([h, w, 3])\n",
        "    nanIdx = np.isnan(u) | np.isnan(v)\n",
        "    u[nanIdx] = 0\n",
        "    v[nanIdx] = 0\n",
        "\n",
        "    colorwheel = make_color_wheel()\n",
        "    ncols = np.size(colorwheel, 0)\n",
        "\n",
        "    rad = np.sqrt(u**2+v**2)\n",
        "\n",
        "    a = np.arctan2(-v, -u) / np.pi\n",
        "\n",
        "    fk = (a+1) / 2 * (ncols - 1) + 1\n",
        "\n",
        "    k0 = np.floor(fk).astype(int)\n",
        "\n",
        "    k1 = k0 + 1\n",
        "    k1[k1 == ncols+1] = 1\n",
        "    f = fk - k0\n",
        "\n",
        "    for i in range(0, np.size(colorwheel,1)):\n",
        "        tmp = colorwheel[:, i]\n",
        "        col0 = tmp[k0-1] / 255\n",
        "        col1 = tmp[k1-1] / 255\n",
        "        col = (1-f) * col0 + f * col1\n",
        "\n",
        "        idx = rad <= 1\n",
        "        col[idx] = 1-rad[idx]*(1-col[idx])\n",
        "        notidx = np.logical_not(idx)\n",
        "\n",
        "        col[notidx] *= 0.75\n",
        "        img[:, :, i] = np.uint8(np.floor(255 * col*(1-nanIdx)))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def make_color_wheel():\n",
        "    \"\"\"\n",
        "    Generate color wheel according Middlebury color code\n",
        "    :return: Color wheel\n",
        "    \"\"\"\n",
        "    RY = 15\n",
        "    YG = 6\n",
        "    GC = 4\n",
        "    CB = 11\n",
        "    BM = 13\n",
        "    MR = 6\n",
        "\n",
        "    ncols = RY + YG + GC + CB + BM + MR\n",
        "\n",
        "    colorwheel = np.zeros([ncols, 3])\n",
        "\n",
        "    col = 0\n",
        "\n",
        "    # RY\n",
        "    colorwheel[0:RY, 0] = 255\n",
        "    colorwheel[0:RY, 1] = np.transpose(np.floor(255*np.arange(0, RY) / RY))\n",
        "    col += RY\n",
        "\n",
        "    # YG\n",
        "    colorwheel[col:col+YG, 0] = 255 - np.transpose(np.floor(255*np.arange(0, YG) / YG))\n",
        "    colorwheel[col:col+YG, 1] = 255\n",
        "    col += YG\n",
        "\n",
        "    # GC\n",
        "    colorwheel[col:col+GC, 1] = 255\n",
        "    colorwheel[col:col+GC, 2] = np.transpose(np.floor(255*np.arange(0, GC) / GC))\n",
        "    col += GC\n",
        "\n",
        "    # CB\n",
        "    colorwheel[col:col+CB, 1] = 255 - np.transpose(np.floor(255*np.arange(0, CB) / CB))\n",
        "    colorwheel[col:col+CB, 2] = 255\n",
        "    col += CB\n",
        "\n",
        "    # BM\n",
        "    colorwheel[col:col+BM, 2] = 255\n",
        "    colorwheel[col:col+BM, 0] = np.transpose(np.floor(255*np.arange(0, BM) / BM))\n",
        "    col += + BM\n",
        "\n",
        "    # MR\n",
        "    colorwheel[col:col+MR, 2] = 255 - np.transpose(np.floor(255 * np.arange(0, MR) / MR))\n",
        "    colorwheel[col:col+MR, 0] = 255\n",
        "\n",
        "    return colorwheel"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itvl1OTiYMSd"
      },
      "source": [
        "Save Flo files as images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YopuaMoJPYnT"
      },
      "source": [
        "if visualize == True:\n",
        "\n",
        "  import os\n",
        "  import PIL.Image\n",
        "  def mkdir_ifnotexists(dir):\n",
        "      if os.path.exists(dir):\n",
        "          return\n",
        "      os.mkdir(dir)\n",
        "\n",
        "  if no_average_frames != None:\n",
        "    directory = \"./Average_Frames\"\n",
        "\n",
        "  elif running_average == True:\n",
        "    directory = \"./Running_Avg_Frames\"\n",
        "\n",
        "  else:\n",
        "    directory = '/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/'\n",
        "\n",
        "  # flo_pth='/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/'\n",
        "  flo_pth = directory\n",
        "  flos=[flo_pth + f for f in os.listdir(flo_pth)]\n",
        "  mkdir_ifnotexists('./FlowFrames')\n",
        "  length = len(flos)\n",
        "  for i in range(length):\n",
        "    if flos[i][-3:] == \"flo\":\n",
        "      print(i+1, \"/\", length)\n",
        "      PIL.Image.fromarray(flow_to_image(read_flow(flos[i]))).save('./FlowFrames/'+os.path.basename(flos[i])+'.png')\n",
        "      os.remove(flos[i])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HXMqwKjYT32"
      },
      "source": [
        "Generate video from Flo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGPockiXSpri"
      },
      "source": [
        "if visualize == True:\n",
        "  os.system('ffmpeg -r 25 -i FlowFrames/%6d.flo.png -vcodec libx264 -b 10M -y FlowVideo.mp4')\n",
        "\n",
        "  print(\"My program took\", time.time() - start_time, \"to run\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWvhMuDdl1GG"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('FlowVideo.mp4')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i_mPe1OYoTi"
      },
      "source": [
        "if visualize == True:\n",
        "\n",
        "  from IPython.display import HTML\n",
        "  from base64 import b64encode\n",
        "  mp4 = open('FlowVideo.mp4','rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  HTML(\"\"\"\n",
        "  <video width=400 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\" % data_url)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1owR4iebzvF"
      },
      "source": [
        "# Head Coordinates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHVMGwXicsdc",
        "outputId": "83c3d4c6-555a-49e1-e744-018081ce817a"
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "frames = []\n",
        "dir = 'NWPU_Results/'\n",
        "\n",
        "for file in sorted(os.listdir('./NWPU_Results')):\n",
        "  if file[-3:] == 'csv':\n",
        "    frames.append(dir + file)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni8lheCUb1Y9",
        "outputId": "f48c69a3-c848-4890-8aa3-034574a3f245"
      },
      "source": [
        "# Import\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "f = open(\"temp.txt\", 'w')\n",
        "\n",
        "# Set Values\n",
        "threshold = 0.5 * (10**(-1))\n",
        "weight = 2\n",
        "\n",
        "for i, frame in enumerate(frames[1:]):\n",
        "    print(i, \" / \", len(frames)-1)\n",
        "\n",
        "    # Get Excel Sheet\n",
        "    X = np.genfromtxt(frame, delimiter=',')\n",
        "\n",
        "    points_val = X\n",
        "\n",
        "    print(X.shape)\n",
        "\n",
        "    # First value is always nan for some reason\n",
        "    X[0][0] = 0\n",
        "\n",
        "    # Total Value\n",
        "    total_val = np.sum(X)\n",
        "    number_people = int(round(np.sum(X)/100))\n",
        "    print(\"Number of people:\", number_people)\n",
        "\n",
        "    vals = X[X[:,:] > threshold] # Contains the values. 1D array\n",
        "\n",
        "    index = np.argwhere(points_val > threshold) # Contains the index. 2D array.\n",
        "\n",
        "    # Making a 2D Array with point, val -> (x, y, val)\n",
        "    list_for_cluster = [] # Contains a 2D array with point, val\n",
        "\n",
        "    for i, point in enumerate(index):\n",
        "        val = vals[i]\n",
        "        list_for_cluster.append(np.append(point, val))\n",
        "\n",
        "    final_list = np.array(list_for_cluster) # Contains a 2D array with point, val -> (x, y, val)\n",
        "    final_list.shape\n",
        "\n",
        "    x_index = index[:,0]\n",
        "    y_index = index[:,1]\n",
        "\n",
        "    cluster_vals = index\n",
        "\n",
        "    weights = vals ** weight\n",
        "\n",
        "    # Cluster based on K Means Clustering\n",
        "    # Forcefully put how many ever people we found, make that many clusters\n",
        "\n",
        "    kmeans = KMeans(\n",
        "        init=\"random\",\n",
        "        n_clusters=number_people,\n",
        "        n_init=10,\n",
        "        max_iter=500,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    kmeans.fit(cluster_vals, sample_weight = weights)\n",
        "\n",
        "    kmeans.inertia_\n",
        "    kmeans.cluster_centers_\n",
        "    kmeans.n_iter_\n",
        "    y_kmeans = kmeans.predict(cluster_vals)\n",
        "\n",
        "    centers = kmeans.cluster_centers_\n",
        "\n",
        "    # Write to cords.txt\n",
        "    line = \"\"\n",
        "    for center in centers:\n",
        "        line += str(int(center[1])) + \" \" + str(int(center[0])) + \" \"\n",
        "\n",
        "    line = line.strip()\n",
        "    line += \"\\n \"\n",
        "\n",
        "    f.write(line)\n",
        "\n",
        "f.close()\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 34\n",
            "1  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 32\n",
            "2  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "3  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "4  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 11\n",
            "5  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 11\n",
            "6  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "7  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "8  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "9  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "10  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "11  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "12  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "13  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "14  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 22\n",
            "15  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "16  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "17  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "18  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "19  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 20\n",
            "20  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "21  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 19\n",
            "22  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 25\n",
            "23  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "24  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "25  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "26  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "27  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "28  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "29  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 8\n",
            "30  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 7\n",
            "31  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 9\n",
            "32  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "33  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 6\n",
            "34  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "35  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 5\n",
            "36  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "37  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "38  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "39  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "40  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 19\n",
            "41  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "42  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 8\n",
            "43  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 7\n",
            "44  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "45  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "46  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 20\n",
            "47  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "48  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "49  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "50  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "51  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 28\n",
            "52  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 36\n",
            "53  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 23\n",
            "54  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "55  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 29\n",
            "56  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "57  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "58  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "59  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "60  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 25\n",
            "61  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 26\n",
            "62  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "63  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "64  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 22\n",
            "65  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 20\n",
            "66  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "67  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "68  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "69  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "70  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "71  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 19\n",
            "72  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "73  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "74  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "75  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 19\n",
            "76  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 22\n",
            "77  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "78  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 24\n",
            "79  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 23\n",
            "80  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "81  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "82  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "83  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "84  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 24\n",
            "85  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "86  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "87  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "88  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 22\n",
            "89  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6P-9seb5HAW"
      },
      "source": [
        "cords = open(\"cords.txt\", 'w')\n",
        "temp = open(\"temp.txt\", 'r')\n",
        "temp_lines = temp.read().split(\"\\n\")\n",
        "\n",
        "for i, line in enumerate(temp_lines):\n",
        "  fline = line.strip()\n",
        "  if i != len(temp_lines) - 1:\n",
        "    fline += \"\\n\"\n",
        "  cords.write(fline)\n",
        "\n",
        "cords.close()\n",
        "temp.close()"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPnauiE5sNLV"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4AwX9BZmv36"
      },
      "source": [
        "## Manual Annotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oKtWXy6m1nQ"
      },
      "source": [
        "\n",
        "\n",
        "1.   Take any frame from the folder frames. RENAME it to 'image.png'\n",
        "2.   Run the file \"annotate.py\" from the github folder\n",
        "3.   Paste the output text file \"text_speed.txt\" in the same folder as the \"cords.txt\". This is the /content/ directory\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWeidUMPnl43"
      },
      "source": [
        "HOW TO RUN ANNOTATE.PY\n",
        "\n",
        "0.   Keep the annotate.py and the first frame in the same directory and run 'python annotate.py'\n",
        "1.   Annotate the first and second x meters\n",
        "2.   Annotate the road in a clockwise fashion starting from where you marked the first x meters\n",
        "3.   Fil these variables:\n",
        "\n",
        "  *   temp_approx_meters_p1 = 0.5 # How many meters the first x meters represents\n",
        "  *   temp_approx_meters_p2 = 0.5 # How many meters the second y meters represents\n",
        "  *   normalize_meters = 1 # If you want the output to be represented in some other amount of meters, do that here. For eg. if you have annotated first point as 0.5m and second as 1m and want the output to be catered to by 1m, then make this 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pewBZr7pmyGH",
        "outputId": "ed8ed95a-2b76-47cb-b57a-105f405469e1"
      },
      "source": [
        "# Setup\n",
        "!mkdir Clustering\n",
        "\n",
        "!mv cords.txt text_speed.txt Clustering\n",
        "\n",
        "%cd Clustering\n",
        "\n",
        "!mkdir text_files\n",
        "!mkdir output_frames\n",
        "\n",
        "!mv cords.txt text_speed.txt text_files"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'text_speed.txt': No such file or directory\n",
            "/content/Clustering\n",
            "mv: cannot stat 'text_speed.txt': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVKQ6WDAsU0w"
      },
      "source": [
        "## Cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTp34fkdsOjq",
        "outputId": "641de1f5-ceb1-4684-abbc-84269350d8ad"
      },
      "source": [
        "!git clone https://github.com/JibKh/NVIDIA-FlowNet2-Google-Colab.git"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NVIDIA-FlowNet2-Google-Colab'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 107 (delta 49), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (107/107), 48.13 MiB | 12.88 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjRiYwsysr5v",
        "outputId": "2bbb85df-40d2-4c41-c6fe-3e2584c7b75f"
      },
      "source": [
        "%cd NVIDIA-FlowNet2-Google-Colab/\n",
        "!mv cluster.py /content/Clustering\n",
        "%cd ..\n",
        "!rm -r NVIDIA-FlowNet2-Google-Colab/"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Clustering/NVIDIA-FlowNet2-Google-Colab\n",
            "/content/Clustering\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE54AYiy2UFw"
      },
      "source": [
        "# Have to remove first frame and rename\n",
        "# !rm /content/frames/000000.png\n",
        "\n",
        "\n",
        "file_dir = \"/content/frames/\"\n",
        "i = 0\n",
        "for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "  # print(filename)\n",
        "  if filename[-3:] == \"png\":\n",
        "    src = file_dir + filename\n",
        "    dst = file_dir + str(i).zfill(6) + '.png'\n",
        "    os.rename(src, dst)\n",
        "    i += 1\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr2YuBcptXPZ",
        "outputId": "e58f0dca-3d0f-4147-b344-fbebc8566841"
      },
      "source": [
        "!python cluster.py"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"cluster.py\", line 496, in <module>\n",
            "    main()\n",
            "  File \"cluster.py\", line 486, in main\n",
            "    points_labels, velocity_labels, speed_labels, average_speed, total_average_speed = cluster_2()\n",
            "  File \"cluster.py\", line 262, in cluster_2\n",
            "    total_total += total_average_speed\n",
            "NameError: name 'total_total' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FzQbslOva0s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}