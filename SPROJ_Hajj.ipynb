{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlowNet2_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JibKh/SPROJ-Hajj/blob/master/SPROJ_Hajj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogNK5nPyLKrB"
      },
      "source": [
        "# Check GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR9h45BnLMst"
      },
      "source": [
        "The GPU must NOT be Tesla K80. If it is then factory reset runtime and try again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6AYibX0sYcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773cf235-ecf4-4216-8563-b6ad48b7ab8d"
      },
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "Mon May 10 09:50:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78C23XEP2kQv"
      },
      "source": [
        "# User Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9cX_qfLjHsu"
      },
      "source": [
        "# If you have a video put 1. If you have frames put 2.\n",
        "# Based on your choice, update the below cells accordingly\n",
        "video_frames = 1\n",
        "\n",
        "# If you would like to visualize the flow frames. This WILL DELETE ALL THE FLOWFRAMES GENERATED TO SAVE STORAGE.\n",
        "visualize = False "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCEEb0v2wYas"
      },
      "source": [
        "# Video Input\n",
        "\n",
        "if video_frames == 1:\n",
        "\n",
        "  video_name = 'test2.mp4' # If you have a video you want to run inference on. Please include .mp4 or whatever extension the video has.\n",
        "  video_local_gdrive = 2 # If you want to upload a video from your local drive, choose 1. If from your google drive, choose 2. If some other option, go to section \"Upload Video\".\n",
        "  \n",
        "  # If your video is on gdrive, please add Gdrive ID here.\n",
        "  if video_local_gdrive == 2:\n",
        "    video_gdrive = '1lT1MDLqteLpRld10q2cWhdf3Erzrj9O9' # File_id for your google drive video. Use this link to see how to get file ID https://docs.meiro.io/books/meiro-integrations/page/where-can-i-find-the-file-id-on-google-drive#:~:text=To%20locate%20the%20File%20ID,%3D%60%20is%20the%20File%20ID.\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lviH4LCUwWmB"
      },
      "source": [
        "# Frames Input\n",
        "\n",
        "if video_frames == 2:\n",
        "\n",
        "  # Mount Gdrive\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  frames_zip_name = \"2 - Arabic.zip\" # If you have the frames, enter its zip file here. For ex: \"3 - Video.zip\"\n",
        "  frames_directory = '../gdrive/My Drive/Hajj Videos/Frames/' # Where the frames are located. If its in gdrive: '../gdrive/My Drive/Location of Zip/' Change the Location of Zip to wherever yours is stored.\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjCyiIBPwhsR"
      },
      "source": [
        "# Skip / Average Options\n",
        "\n",
        "no_frames_skip = 1 # How many frames you want skipped. For eg if its 2 then from frames 1,2,3,4,5,6,7 we take frames 1,4,7. Leave at None to not skip frames.\n",
        "\n",
        "# Only one can work at a time\n",
        "no_average_frames = None # How many frames you want to average. Leave at None if you don't want to avg.\n",
        "running_average = False # If you want to visually see running average"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFhOiS9EvPyJ",
        "outputId": "55205c0d-fdb8-4e4b-e694-53538812eaa8"
      },
      "source": [
        "# DO NOT TOUCH\n",
        "\n",
        "flow_video_name = 'flowvid.mp4'\n",
        "\n",
        "# FOR VIDEOS\n",
        "if video_frames == 1:\n",
        "\n",
        "  # This will prompt you to upload the video from your local machine\n",
        "  if video_local_gdrive == 1:\n",
        "\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if video_name != list(uploaded.keys())[0]:\n",
        "      video_name = list(uploaded.keys())[0]\n",
        "\n",
        "  # This downloads the gdrive video\n",
        "  elif video_local_gdrive == 2:\n",
        "\n",
        "    # This will download the video\n",
        "    !gdown --id $video_gdrive\n",
        "\n",
        "# FOR FRAMES\n",
        "if video_frames == 2:\n",
        "  \n",
        "  !mkdir -p ./frames\n",
        "  unzip_file = frames_directory + frames_zip_name\n",
        "  !unzip '$unzip_file' -d ./frames\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lT1MDLqteLpRld10q2cWhdf3Erzrj9O9\n",
            "To: /content/test2.mp4\n",
            "9.70MB [00:00, 18.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiX1DcSQ2sye"
      },
      "source": [
        "# # THIS WILL DELETE ALL THE FRAMES, FLOW FRAMES, OUTPUT FILES, FLOW VIDEO.\n",
        "# # If you would like to keep something, make sure to comment it out and save it before running this.\n",
        "\n",
        "# # To restart and run again. Change any parameters above and then go click the \"User Input and Restart\" cell. Then Runtime -> Run After.\n",
        "\n",
        "# !rm -r ./frames\n",
        "# !rm -r ./Flo\n",
        "# !rm -r ./FlowFrames\n",
        "# !rm -r ./output\n",
        "# # !rm ./$video_name\n",
        "# !rm -r ./Average_Frames\n",
        "# !rm -r ./Running_Avg_Frames\n",
        "# !rm -r ./FlowVideo\n",
        "# !pip install setproctitle colorama scipy==1.1.0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gE_PzuiNKF4"
      },
      "source": [
        "# Setup Video / Frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ODrjmF5NOC5"
      },
      "source": [
        "## Setup Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFfa5R6tNOC5"
      },
      "source": [
        "Converting video to frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vuJWgkTNOC5"
      },
      "source": [
        "import os\n",
        "\n",
        "if video_frames == 1:\n",
        "  def mkdir_ifnotexists(dir):\n",
        "      if os.path.exists(dir):\n",
        "          return\n",
        "      os.mkdir(dir)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmnYMaDJNODA"
      },
      "source": [
        "if video_frames == 1:\n",
        "  vid_file = video_name\n",
        "  frame_pth = './frames'\n",
        "  mkdir_ifnotexists(frame_pth)\n",
        "  cmd = \"ffmpeg -i %s -start_number 0 -vsync 0 %s/frame_%%06d.png\" % (\n",
        "              vid_file,\n",
        "              frame_pth,\n",
        "          )\n",
        "  os.system(cmd)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr47ObqgrBTE",
        "outputId": "9b112766-899a-404d-a19e-0b17775b768c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm test.mp4"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'test.mp4': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t60sUMuNRLZ"
      },
      "source": [
        "## Setup Frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZzEI0oeNRLZ"
      },
      "source": [
        "Rename Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTa3YYfiNRLa",
        "outputId": "3e16ad3b-dd05-4b8d-c57b-d371d6298ad3"
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6MZlFeuNRLa"
      },
      "source": [
        "if video_frames == 2:\n",
        "  import os\n",
        "\n",
        "  file_dir = \"./frames/\"\n",
        "  for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "    # print(filename)\n",
        "    if filename[-11:] == \"_UTC+01.jpg\":\n",
        "      src = file_dir + filename\n",
        "      dst = file_dir + str(count).zfill(6) + '.png'\n",
        "      os.rename(src, dst)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44Yctdz7NRLb",
        "outputId": "3ebe1001-49c0-49c1-b295-61d2bd98c393"
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pyBrSUVNRLb"
      },
      "source": [
        "Skip Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enywSfQ6NRLb",
        "outputId": "304e4c63-cb1d-4179-db51-9dd0a6ea9028"
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knL6MOOQNRLb"
      },
      "source": [
        "if no_frames_skip != None:\n",
        "  directory = \"./frames\"\n",
        "\n",
        "  temp_skip = no_frames_skip\n",
        "\n",
        "  for i, file in enumerate(sorted(os.listdir(directory))):\n",
        "    if (temp_skip != 0) and (file[-4:] == \".png\"):\n",
        "      os.remove(directory + '/' + file)\n",
        "      temp_skip = temp_skip - 1\n",
        "      continue\n",
        "    temp_skip = no_frames_skip\n",
        "\n",
        "\n",
        "# if no_frames_skip != None:\n",
        "#   directory = './frames'\n",
        "#   # no_frames_skip = 2\n",
        "\n",
        "#   for i, file in enumerate(sorted(os.listdir(directory))):\n",
        "#     if (file[-4:] == \".png\") and (int(file[0:-4]) % no_frames_skip == 0):\n",
        "#       # print(file)\n",
        "#       os.remove(directory+'/' + file)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxY5ICzwNRLb"
      },
      "source": [
        "if no_frames_skip != None:\n",
        "  import os\n",
        "\n",
        "  file_dir = \"./frames/\"\n",
        "  for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "    # print(filename)\n",
        "    if filename[-4:] == \".png\":\n",
        "      src = file_dir + filename\n",
        "      dst = file_dir + str(count).zfill(6) + '.png'\n",
        "      os.rename(src, dst)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQpbfMeRNRLc",
        "outputId": "4f8625ea-a2a6-4154-fed4-861c67990184"
      },
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUf1OTRXElWr"
      },
      "source": [
        "# NWPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3M14FnKfsHI"
      },
      "source": [
        "## Resized Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcTSrn5hNxCA",
        "outputId": "423bd7eb-45d8-437e-b6ef-c1c6acbaa0a8"
      },
      "source": [
        "# FlowNet outputs frames in multiples of 64. So we ensure it matches that for NWPU also.\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "img = Image.open(\"./frames/000000.png\")\n",
        "\n",
        "# New Sizes\n",
        "x = (img.size[0] // 64) * 64\n",
        "y = (img.size[1] // 64) * 64\n",
        "\n",
        "x, y"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280, 704)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SlK-azbgHVy"
      },
      "source": [
        "dir = \"./frames\"\n",
        "\n",
        "for frame in sorted(os.listdir(dir)):\n",
        "  if frame[-3:] == 'png':\n",
        "\n",
        "    # Open image and resize\n",
        "    image = Image.open(dir + \"/\" + frame)\n",
        "    new_image = image.resize((x, y))\n",
        "\n",
        "    # Remove image and write new one\n",
        "    os.remove(dir + \"/\" + frame)\n",
        "    new_image.save(dir + \"/\" + frame)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8LDp_Ryq8Cm"
      },
      "source": [
        "## Setup text file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svT7wMpoq9tb"
      },
      "source": [
        "f = open(\"./frames/test1.txt\", \"w\")\n",
        "\n",
        "i = 0\n",
        "for frame in sorted(os.listdir(\"./frames\")):\n",
        "\n",
        "  if frame[-3:] == 'png':\n",
        "\n",
        "    if i != 0:\n",
        "      f.write(\"\\n\")\n",
        "      \n",
        "    f.write(frame[:-4])\n",
        "    i += 1\n",
        "\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctFBGklsjl3c"
      },
      "source": [
        "## Import NWPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsKZi0pThUQL"
      },
      "source": [
        "!gdown --id '1-QsJ4EHwMBwDRQl7bMeCkI0gvUtM2eGZ'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXIG2U6qp7N7"
      },
      "source": [
        "!unzip NWPU.zip\n",
        "!rm NWPU.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtdQClnhu1Cr"
      },
      "source": [
        "## Do NWPU Stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdCjDvbZRDwN"
      },
      "source": [
        "%cd NWPU-Crowd-Sample-Code/\n",
        "!mkdir Final_Results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ngURUZu22Q"
      },
      "source": [
        "# Edit dataRoot, result_path, model_path, txtpath variables in test.py\n",
        "!python test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7rlOWslUMU_"
      },
      "source": [
        "!mv Final_Results /content/\n",
        "%cd ../\n",
        "!mv Final_Results NWPU_Results\n",
        "!rm -r NWPU-Crowd-Sample-Code\n",
        "!rm /content/frames/test1.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-kuk7gHvBwP"
      },
      "source": [
        "## To Zip NWPU files and then have to get shareable link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUN-ObA5QGcv"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq0SVyVfvDvB"
      },
      "source": [
        "# %cd /content/drive/MyDrive/\n",
        "# !zip -r NWPU.zip './NWPU-Crowd-Sample-Code'\n",
        "# %cd ../../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh_ui4kmLvBw"
      },
      "source": [
        "# FlowNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OGCfYuDTz7n"
      },
      "source": [
        "## Setup and Install FlowNet2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMRndXGRFDJo"
      },
      "source": [
        "!pip install torch==1.0.0 torchvision==0.2.2 -f https://download.pytorch.org/whl/cu100/torch_stable.html\n",
        "!pip install pypng\n",
        "!pip install tensorboardx\n",
        "!pip install setproctitle colorama scipy==1.1.0\n",
        "!pip install flowiz -U"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWy52WXkEX7M"
      },
      "source": [
        "import os\n",
        "# get flownet2-pytorch source\n",
        "!git clone https://github.com/NVIDIA/flownet2-pytorch.git\n",
        "!mv /content/flownet2-pytorch /content/flownet2pytorch\n",
        "os.chdir('./flownet2pytorch')\n",
        "# install custom layers\n",
        "!bash install.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVwu6EIMVj2C"
      },
      "source": [
        "import os\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append( '/root/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tekc8kk_Ehft"
      },
      "source": [
        "!python main.py --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVqbeGLwLGfJ"
      },
      "source": [
        "## Training and Validation - Not tested"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBj_0jWLKci"
      },
      "source": [
        "If you do not want to train your model, you can skip this and move on to inference.\n",
        "\n",
        "The dataset my team used is quite large and we have unlimited storage on OneDrive. So we have mounted OneDrive to read and write data to. <br>\n",
        "To understand how to use it: https://www.youtube.com/watch?v=U6YPgARhRzA&t=255s&ab_channel=BoostUpStation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVqSGUtKLlVA"
      },
      "source": [
        "### OneDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYM_bz-zLbyj"
      },
      "source": [
        "# !wget https://downloads.rclone.org/v1.50.1/rclone-v1.50.1-linux-amd64.deb\n",
        "# !apt install ./rclone-v1.50.1-linux-amd64.deb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEbqhaQRLiAe"
      },
      "source": [
        "# !rclone config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DKu50aALjjY"
      },
      "source": [
        "# !sudo mkdir /content/onedrive\n",
        "# !nohup rclone --vfs-cache-mode writes mount onedrive: /content/onedrive &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phyZO2lSLqla"
      },
      "source": [
        "### Train and Validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y9f7R1gLu3w"
      },
      "source": [
        "# !python main.py --batch_size 8 --model FlowNet2 --loss=L1Loss --optimizer=Adam --optimizer_lr=1e-4 \\\n",
        "# --training_dataset MpiSintelFinal --training_dataset_root /path/to/mpi-sintel/final/dataset  \\\n",
        "# --validation_dataset MpiSintelClean --validation_dataset_root /path/to/mpi-sintel/clean/dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9C7PFQ8U9b6"
      },
      "source": [
        "## Run inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmez3yOUKkQx"
      },
      "source": [
        "Download the checkpoint. <br>\n",
        "If you have your own checkpoint after training, skip this step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePuj4IqqGk_k"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da',dest_path='./FlowNet2_checkpoint.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZn6AR6VKqMb"
      },
      "source": [
        "Run inference. <br>\n",
        "You can learn more about each command from here: https://towardsdatascience.com/generating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOJoEKsHS1n1"
      },
      "source": [
        "!python main.py --inference --model FlowNet2 --save_flow --save ./output --inference_dataset ImagesFromFolder --inference_dataset_root ../frames/ --resume ./FlowNet2_checkpoint.pth.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex7-_aXHaBUm"
      },
      "source": [
        "## Average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWJvO63kaDbM"
      },
      "source": [
        "if running_average == True or no_average_frames != None:\n",
        "  import numpy as np\n",
        "  from pathlib import Path\n",
        "  import os\n",
        "  from utils.flow_utils import writeFlow\n",
        "\n",
        "  def write_frame_ra(flow, i):\n",
        "    dir = \"./Running_Avg_Frames/\" + str(i).zfill(6) + \".flo\"\n",
        "    writeFlow(dir, flow)\n",
        "\n",
        "  def write_frame_avg(flow, i):\n",
        "    dir = \"./Average_Frames/\" + str(i).zfill(6) + \".flo\"\n",
        "    writeFlow(dir, flow)\n",
        "\n",
        "  def average_list(list1):\n",
        "    length_list = len(list1)\n",
        "    temp_addition = 0\n",
        "    for i in range(0, length_list):\n",
        "        temp_addition += list1[i]\n",
        "    temp_val = temp_addition / length_list\n",
        "    return temp_val\n",
        "    # try:\n",
        "    #   return (list1[0] + list1[1]) / 2\n",
        "    # except:\n",
        "    #   print(\"Error in averaging\")\n",
        "\n",
        "  def make_flow(flo):\n",
        "    tag = np.fromfile(flo, np.float32, count=1)[0]\n",
        "    width = np.fromfile(flo, np.int32, count=1)[0]\n",
        "    height = np.fromfile(flo, np.int32, count=1)[0]\n",
        "    nbands = 2\n",
        "    tmp = np.fromfile(flo, np.float32, count= nbands * width * height)\n",
        "    flow = np.resize(tmp, (int(height), int(width), int(nbands)))\n",
        "    return flow\n",
        "\n",
        "  if no_average_frames != None:\n",
        "    flow_list = [None] * no_average_frames\n",
        "    index_flow = 0\n",
        "    index_name = 0\n",
        "\n",
        "  numerator = 0\n",
        "  denominator = 0\n",
        "  index_name = 0\n",
        "\n",
        "  !mkdir ./Running_Avg_Frames\n",
        "  !mkdir ./Average_Frames\n",
        "  dir = './output/inference/run.epoch-0-flow-field/'\n",
        "\n",
        "  for i, flo_file in enumerate(sorted(os.listdir(dir))):\n",
        "    if flo_file[-3:] != \"flo\":\n",
        "      continue\n",
        "\n",
        "    path = Path(dir + flo_file)\n",
        "    with path.open(mode='r') as flo:\n",
        "      final_flo = make_flow(flo) # From their own code\n",
        "\n",
        "      if running_average == True and no_average_frames == None:\n",
        "        # Method 4\n",
        "        if denominator == 0:\n",
        "          numerator += final_flo\n",
        "          denominator = 1\n",
        "        else:\n",
        "          numerator += final_flo\n",
        "          denominator +=1\n",
        "\n",
        "          average_flow = numerator/denominator\n",
        "\n",
        "          write_frame(average_flow, index_name)\n",
        "          index_name += 1\n",
        "          \n",
        "        # os.remove(dir + flo_file)\n",
        "\n",
        "      # Method 3\n",
        "      if running_average == False and no_average_frames != None:\n",
        "        if (index_flow % no_average_frames == 0) and index_flow != 0:\n",
        "          average_flow = average_list(flow_list)\n",
        "          write_frame_ra(average_flow, index_name)\n",
        "          index_flow = 0\n",
        "          index_name += 1\n",
        "\n",
        "        flow_list[index_flow] = final_flo\n",
        "        index_flow += 1\n",
        "\n",
        "        if i == len(os.listdir(dir)) - 1:\n",
        "          average_flow = average_list(flow_list)\n",
        "          write_frame_avg(average_flow, index_name)\n",
        "\n",
        "        os.remove(dir + flo_file)\n",
        "\n",
        "      # Method 1\n",
        "      # if i == 0:\n",
        "      #   flow_list[0] = flow\n",
        "      # else:\n",
        "      #   flow_list[1] = flow\n",
        "      #   average_flow = average_list(flow_list)\n",
        "      #   write_frame(average_flow, i-1)\n",
        "      #   flow_list[0] = average_flow\n",
        "\n",
        "      # Method 2\n",
        "      # if index_flow == 0:\n",
        "      #   flow_list[index_flow] = flow\n",
        "      #   index_flow += 1\n",
        "      # else:\n",
        "      #   flow_list[index_flow] = flow\n",
        "      #   index_flow = 0\n",
        "      #   average_flow = average_list(flow_list)\n",
        "      #   write_frame(average_flow, index_name)\n",
        "      #   index_name += 1\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-EUe_yX5wwC"
      },
      "source": [
        "## Visualizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcPNFZh04-YE"
      },
      "source": [
        "### Flowiz technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBogYWu65HQe"
      },
      "source": [
        "# if visualize == True:\n",
        "\n",
        "#   !python -m flowiz \\\n",
        "#   ./Flo/*.flo \\\n",
        "#   -o FlowFrames \\\n",
        "#   -v FlowVideo \\\n",
        "#   -r 15\n",
        "\n",
        "#   !mv ./FlowVideo/000000.flo.mp4 './FlowVideo/$flow_video_name'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpdC2-7o-V3p"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('./FlowVideo/'+flow_video_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBSvCvj5XPMX"
      },
      "source": [
        "### Scipy Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5j8_TkanL0_"
      },
      "source": [
        "Install scipy as some tensorflow functionality requires updated scipy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb5ZMFHcl_jw"
      },
      "source": [
        "if visualize == True:\n",
        "  import time\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  !pip install scipy==1.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihUwCSdnXlge"
      },
      "source": [
        "Define show_flow() for visualization.\n",
        " Original Source https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGwMS0x0XaJC"
      },
      "source": [
        "# Source:https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "UNKNOWN_FLOW_THRESH = 1e7\n",
        "def show_flow(filename):\n",
        "    \"\"\"\n",
        "    visualize optical flow map using matplotlib\n",
        "    :param filename: optical flow file\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    flow = read_flow(filename)\n",
        "    img = flow_to_image(flow)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "def read_flow(filename):\n",
        "    \"\"\"\n",
        "    read optical flow from Middlebury .flo file\n",
        "    :param filename: name of the flow file\n",
        "    :return: optical flow data in matrix\n",
        "    \"\"\"\n",
        "    f = open(filename, 'rb')\n",
        "    magic = np.fromfile(f, np.float32, count=1)\n",
        "    data2d = None\n",
        "\n",
        "    if 202021.25 != magic:\n",
        "        print ('Magic number incorrect. Invalid .flo file')\n",
        "    else:\n",
        "        w = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "        h = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "        #print(\"Reading %d x %d flo file\" % (h, w))\n",
        "        data2d = np.fromfile(f, np.float32, count=2 * w * h)\n",
        "        # reshape data into 3D array (columns, rows, channels)\n",
        "        data2d = np.resize(data2d, (h, w, 2))\n",
        "    f.close()\n",
        "    return data2d\n",
        "\n",
        "def flow_to_image(flow):\n",
        "    \"\"\"\n",
        "    Convert flow into middlebury color code image\n",
        "    :param flow: optical flow map\n",
        "    :return: optical flow image in middlebury color\n",
        "    \"\"\"\n",
        "    u = flow[:, :, 0]\n",
        "    v = flow[:, :, 1]\n",
        "\n",
        "    maxu = -999.\n",
        "    maxv = -999.\n",
        "    minu = 999.\n",
        "    minv = 999.\n",
        "\n",
        "    idxUnknow = (abs(u) > UNKNOWN_FLOW_THRESH) | (abs(v) > UNKNOWN_FLOW_THRESH)\n",
        "    u[idxUnknow] = 0\n",
        "    v[idxUnknow] = 0\n",
        "\n",
        "    maxu = max(maxu, np.max(u))\n",
        "    minu = min(minu, np.min(u))\n",
        "\n",
        "    maxv = max(maxv, np.max(v))\n",
        "    minv = min(minv, np.min(v))\n",
        "\n",
        "    rad = np.sqrt(u ** 2 + v ** 2)\n",
        "    maxrad = max(-1, np.max(rad))\n",
        "\n",
        "    #print( \"max flow: %.4f\\nflow range:\\nu = %.3f .. %.3f\\nv = %.3f .. %.3f\" % (maxrad, minu,maxu, minv, maxv))\n",
        "\n",
        "    u = u/(maxrad + np.finfo(float).eps)\n",
        "    v = v/(maxrad + np.finfo(float).eps)\n",
        "\n",
        "    img = compute_color(u, v)\n",
        "\n",
        "    idx = np.repeat(idxUnknow[:, :, np.newaxis], 3, axis=2)\n",
        "    img[idx] = 0\n",
        "\n",
        "    return np.uint8(img)\n",
        "\n",
        "\n",
        "def compute_color(u, v):\n",
        "    \"\"\"\n",
        "    compute optical flow color map\n",
        "    :param u: optical flow horizontal map\n",
        "    :param v: optical flow vertical map\n",
        "    :return: optical flow in color code\n",
        "    \"\"\"\n",
        "    [h, w] = u.shape\n",
        "    img = np.zeros([h, w, 3])\n",
        "    nanIdx = np.isnan(u) | np.isnan(v)\n",
        "    u[nanIdx] = 0\n",
        "    v[nanIdx] = 0\n",
        "\n",
        "    colorwheel = make_color_wheel()\n",
        "    ncols = np.size(colorwheel, 0)\n",
        "\n",
        "    rad = np.sqrt(u**2+v**2)\n",
        "\n",
        "    a = np.arctan2(-v, -u) / np.pi\n",
        "\n",
        "    fk = (a+1) / 2 * (ncols - 1) + 1\n",
        "\n",
        "    k0 = np.floor(fk).astype(int)\n",
        "\n",
        "    k1 = k0 + 1\n",
        "    k1[k1 == ncols+1] = 1\n",
        "    f = fk - k0\n",
        "\n",
        "    for i in range(0, np.size(colorwheel,1)):\n",
        "        tmp = colorwheel[:, i]\n",
        "        col0 = tmp[k0-1] / 255\n",
        "        col1 = tmp[k1-1] / 255\n",
        "        col = (1-f) * col0 + f * col1\n",
        "\n",
        "        idx = rad <= 1\n",
        "        col[idx] = 1-rad[idx]*(1-col[idx])\n",
        "        notidx = np.logical_not(idx)\n",
        "\n",
        "        col[notidx] *= 0.75\n",
        "        img[:, :, i] = np.uint8(np.floor(255 * col*(1-nanIdx)))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def make_color_wheel():\n",
        "    \"\"\"\n",
        "    Generate color wheel according Middlebury color code\n",
        "    :return: Color wheel\n",
        "    \"\"\"\n",
        "    RY = 15\n",
        "    YG = 6\n",
        "    GC = 4\n",
        "    CB = 11\n",
        "    BM = 13\n",
        "    MR = 6\n",
        "\n",
        "    ncols = RY + YG + GC + CB + BM + MR\n",
        "\n",
        "    colorwheel = np.zeros([ncols, 3])\n",
        "\n",
        "    col = 0\n",
        "\n",
        "    # RY\n",
        "    colorwheel[0:RY, 0] = 255\n",
        "    colorwheel[0:RY, 1] = np.transpose(np.floor(255*np.arange(0, RY) / RY))\n",
        "    col += RY\n",
        "\n",
        "    # YG\n",
        "    colorwheel[col:col+YG, 0] = 255 - np.transpose(np.floor(255*np.arange(0, YG) / YG))\n",
        "    colorwheel[col:col+YG, 1] = 255\n",
        "    col += YG\n",
        "\n",
        "    # GC\n",
        "    colorwheel[col:col+GC, 1] = 255\n",
        "    colorwheel[col:col+GC, 2] = np.transpose(np.floor(255*np.arange(0, GC) / GC))\n",
        "    col += GC\n",
        "\n",
        "    # CB\n",
        "    colorwheel[col:col+CB, 1] = 255 - np.transpose(np.floor(255*np.arange(0, CB) / CB))\n",
        "    colorwheel[col:col+CB, 2] = 255\n",
        "    col += CB\n",
        "\n",
        "    # BM\n",
        "    colorwheel[col:col+BM, 2] = 255\n",
        "    colorwheel[col:col+BM, 0] = np.transpose(np.floor(255*np.arange(0, BM) / BM))\n",
        "    col += + BM\n",
        "\n",
        "    # MR\n",
        "    colorwheel[col:col+MR, 2] = 255 - np.transpose(np.floor(255 * np.arange(0, MR) / MR))\n",
        "    colorwheel[col:col+MR, 0] = 255\n",
        "\n",
        "    return colorwheel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itvl1OTiYMSd"
      },
      "source": [
        "Save Flo files as images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YopuaMoJPYnT"
      },
      "source": [
        "if visualize == True:\n",
        "\n",
        "  import os\n",
        "  import PIL.Image\n",
        "  def mkdir_ifnotexists(dir):\n",
        "      if os.path.exists(dir):\n",
        "          return\n",
        "      os.mkdir(dir)\n",
        "\n",
        "  if no_average_frames != None:\n",
        "    directory = \"./Average_Frames\"\n",
        "\n",
        "  elif running_average == True:\n",
        "    directory = \"./Running_Avg_Frames\"\n",
        "\n",
        "  else:\n",
        "    directory = '/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/'\n",
        "\n",
        "  # flo_pth='/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/'\n",
        "  flo_pth = directory\n",
        "  flos=[flo_pth + f for f in os.listdir(flo_pth)]\n",
        "  mkdir_ifnotexists('./FlowFrames')\n",
        "  length = len(flos)\n",
        "  for i in range(length):\n",
        "    if flos[i][-3:] == \"flo\":\n",
        "      print(i+1, \"/\", length)\n",
        "      PIL.Image.fromarray(flow_to_image(read_flow(flos[i]))).save('./FlowFrames/'+os.path.basename(flos[i])+'.png')\n",
        "      os.remove(flos[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HXMqwKjYT32"
      },
      "source": [
        "Generate video from Flo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGPockiXSpri"
      },
      "source": [
        "if visualize == True:\n",
        "  os.system('ffmpeg -r 25 -i FlowFrames/%6d.flo.png -vcodec libx264 -b 10M -y FlowVideo.mp4')\n",
        "\n",
        "  print(\"My program took\", time.time() - start_time, \"to run\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWvhMuDdl1GG"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('FlowVideo.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i_mPe1OYoTi"
      },
      "source": [
        "if visualize == True:\n",
        "\n",
        "  from IPython.display import HTML\n",
        "  from base64 import b64encode\n",
        "  mp4 = open('FlowVideo.mp4','rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  HTML(\"\"\"\n",
        "  <video width=400 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1owR4iebzvF"
      },
      "source": [
        "# Head Coordinates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHVMGwXicsdc",
        "outputId": "83c3d4c6-555a-49e1-e744-018081ce817a"
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "frames = []\n",
        "dir = 'NWPU_Results/'\n",
        "\n",
        "for file in sorted(os.listdir('./NWPU_Results')):\n",
        "  if file[-3:] == 'csv':\n",
        "    frames.append(dir + file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni8lheCUb1Y9",
        "outputId": "f48c69a3-c848-4890-8aa3-034574a3f245"
      },
      "source": [
        "# Import\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "f = open(\"temp.txt\", 'w')\n",
        "\n",
        "# Set Values\n",
        "threshold = 0.5 * (10**(-1))\n",
        "weight = 2\n",
        "\n",
        "for i, frame in enumerate(frames[1:]):\n",
        "    print(i, \" / \", len(frames)-1)\n",
        "\n",
        "    # Get Excel Sheet\n",
        "    X = np.genfromtxt(frame, delimiter=',')\n",
        "\n",
        "    os.remove(frame)\n",
        "\n",
        "    points_val = X\n",
        "\n",
        "    print(X.shape)\n",
        "\n",
        "    # First value is always nan for some reason\n",
        "    X[0][0] = 0\n",
        "\n",
        "    # Total Value\n",
        "    total_val = np.sum(X)\n",
        "    number_people = int(round(np.sum(X)/100))\n",
        "    print(\"Number of people:\", number_people)\n",
        "\n",
        "    vals = X[X[:,:] > threshold] # Contains the values. 1D array\n",
        "\n",
        "    index = np.argwhere(points_val > threshold) # Contains the index. 2D array.\n",
        "\n",
        "    # Making a 2D Array with point, val -> (x, y, val)\n",
        "    list_for_cluster = [] # Contains a 2D array with point, val\n",
        "\n",
        "    for i, point in enumerate(index):\n",
        "        val = vals[i]\n",
        "        list_for_cluster.append(np.append(point, val))\n",
        "\n",
        "    final_list = np.array(list_for_cluster) # Contains a 2D array with point, val -> (x, y, val)\n",
        "    final_list.shape\n",
        "\n",
        "    x_index = index[:,0]\n",
        "    y_index = index[:,1]\n",
        "\n",
        "    cluster_vals = index\n",
        "\n",
        "    weights = vals ** weight\n",
        "\n",
        "    # Cluster based on K Means Clustering\n",
        "    # Forcefully put how many ever people we found, make that many clusters\n",
        "\n",
        "    kmeans = KMeans(\n",
        "        init=\"random\",\n",
        "        n_clusters=number_people,\n",
        "        n_init=10,\n",
        "        max_iter=500,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    kmeans.fit(cluster_vals, sample_weight = weights)\n",
        "\n",
        "    kmeans.inertia_\n",
        "    kmeans.cluster_centers_\n",
        "    kmeans.n_iter_\n",
        "    y_kmeans = kmeans.predict(cluster_vals)\n",
        "\n",
        "    centers = kmeans.cluster_centers_\n",
        "\n",
        "    # Write to cords.txt\n",
        "    line = \"\"\n",
        "    for center in centers:\n",
        "        line += str(int(center[1])) + \" \" + str(int(center[0])) + \" \"\n",
        "\n",
        "    line = line.strip()\n",
        "    line += \"\\n \"\n",
        "\n",
        "    f.write(line)\n",
        "\n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 34\n",
            "1  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 32\n",
            "2  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "3  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "4  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 11\n",
            "5  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 11\n",
            "6  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "7  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "8  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "9  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "10  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "11  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "12  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "13  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "14  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 22\n",
            "15  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "16  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "17  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "18  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "19  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 20\n",
            "20  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "21  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 19\n",
            "22  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 25\n",
            "23  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "24  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "25  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "26  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "27  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "28  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "29  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 8\n",
            "30  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 7\n",
            "31  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 9\n",
            "32  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "33  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 6\n",
            "34  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "35  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 5\n",
            "36  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "37  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "38  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "39  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "40  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 19\n",
            "41  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "42  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 8\n",
            "43  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 7\n",
            "44  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "45  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "46  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 20\n",
            "47  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "48  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "49  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "50  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "51  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 28\n",
            "52  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 36\n",
            "53  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 23\n",
            "54  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "55  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 29\n",
            "56  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "57  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "58  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "59  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "60  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 25\n",
            "61  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 26\n",
            "62  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "63  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "64  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 22\n",
            "65  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 20\n",
            "66  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "67  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "68  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "69  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "70  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "71  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 19\n",
            "72  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "73  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "74  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "75  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 19\n",
            "76  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 22\n",
            "77  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "78  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 24\n",
            "79  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 23\n",
            "80  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "81  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "82  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "83  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "84  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 24\n",
            "85  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "86  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "87  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "88  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 22\n",
            "89  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6P-9seb5HAW"
      },
      "source": [
        "cords = open(\"cords.txt\", 'w')\n",
        "temp = open(\"temp.txt\", 'r')\n",
        "temp_lines = temp.read().split(\"\\n\")\n",
        "\n",
        "for i, line in enumerate(temp_lines):\n",
        "  fline = line.strip()\n",
        "  if i != len(temp_lines) - 1:\n",
        "    fline += \"\\n\"\n",
        "  cords.write(fline)\n",
        "\n",
        "cords.close()\n",
        "temp.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPnauiE5sNLV"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4AwX9BZmv36"
      },
      "source": [
        "## Manual Annotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oKtWXy6m1nQ"
      },
      "source": [
        "\n",
        "\n",
        "1.   Take any frame from the folder frames. RENAME it to 'image.png'\n",
        "2.   Run the file \"annotate.py\" from the github folder\n",
        "3.   Paste the output text file \"text_speed.txt\" in the same folder as the \"cords.txt\". This is the /content/ directory\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWeidUMPnl43"
      },
      "source": [
        "HOW TO RUN ANNOTATE.PY\n",
        "\n",
        "0.   Keep the annotate.py and the first frame in the same directory and run 'python annotate.py'\n",
        "1.   Annotate the first and second x meters\n",
        "2.   Annotate the road in a clockwise fashion starting from where you marked the first x meters\n",
        "3.   Fil these variables:\n",
        "\n",
        "  *   temp_approx_meters_p1 = 0.5 # How many meters the first x meters represents\n",
        "  *   temp_approx_meters_p2 = 0.5 # How many meters the second y meters represents\n",
        "  *   normalize_meters = 1 # If you want the output to be represented in some other amount of meters, do that here. For eg. if you have annotated first point as 0.5m and second as 1m and want the output to be catered to by 1m, then make this 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pewBZr7pmyGH",
        "outputId": "ed8ed95a-2b76-47cb-b57a-105f405469e1"
      },
      "source": [
        "# Setup\n",
        "!mkdir Clustering\n",
        "\n",
        "!mv cords.txt text_speed.txt Clustering\n",
        "\n",
        "%cd Clustering\n",
        "\n",
        "!mkdir text_files\n",
        "!mkdir output_frames\n",
        "\n",
        "!mv cords.txt text_speed.txt text_files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'text_speed.txt': No such file or directory\n",
            "/content/Clustering\n",
            "mv: cannot stat 'text_speed.txt': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVKQ6WDAsU0w"
      },
      "source": [
        "## Cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTp34fkdsOjq",
        "outputId": "641de1f5-ceb1-4684-abbc-84269350d8ad"
      },
      "source": [
        "!git clone https://github.com/JibKh/NVIDIA-FlowNet2-Google-Colab.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NVIDIA-FlowNet2-Google-Colab'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 107 (delta 49), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (107/107), 48.13 MiB | 12.88 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjRiYwsysr5v",
        "outputId": "2bbb85df-40d2-4c41-c6fe-3e2584c7b75f"
      },
      "source": [
        "%cd NVIDIA-FlowNet2-Google-Colab/\n",
        "!mv cluster.py /content/Clustering\n",
        "%cd ..\n",
        "!rm -r NVIDIA-FlowNet2-Google-Colab/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Clustering/NVIDIA-FlowNet2-Google-Colab\n",
            "/content/Clustering\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE54AYiy2UFw"
      },
      "source": [
        "# Have to remove first frame and rename\n",
        "!rm /content/frames/000000.png\n",
        "\n",
        "\n",
        "file_dir = \"/content/frames/\"\n",
        "i = 0\n",
        "for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "  # print(filename)\n",
        "  if filename[-3:] == \"png\":\n",
        "    src = file_dir + filename\n",
        "    dst = file_dir + str(i).zfill(6) + '.png'\n",
        "    os.rename(src, dst)\n",
        "    i += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr2YuBcptXPZ",
        "outputId": "e58f0dca-3d0f-4147-b344-fbebc8566841"
      },
      "source": [
        "!python cluster.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"cluster.py\", line 496, in <module>\n",
            "    main()\n",
            "  File \"cluster.py\", line 486, in main\n",
            "    points_labels, velocity_labels, speed_labels, average_speed, total_average_speed = cluster_2()\n",
            "  File \"cluster.py\", line 262, in cluster_2\n",
            "    total_total += total_average_speed\n",
            "NameError: name 'total_total' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FzQbslOva0s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}